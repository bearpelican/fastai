{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from fastai import *\n",
    "from fastai.vision import *\n",
    "from fastai.vision.models.wrn import wrn_22\n",
    "from fastai.docs import *\n",
    "from fastai.docs import CIFAR_PATH\n",
    "\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --\n",
    "# Model definition\n",
    "# Derived from models in `https://github.com/kuangliu/pytorch-cifar`\n",
    "\n",
    "class PreActBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.bn1   = nn.BatchNorm2d(in_channels)\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn2   = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False)\n",
    "            )\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(x))\n",
    "        shortcut = self.shortcut(out) if hasattr(self, 'shortcut') else x\n",
    "        out = self.conv1(out)\n",
    "        out = self.conv2(F.relu(self.bn2(out)))\n",
    "        return out + shortcut\n",
    "    \n",
    "class ResNet18(nn.Module):\n",
    "    def __init__(self, num_blocks=[2, 2, 2, 2], num_classes=10):\n",
    "        super().__init__()\n",
    "        self.in_channels = 64\n",
    "        self.prep = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.layers = nn.Sequential(\n",
    "            self._make_layer(64, 64, num_blocks[0], stride=1),\n",
    "            self._make_layer(64, 128, num_blocks[1], stride=2),\n",
    "            self._make_layer(128, 256, num_blocks[2], stride=2),\n",
    "            self._make_layer(256, 256, num_blocks[3], stride=2),\n",
    "        )\n",
    "        self.classifier = nn.Linear(512, num_classes)\n",
    "        \n",
    "    def _make_layer(self, in_channels, out_channels, num_blocks, stride):\n",
    "        \n",
    "        strides = [stride] + [1] * (num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(PreActBlock(in_channels=in_channels, out_channels=out_channels, stride=stride))\n",
    "            in_channels = out_channels\n",
    "        \n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.half()\n",
    "        x = self.prep(x)\n",
    "        \n",
    "        x = self.layers(x)\n",
    "        \n",
    "        x_avg = F.adaptive_avg_pool2d(x, (1, 1))\n",
    "        x_avg = x_avg.view(x_avg.size(0), -1)\n",
    "        \n",
    "        x_max = F.adaptive_max_pool2d(x, (1, 1))\n",
    "        x_max = x_max.view(x_max.size(0), -1)\n",
    "        \n",
    "        x = torch.cat([x_avg, x_max], dim=-1)\n",
    "        \n",
    "        x = self.classifier(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "untar_data(CIFAR_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_tfms = ([pad(padding=4), crop(size=32, row_pct=(0,1), col_pct=(0,1)), flip_lr(p=0.5)], [])\n",
    "data = image_data_from_folder(CIFAR_PATH, valid='test', ds_tfms=ds_tfms, tfms=cifar_norm, bs=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQEAZABkAAD/2wBDAAIBAQEBAQIBAQECAgICAgQDAgICAgUEBAMEBgUGBgYFBgYGBwkIBgcJBwYGCAsICQoKCgoKBggLDAsKDAkKCgr/2wBDAQICAgICAgUDAwUKBwYHCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgr/wAARCAAgACADASIAAhEBAxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6/9oADAMBAAIRAxEAPwD6C+LnxK1TwV4bFyq3KWxmWK/v4PlNsrDI2sRgM2MZ7bvUirvwn/aZ8O+PfCB12yiuYb2C5e1n0q4UrIkqEggE9U6EN3BBrP8AFmt6hbaFq/gLUtHs9ZF3bSRbZHGz5gRhs8ZHX2xXz5pPhH4meBIn8H3Ov7Lm0KtYa2EyIyf9XvX+KNh8h6H72OlfH1q6pzutj6rDYb2sfe0f5n2h8I/F3jDxWJ08R2QhdZDsEfQe3uPf/GuwfTL03G7zD1rl/wBlvXYvEngW3l142EGrRxEX0dlcmWHIJBZXYAkcZ5GR096luv2q/gTb6Fq/ic6/PJa6LrUOmXTRWxJeaQNsZBn5kIVzn0U+1dtOtSVJNy3OWrSqOtJKO39fifJGofEa3+G+sj4e+FdLu/EniK7EYtdJ06FlEWAQZbiViVVmzl26kjOBXpOl/sR/ET4ieI9J+L3jb4hSRanY2Ait/DcKbbAZ5IfvJ9W69cCvf/DvwT+Hugap/btjoUQvHwZbgoN0h9Se9dzptrGDkDGOBiuZRXLtqy51KlR6vRbJHytr/wAJ/GHw6u203SdOu9Gg1Vvs95ZwTNJazBxtJhkHMbYz8p6jNcyn7KHjyP4U+KPDttexSPeeL9NuLS734UQrHMCzDsVDkY/xr6h+N3hzxR4p1jw3oHhzU7G13agZZZbudR0GBhCQX4J4Fd/o3wl8P6d8PJvAU889xHdAm5u3bEskhyS+R90g9McDA9Kzp4aEqkvT8zo+syVNJ9/wP//Z\n",
      "image/png": "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\n",
      "text/plain": [
       "Image (3, 32, 32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.train_ds[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show_image_batch(data.train_dl, data.train_ds.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, max=30), HTML(value='0.00% [0/30 00:00<00:00]'))), HTML(valâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 04:28\n",
      "epoch  train loss  valid loss  accuracy\n",
      "0      1.795702    1.365861    0.535200  (00:20)\n",
      "1      1.581178    1.207135    0.577200  (00:08)\n",
      "2      1.440670    1.063459    0.641600  (00:08)\n",
      "3      1.334411    1.294384    0.584400  (00:08)\n",
      "4      1.289912    1.274863    0.565400  (00:08)\n",
      "5      1.241590    0.927619    0.699300  (00:08)\n",
      "6      1.201504    0.752876    0.767600  (00:08)\n",
      "7      1.173325    0.698428    0.791800  (00:08)\n",
      "8      1.162377    0.771245    0.769500  (00:08)\n",
      "9      1.139921    0.648074    0.817400  (00:08)\n",
      "10     1.126804    0.617434    0.825300  (00:08)\n",
      "11     1.117855    0.647468    0.817300  (00:08)\n",
      "12     1.107589    0.646871    0.801700  (00:08)\n",
      "13     1.098015    0.714905    0.796200  (00:08)\n",
      "14     1.087251    0.770405    0.777800  (00:08)\n",
      "15     1.076816    0.501551    0.870600  (00:08)\n",
      "16     1.060990    0.556516    0.844400  (00:08)\n",
      "17     1.043575    0.538492    0.855700  (00:08)\n",
      "18     1.035051    0.510318    0.875400  (00:08)\n",
      "19     1.011068    0.435927    0.894200  (00:08)\n",
      "20     0.992082    0.453798    0.885000  (00:08)\n",
      "21     0.973627    0.433991    0.890600  (00:08)\n",
      "22     0.949603    0.390490    0.911700  (00:08)\n",
      "23     0.939600    0.365594    0.915900  (00:08)\n",
      "24     0.921042    0.359234    0.925100  (00:08)\n",
      "25     0.893907    0.336610    0.932700  (00:08)\n",
      "26     0.882428    0.328191    0.935300  (00:08)\n",
      "27     0.868656    0.316287    0.935300  (00:08)\n",
      "28     0.865694    0.314341    0.938500  (00:08)\n",
      "29     0.855949    0.313705    0.938600  (00:08)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "learn = Learner(data, ResNet18(), metrics=accuracy).to_fp16().mixup()\n",
    "learn.fit_one_cycle(30, 4e-3, wd=0.2, div_factor=20, pct_start=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, max=30), HTML(value='0.00% [0/30 00:00<00:00]'))), HTML(valâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 04:13\n",
      "epoch  train loss  valid loss  accuracy\n",
      "0      1.789306    1.456366    0.468000  (00:08)\n",
      "1      1.571725    1.181943    0.604300  (00:08)\n",
      "2      1.428148    0.898890    0.718400  (00:08)\n",
      "3      1.333608    1.044259    0.660000  (00:08)\n",
      "4      1.275320    1.186650    0.592100  (00:08)\n",
      "5      1.228309    0.843180    0.736200  (00:08)\n",
      "6      1.206232    0.662824    0.803300  (00:08)\n",
      "7      1.178555    0.763833    0.772100  (00:08)\n",
      "8      1.159437    0.754386    0.781800  (00:08)\n",
      "9      1.148030    0.651326    0.810700  (00:08)\n",
      "10     1.133018    0.883851    0.723200  (00:08)\n",
      "11     1.125575    0.666752    0.808100  (00:08)\n",
      "12     1.109944    0.824744    0.751900  (00:08)\n",
      "13     1.105049    0.620707    0.822100  (00:08)\n",
      "14     1.094006    0.743840    0.768300  (00:08)\n",
      "15     1.086294    0.560766    0.852300  (00:08)\n",
      "16     1.070282    0.493755    0.865100  (00:08)\n",
      "17     1.045532    0.488506    0.875600  (00:08)\n",
      "18     1.037327    0.475848    0.881500  (00:08)\n",
      "19     1.017956    0.455821    0.887500  (00:08)\n",
      "20     0.995424    0.461125    0.892300  (00:08)\n",
      "21     0.973048    0.410172    0.902000  (00:08)\n",
      "22     0.951355    0.389699    0.911900  (00:08)\n",
      "23     0.936195    0.372342    0.914100  (00:08)\n",
      "24     0.917232    0.353124    0.926600  (00:08)\n",
      "25     0.893314    0.323894    0.932900  (00:08)\n",
      "26     0.882400    0.325098    0.933800  (00:08)\n",
      "27     0.875555    0.321898    0.937500  (00:08)\n",
      "28     0.863448    0.320172    0.938500  (00:08)\n",
      "29     0.857723    0.316557    0.938900  (00:08)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "learn = Learner(data, ResNet18(), metrics=accuracy).to_fp16().mixup()\n",
    "learn.bn_wd = False\n",
    "learn.fit_one_cycle(30, 4e-3, wd=0.2, div_factor=20, pct_start=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(data, ResNet18(), metrics=accuracy).to_fp16().mixup()\n",
    "learn.bn_wd = False\n",
    "learn.fit_one_cycle(30, 4e-3, wd=0.2, div_factor=20, pct_start=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class fp16cb(Callback):    \n",
    "    def on_train_begin(self, n_epochs:int, **kwargs:Any)->None: pass\n",
    "    def on_loss_begin(self, last_output:Tensor, **kwargs:Any) -> Tensor:\n",
    "        \"Convert half precision output to FP32 to avoid reduction overflow.\"\n",
    "        return last_output.float()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
