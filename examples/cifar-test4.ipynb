{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from fastai import *\n",
    "from fastai.vision import *\n",
    "from fastai.vision.models.wrn import wrn_22\n",
    "from fastai.docs import *\n",
    "from fastai.docs import CIFAR_PATH\n",
    "\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --\n",
    "# Model definition\n",
    "# Derived from models in `https://github.com/kuangliu/pytorch-cifar`\n",
    "\n",
    "class PreActBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.bn1   = nn.BatchNorm2d(in_channels)\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn2   = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False)\n",
    "            )\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(x))\n",
    "        shortcut = self.shortcut(out) if hasattr(self, 'shortcut') else x\n",
    "        out = self.conv1(out)\n",
    "        out = self.conv2(F.relu(self.bn2(out)))\n",
    "        return out + shortcut\n",
    "    \n",
    "class ResNet18(nn.Module):\n",
    "    def __init__(self, num_blocks=[2, 2, 2, 2], num_classes=10):\n",
    "        super().__init__()\n",
    "        self.in_channels = 64\n",
    "        self.prep = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.layers = nn.Sequential(\n",
    "            self._make_layer(64, 64, num_blocks[0], stride=1),\n",
    "            self._make_layer(64, 128, num_blocks[1], stride=2),\n",
    "            self._make_layer(128, 256, num_blocks[2], stride=2),\n",
    "            self._make_layer(256, 256, num_blocks[3], stride=2),\n",
    "        )\n",
    "        self.classifier = nn.Linear(512, num_classes)\n",
    "        \n",
    "    def _make_layer(self, in_channels, out_channels, num_blocks, stride):\n",
    "        \n",
    "        strides = [stride] + [1] * (num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(PreActBlock(in_channels=in_channels, out_channels=out_channels, stride=stride))\n",
    "            in_channels = out_channels\n",
    "        \n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.half()\n",
    "        x = self.prep(x)\n",
    "        \n",
    "        x = self.layers(x)\n",
    "        \n",
    "        x_avg = F.adaptive_avg_pool2d(x, (1, 1))\n",
    "        x_avg = x_avg.view(x_avg.size(0), -1)\n",
    "        \n",
    "        x_max = F.adaptive_max_pool2d(x, (1, 1))\n",
    "        x_max = x_max.view(x_max.size(0), -1)\n",
    "        \n",
    "        x = torch.cat([x_avg, x_max], dim=-1)\n",
    "        \n",
    "        x = self.classifier(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "untar_data(CIFAR_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_tfms = ([pad(padding=4), crop(size=32, row_pct=(0,1), col_pct=(0,1)), flip_lr(p=0.5)], [])\n",
    "data = image_data_from_folder(CIFAR_PATH, valid='test', ds_tfms=ds_tfms, tfms=cifar_norm, bs=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, max=30), HTML(value='0.00% [0/30 00:00<00:00]'))), HTML(val…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 04:33\n",
      "epoch  train loss  valid loss  accuracy\n",
      "0      1.863839    1.428895    0.494100  (00:17)\n",
      "1      1.686357    1.292163    0.555500  (00:08)\n",
      "2      1.545858    1.143956    0.614600  (00:08)\n",
      "3      1.453602    0.974595    0.686900  (00:08)\n",
      "4      1.363806    0.967794    0.683500  (00:08)\n",
      "5      1.296154    1.037295    0.648200  (00:08)\n",
      "6      1.252518    0.708865    0.791900  (00:08)\n",
      "7      1.227285    0.759126    0.763200  (00:08)\n",
      "8      1.205061    0.805400    0.752900  (00:08)\n",
      "9      1.174518    0.646748    0.812500  (00:09)\n",
      "10     1.153771    0.847638    0.750900  (00:08)\n",
      "11     1.137956    0.817254    0.748400  (00:08)\n",
      "12     1.130720    0.676482    0.796100  (00:08)\n",
      "13     1.115529    0.622713    0.814500  (00:08)\n",
      "14     1.108972    0.630571    0.830100  (00:08)\n",
      "15     1.094643    0.619395    0.826500  (00:08)\n",
      "16     1.085728    0.677245    0.807700  (00:08)\n",
      "17     1.068075    0.560595    0.850900  (00:08)\n",
      "18     1.052747    0.566342    0.841600  (00:09)\n",
      "19     1.036317    0.485027    0.872000  (00:08)\n",
      "20     1.013467    0.463638    0.887500  (00:08)\n",
      "21     0.998690    0.485865    0.882100  (00:08)\n",
      "22     0.972597    0.430945    0.900100  (00:08)\n",
      "23     0.956025    0.387300    0.912000  (00:08)\n",
      "24     0.932912    0.368510    0.918600  (00:08)\n",
      "25     0.914025    0.346781    0.926000  (00:08)\n",
      "26     0.895283    0.330095    0.932300  (00:08)\n",
      "27     0.883898    0.319411    0.936200  (00:08)\n",
      "28     0.874691    0.318610    0.936900  (00:08)\n",
      "29     0.866088    0.314837    0.937000  (00:08)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "learn = Learner(data, ResNet18(), metrics=accuracy).to_fp16().mixup()\n",
    "learn.bn_wd = False\n",
    "learn.fit_one_cycle(30, 8e-3, wd=0.2, div_factor=20, pct_start=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, max=30), HTML(value='0.00% [0/30 00:00<00:00]'))), HTML(val…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 04:18\n",
      "epoch  train loss  valid loss  accuracy\n",
      "0      1.850430    1.401118    0.508300  (00:08)\n",
      "1      1.661367    1.192342    0.584200  (00:08)\n",
      "2      1.552455    1.109327    0.624200  (00:08)\n",
      "3      1.441292    1.005031    0.671800  (00:08)\n",
      "4      1.360136    1.068661    0.647400  (00:08)\n",
      "5      1.299787    0.871593    0.731400  (00:08)\n",
      "6      1.267726    0.787459    0.754300  (00:08)\n",
      "7      1.235394    0.963737    0.704900  (00:08)\n",
      "8      1.205380    0.777847    0.759100  (00:08)\n",
      "9      1.177572    0.898474    0.725700  (00:08)\n",
      "10     1.162290    0.695065    0.794000  (00:08)\n",
      "11     1.147247    0.643912    0.819000  (00:08)\n",
      "12     1.136665    0.650594    0.826300  (00:08)\n",
      "13     1.125513    0.782817    0.751200  (00:08)\n",
      "14     1.119277    0.617884    0.826900  (00:08)\n",
      "15     1.104281    0.730081    0.782700  (00:08)\n",
      "16     1.093953    0.590395    0.834500  (00:08)\n",
      "17     1.080366    0.598041    0.832600  (00:08)\n",
      "18     1.067626    0.527368    0.861200  (00:08)\n",
      "19     1.048240    0.540811    0.846700  (00:08)\n",
      "20     1.032490    0.478486    0.883200  (00:08)\n",
      "21     1.007876    0.501827    0.866600  (00:08)\n",
      "22     0.983177    0.409386    0.901200  (00:08)\n",
      "23     0.965105    0.475422    0.878800  (00:08)\n",
      "24     0.943801    0.390181    0.906300  (00:08)\n",
      "25     0.923640    0.361848    0.920000  (00:08)\n",
      "26     0.902885    0.332814    0.931300  (00:08)\n",
      "27     0.887069    0.320165    0.936400  (00:08)\n",
      "28     0.876276    0.312874    0.938100  (00:08)\n",
      "29     0.872113    0.318323    0.938900  (00:08)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "learn = Learner(data, ResNet18(), metrics=accuracy).to_fp16().mixup()\n",
    "learn.bn_wd = False\n",
    "learn.fit_one_cycle(30, 1e-2, wd=0.2, div_factor=20, pct_start=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, max=30), HTML(value='0.00% [0/30 00:00<00:00]'))), HTML(val…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 04:18\n",
      "epoch  train loss  valid loss  accuracy\n",
      "0      1.873983    1.790770    0.371000  (00:08)\n",
      "1      1.678811    1.212362    0.577800  (00:08)\n",
      "2      1.537629    1.090717    0.620000  (00:08)\n",
      "3      1.435880    1.212508    0.579300  (00:08)\n",
      "4      1.352413    0.849448    0.725900  (00:08)\n",
      "5      1.299714    0.909035    0.722500  (00:08)\n",
      "6      1.249889    0.721878    0.787200  (00:08)\n",
      "7      1.228680    0.781462    0.758700  (00:08)\n",
      "8      1.198071    0.823750    0.735500  (00:08)\n",
      "9      1.180463    0.874900    0.727800  (00:08)\n",
      "10     1.164486    0.875520    0.717600  (00:08)\n",
      "11     1.148277    0.679772    0.807200  (00:08)\n",
      "12     1.138567    0.663854    0.806200  (00:08)\n",
      "13     1.134031    0.945333    0.701200  (00:08)\n",
      "14     1.118752    0.663251    0.801000  (00:08)\n",
      "15     1.111242    1.069927    0.651500  (00:08)\n",
      "16     1.095738    0.713565    0.781000  (00:08)\n",
      "17     1.081970    0.638267    0.810600  (00:08)\n",
      "18     1.062134    0.503238    0.876300  (00:08)\n",
      "19     1.046649    0.552543    0.846800  (00:08)\n",
      "20     1.028016    0.550564    0.859100  (00:08)\n",
      "21     1.008660    0.475574    0.879300  (00:08)\n",
      "22     0.987989    0.412642    0.903700  (00:08)\n",
      "23     0.963739    0.400533    0.908400  (00:08)\n",
      "24     0.942090    0.379299    0.916600  (00:08)\n",
      "25     0.924465    0.345775    0.929300  (00:08)\n",
      "26     0.902678    0.339981    0.928900  (00:08)\n",
      "27     0.888326    0.322335    0.935300  (00:08)\n",
      "28     0.877355    0.317406    0.936600  (00:08)\n",
      "29     0.875629    0.317712    0.938300  (00:08)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "learn = Learner(data, ResNet18(), metrics=accuracy).to_fp16().mixup()\n",
    "learn.bn_wd = False\n",
    "learn.fit_one_cycle(30, 1e-2, wd=0.2, div_factor=25, pct_start=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class fp16cb(Callback):    \n",
    "    def on_train_begin(self, n_epochs:int, **kwargs:Any)->None: pass\n",
    "    def on_loss_begin(self, last_output:Tensor, **kwargs:Any) -> Tensor:\n",
    "        \"Convert half precision output to FP32 to avoid reduction overflow.\"\n",
    "        return last_output.float()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
