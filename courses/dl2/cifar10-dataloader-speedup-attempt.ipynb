{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CIFAR 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.conv_learner import *\n",
    "from fastai.models.cifar10.preact_resnet import *\n",
    "torch.backends.cudnn.benchmark = True\n",
    "PATH = Path(\"data/cifar10/\")\n",
    "os.makedirs(PATH,exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "stats = (np.array([ 0.4914 ,  0.48216,  0.44653]), np.array([ 0.24703,  0.24349,  0.26159]))\n",
    "\n",
    "bs=512\n",
    "sz=32\n",
    "workers=7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "\n",
    "def pad(img, p=4, padding_mode='reflect'):\n",
    "        return Image.fromarray(np.pad(np.asarray(img), ((p, p), (p, p), (0, 0)), padding_mode))\n",
    "def to_pil(img): return Image.fromarray(img)\n",
    "\n",
    "def torch_tfms(size, conv_pil=False, to_numpy=False):\n",
    "    mean,std=[0.4914 , 0.48216, 0.44653], [0.24703, 0.24349, 0.26159]\n",
    "    normalize = transforms.Normalize(mean=mean, std=std)\n",
    "    tfms = [transforms.ToTensor(), normalize]\n",
    "    \n",
    "    # Torch transforms with fastai dl\n",
    "    if to_numpy: tfms = [np.array, Normalize(mean,std), lambda x: x[0].T]\n",
    "        \n",
    "    aug_tfms = [\n",
    "#         pad, # TODO: use `padding` rather than assuming 4\n",
    "#         transforms.RandomCrop(size),\n",
    "# #         transforms.ColorJitter(.25,.25,.25),\n",
    "# #         transforms.RandomRotation(2),\n",
    "#         transforms.RandomHorizontalFlip(),\n",
    "    ]\n",
    "    scale_size = 40\n",
    "    padding = int((scale_size - size) / 2)\n",
    "    \n",
    "    train_tfms = transforms.Compose(aug_tfms + tfms)\n",
    "    train_tfms.sz = size\n",
    "    val_tfms = transforms.Compose(tfms)\n",
    "    val_tfms.sz = size\n",
    "    if conv_pil:\n",
    "        train_tfms.transforms.insert(0, to_pil)\n",
    "        val_tfms.transforms.insert(0, to_pil)\n",
    "    return train_tfms, val_tfms\n",
    "    \n",
    "def torch_ds(data_path, tfms):\n",
    "    train_tfms, val_tfms = tfms\n",
    "    \n",
    "    # Data loading code\n",
    "    traindir = os.path.join(data_path, 'train')\n",
    "    valdir = os.path.join(data_path, 'test')\n",
    "\n",
    "    train_dataset = datasets.ImageFolder(traindir, train_tfms)\n",
    "    val_dataset = datasets.ImageFolder(valdir, val_tfms)\n",
    "    return train_dataset, val_dataset\n",
    "\n",
    "def torch_loader(data_path, datasets):\n",
    "    train_dataset, val_dataset = datasets\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=bs, shuffle=True,\n",
    "        num_workers=workers, pin_memory=True)\n",
    "\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        val_dataset, batch_size=bs*2, shuffle=False,\n",
    "        num_workers=workers, pin_memory=True)\n",
    "\n",
    "    data = ModelData(data_path, train_loader, val_loader)\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_learner(data):\n",
    "    m = PreActResNet18()\n",
    "    learn = ConvLearner.from_model_data(m, data)\n",
    "    learn.crit = nn.CrossEntropyLoss()\n",
    "    learn.metrics = [accuracy]\n",
    "    learn.half()\n",
    "    return learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ZombieLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, queue\n",
    "from torch.utils.data.sampler import SequentialSampler, RandomSampler, BatchSampler\n",
    "# from .imports import *\n",
    "# from .core import *\n",
    "import collections,sys,traceback,threading\n",
    "from fastai.executors import LazyThreadPoolExecutor\n",
    "\n",
    "string_classes = (str, bytes)\n",
    "\n",
    "\n",
    "def get_tensor(batch, pin, half=False):\n",
    "    if isinstance(batch, (np.ndarray, np.generic)):\n",
    "        batch = T(batch, half=half, cuda=False).contiguous()\n",
    "        if pin: batch = batch.pin_memory()\n",
    "        return to_gpu(batch)\n",
    "    elif isinstance(batch, string_classes):\n",
    "        return batch\n",
    "    elif isinstance(batch, collections.Mapping):\n",
    "        return {k: get_tensor(sample, pin, half) for k, sample in batch.items()}\n",
    "    elif isinstance(batch, collections.Sequence):\n",
    "        return [get_tensor(sample, pin, half) for sample in batch]\n",
    "    raise TypeError(f\"batch must contain numbers, dicts or lists; found {type(batch)}\")\n",
    "\n",
    "\n",
    "class ZombieDataLoader(object):\n",
    "    def __init__(self, dataset, batch_size=1, shuffle=False, sampler=None, batch_sampler=None, pad_idx=0,\n",
    "                 num_workers=None, pin_memory=False, drop_last=False, pre_pad=True, half=False,\n",
    "                 transpose=False, transpose_y=False, collate_fn=None, multiprocess=False):\n",
    "        self.dataset,self.batch_size,self.num_workers = dataset,batch_size,num_workers\n",
    "        self.pin_memory,self.drop_last,self.pre_pad = pin_memory,drop_last,pre_pad\n",
    "        self.transpose,self.transpose_y,self.pad_idx,self.half = transpose,transpose_y,pad_idx,half\n",
    "\n",
    "#         if batch_sampler is not None:\n",
    "#             if batch_size > 1 or shuffle or sampler is not None or drop_last:\n",
    "#                 raise ValueError('batch_sampler is mutually exclusive with '\n",
    "#                                  'batch_size, shuffle, sampler, and drop_last')\n",
    "\n",
    "        if sampler is not None and shuffle:\n",
    "            raise ValueError('sampler is mutually exclusive with shuffle')\n",
    "\n",
    "        if batch_sampler is None:\n",
    "            if sampler is None:\n",
    "                sampler = RandomSampler(dataset) if shuffle else SequentialSampler(dataset)\n",
    "            batch_sampler = BatchSampler(sampler, batch_size, drop_last)\n",
    "\n",
    "        if num_workers is None:\n",
    "            self.num_workers = num_cpus()\n",
    "\n",
    "        self.sampler = sampler\n",
    "        self.batch_sampler = batch_sampler\n",
    "        self.collate_fn = self.np_collate if collate_fn is None else collate_fn\n",
    "        self.multiprocess = multiprocess\n",
    "\n",
    "    def __len__(self): return len(self.batch_sampler)\n",
    "\n",
    "    def jag_stack(self, b):\n",
    "        if len(b[0].shape) not in (1,2): return np.stack(b)\n",
    "        ml = max(len(o) for o in b)\n",
    "        if min(len(o) for o in b)==ml: return np.stack(b)\n",
    "        res = np.zeros((len(b), ml), dtype=b[0].dtype) + self.pad_idx\n",
    "        for i,o in enumerate(b):\n",
    "            if self.pre_pad: res[i, -len(o):] = o\n",
    "            else:            res[i,  :len(o)] = o\n",
    "        return res\n",
    "\n",
    "    def np_collate(self, batch):\n",
    "        b = batch[0]\n",
    "        if isinstance(b, (np.ndarray, np.generic)): return self.jag_stack(batch)\n",
    "        elif isinstance(b, (int, float)): return np.array(batch)\n",
    "        elif isinstance(b, string_classes): return batch\n",
    "        elif isinstance(b, collections.Mapping):\n",
    "            return {key: self.np_collate([d[key] for d in batch]) for key in b}\n",
    "        elif isinstance(b, collections.Sequence):\n",
    "            return [self.np_collate(samples) for samples in zip(*batch)]\n",
    "        raise TypeError((\"batch must contain numbers, dicts or lists; found {}\".format(type(b))))\n",
    "\n",
    "    def get_batch(self, indices):\n",
    "        res = self.collate_fn([self.dataset[i] for i in indices])\n",
    "        if self.transpose:   res[0] = res[0].T\n",
    "        if self.transpose_y: res[1] = res[1].T\n",
    "        return res\n",
    "\n",
    "    def __iter__(self):\n",
    "        if self.num_workers==0:\n",
    "            for batch in map(self.get_batch, iter(self.batch_sampler)):\n",
    "                yield get_tensor(batch, self.pin_memory, self.half)\n",
    "        else:\n",
    "            if self.multiprocess:\n",
    "                with ProcessPoolExecutor(max_workers=self.num_workers) as e:\n",
    "                    # avoid py3.6 issue where queue is infinite and can result in memory exhaustion\n",
    "                    for batch in e.map(self.get_batch, iter(self.batch_sampler)): \n",
    "                        if self.collate_fn == self.np_collate: \n",
    "                            yield get_tensor(batch, self.pin_memory, self.half)\n",
    "                        else:\n",
    "                            yield batch\n",
    "            else:\n",
    "                with LazyThreadPoolExecutor(max_workers=self.num_workers) as e:\n",
    "                    # avoid py3.6 issue where queue is infinite and can result in memory exhaustion\n",
    "                    for batch in e.map(self.get_batch, iter(self.batch_sampler)): \n",
    "                        if self.collate_fn == self.np_collate: \n",
    "                            yield get_tensor(batch, self.pin_memory, self.half)\n",
    "                        else:\n",
    "                            yield batch\n",
    "#                     # avoid py3.6 issue where queue is infinite and can result in memory exhaustion\n",
    "#                     for c in chunk_iter(iter(self.batch_sampler), self.num_workers*10):\n",
    "#                         for batch in e.map(self.get_batch, c):\n",
    "# #                             yield batch\n",
    "#                             yield get_tensor(batch, self.pin_memory, self.half)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fake_collate(indices):\n",
    "    return torch.ones(512, 3, 32, 32).cuda(), torch.ones(512).long().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfms = tfms_from_stats(stats, sz, aug_tfms=[])\n",
    "# tfms = tfms_from_stats(stats, sz, aug_tfms=[RandomCrop(sz), RandomFlip()], pad=sz//8)\n",
    "zombiedl = ImageClassifierData.from_paths(PATH, val_name='test', tfms=tfms, bs=bs, num_workers=workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_sampler = np.ones((98,2), dtype=np.int).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "collate_fn = torch.utils.data.DataLoader(None).collate_fn\n",
    "tdl = ZombieDataLoader(zombiedl.trn_ds, batch_size=bs, shuffle=True,\n",
    "                 num_workers=workers, pin_memory=True, collate_fn=fake_collate, multiprocess=False, batch_sampler=fake_sampler)\n",
    "vdl = ZombieDataLoader(zombiedl.val_ds, batch_size=bs, shuffle=False,\n",
    "                 num_workers=workers, pin_memory=True, collate_fn=fake_collate, multiprocess=False, batch_sampler=fake_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_collate = torch.utils.data.DataLoader(None).collate_fn\n",
    "# tdl = ZombieDataLoader(zombiedl.trn_ds, batch_size=bs, shuffle=True,\n",
    "#                  num_workers=workers, pin_memory=True, collate_fn=default_collate, multiprocess=False)\n",
    "# vdl = ZombieDataLoader(zombiedl.val_ds, batch_size=bs, shuffle=False,\n",
    "#                  num_workers=workers, pin_memory=True, collate_fn=default_collate, multiprocess=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_batches = len(list(iter(tdl.batch_sampler))); n_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([512, 3, 32, 32]), torch.Size([512]))"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x,y = next(iter(tdl)); x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "zombiedl.trn_dl = tdl\n",
    "zombiedl.val_dl = vdl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = get_learner(zombiedl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6158a2c557c499d965b3d0f25217473",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=2), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                    \n",
      "    0      0.006953   0.0        1.0       \n",
      "    1      0.000844   0.0        1.0                          \n",
      "\n",
      "CPU times: user 48.7 s, sys: 1min 55s, total: 2min 44s\n",
      "Wall time: 24.2 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([0.]), 1.0]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time learn.fit(lrs=1, n_cycle=1, wds=1e-4, cycle_len=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.3.1.post2'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "266px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
