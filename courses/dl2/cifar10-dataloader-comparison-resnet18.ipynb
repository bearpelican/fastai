{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CIFAR 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.conv_learner import *\n",
    "from fastai.models.cifar10.preact_resnet import *\n",
    "torch.backends.cudnn.benchmark = True\n",
    "PATH = Path(\"data/cifar10/\")\n",
    "os.makedirs(PATH,exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "stats = (np.array([ 0.4914 ,  0.48216,  0.44653]), np.array([ 0.24703,  0.24349,  0.26159]))\n",
    "\n",
    "bs=512\n",
    "sz=32\n",
    "workers=7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "\n",
    "def pad(img, p=4, padding_mode='reflect'):\n",
    "        return Image.fromarray(np.pad(np.asarray(img), ((p, p), (p, p), (0, 0)), padding_mode))\n",
    "def to_pil(img): return Image.fromarray(img)\n",
    "\n",
    "def torch_tfms(size, conv_pil=False, to_numpy=False):\n",
    "    mean,std=[0.4914 , 0.48216, 0.44653], [0.24703, 0.24349, 0.26159]\n",
    "    normalize = transforms.Normalize(mean=mean, std=std)\n",
    "    tfms = [transforms.ToTensor(), normalize]\n",
    "    \n",
    "    # Torch transforms with fastai dl\n",
    "    if to_numpy: tfms = [np.array, Normalize(mean,std), lambda x: x[0].T]\n",
    "        \n",
    "    aug_tfms = [\n",
    "        pad, # TODO: use `padding` rather than assuming 4\n",
    "        transforms.RandomCrop(size),\n",
    "        transforms.ColorJitter(.25,.25,.25),\n",
    "        transforms.RandomRotation(2),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "    ]\n",
    "    scale_size = 40\n",
    "    padding = int((scale_size - size) / 2)\n",
    "    \n",
    "    train_tfms = transforms.Compose(aug_tfms + tfms)\n",
    "    train_tfms.sz = size\n",
    "    val_tfms = transforms.Compose(tfms)\n",
    "    val_tfms.sz = size\n",
    "    if conv_pil:\n",
    "        train_tfms.transforms.insert(0, to_pil)\n",
    "        val_tfms.transforms.insert(0, to_pil)\n",
    "    return train_tfms, val_tfms\n",
    "    \n",
    "def torch_ds(data_path, tfms):\n",
    "    train_tfms, val_tfms = tfms\n",
    "    \n",
    "    # Data loading code\n",
    "    traindir = os.path.join(data_path, 'train')\n",
    "    valdir = os.path.join(data_path, 'test')\n",
    "\n",
    "    train_dataset = datasets.ImageFolder(traindir, train_tfms)\n",
    "    val_dataset = datasets.ImageFolder(valdir, val_tfms)\n",
    "    return train_dataset, val_dataset\n",
    "\n",
    "def torch_loader(data_path, datasets):\n",
    "    train_dataset, val_dataset = datasets\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=bs, shuffle=True,\n",
    "        num_workers=workers, pin_memory=True)\n",
    "\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        val_dataset, batch_size=bs*2, shuffle=False,\n",
    "        num_workers=workers, pin_memory=True)\n",
    "\n",
    "    data = ModelData(data_path, train_loader, val_loader)\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_learner(data):\n",
    "    m = PreActResNet18()\n",
    "    learn = ConvLearner.from_model_data(m, data)\n",
    "    learn.crit = nn.CrossEntropyLoss()\n",
    "    learn.metrics = [accuracy]\n",
    "    return learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Torch Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfms = torch_tfms(sz)\n",
    "dsets = torch_ds(PATH, tfms)\n",
    "torch_data = torch_loader(str(PATH), dsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = get_learner(torch_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07d702d4be814ddb9dc3aaff9037244b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                     \n",
      "    0      nan        nan        0.1       \n",
      "\n",
      "CPU times: user 8.38 s, sys: 4.54 s, total: 12.9 s\n",
      "Wall time: 15.9 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([nan]), 0.1]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Warmup session\n",
    "%time learn.fit(lrs=1, n_cycle=1, wds=1e-4, cycle_len=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2556376a2c03415c915bea3e4a5258ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=2), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                \n",
      "    0      nan        nan        0.1       \n",
      "    1      nan        nan        0.1                     \n",
      "\n",
      "CPU times: user 17.1 s, sys: 8.5 s, total: 25.6 s\n",
      "Wall time: 26.9 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([nan]), 0.1]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time learn.fit(lrs=1, n_cycle=1, wds=1e-4, cycle_len=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fastai Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfms = tfms_from_stats(stats, sz, aug_tfms=[RandomCrop(sz), RandomFlip()], pad=sz//8)\n",
    "fastai_data = ImageClassifierData.from_paths(PATH, val_name='test', tfms=tfms, bs=bs, num_workers=workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = get_learner(fastai_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b40ef663355649969f0a399756c16ca8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=2), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                     \n",
      "    0      nan        nan        0.1       \n",
      "    1      nan        nan        0.1                     \n",
      "\n",
      "CPU times: user 1min 50s, sys: 2min 59s, total: 4min 50s\n",
      "Wall time: 47.7 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([nan]), 0.1]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time learn.fit(lrs=1, n_cycle=1, wds=1e-4, cycle_len=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fastai Default Collate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfms = tfms_from_stats(stats, sz, aug_tfms=[RandomCrop(sz), RandomFlip()], pad=sz//8)\n",
    "fastai_dc_data = ImageClassifierData.from_paths(PATH, val_name='test', tfms=tfms, bs=bs, num_workers=workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hack to get the hidden collate function out of the torch dataloader class. \n",
    "collate_fn = torch.utils.data.DataLoader(None).collate_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "fastai_dc_data.trn_dl.collate_fn = collate_fn\n",
    "fastai_dc_data.val_dl.collate_fn = collate_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = get_learner(fastai_dc_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ca576c0846d46648b032f82d5ef0cfb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=2), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/98 [00:00<?, ?it/s]iter called\n",
      "iter called                                                   \n",
      "epoch      trn_loss   val_loss   accuracy   \n",
      "    0      nan        nan        0.1       \n",
      "  0%|          | 0/98 [00:00<?, ?it/s]iter called\n",
      "iter called                                              \n",
      "    1      nan        nan        0.1       \n",
      "\n",
      "CPU times: user 1min 51s, sys: 2min 59s, total: 4min 51s\n",
      "Wall time: 47.8 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([nan]), 0.1]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time learn.fit(lrs=1, n_cycle=1, wds=1e-4, cycle_len=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fastai DataLoader - Torch Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfms = torch_tfms(sz, to_numpy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdl_tds_data = ImageClassifierData.from_paths(PATH, val_name='test', tfms=tfms, bs=bs, num_workers=workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdl_tds_data.trn_ds.open_fn = Image.open\n",
    "fdl_tds_data.val_ds.open_fn = Image.open"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = get_learner(fdl_tds_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce1c74a372d24603a75ad4466918a544",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=2), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                     \n",
      "    0      nan        nan        0.1       \n",
      "    1      nan        nan        0.1                     \n",
      "\n",
      "CPU times: user 2min 55s, sys: 3min 29s, total: 6min 25s\n",
      "Wall time: 2min 12s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([nan]), 0.1]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time learn.fit(lrs=1, n_cycle=1, wds=1e-4, cycle_len=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Torch DataLoader - Fastai Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfms = tfms_from_stats(stats, sz, aug_tfms=[RandomCrop(sz), RandomFlip()], pad=sz//8)\n",
    "fdl = ImageClassifierData.from_paths(PATH, val_name='test', tfms=tfms, bs=bs, num_workers=workers)\n",
    "tdl_fds = fdl.trn_ds, fdl.val_ds\n",
    "torch_data = torch_loader(str(PATH), tdl_fds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = get_learner(torch_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52a6115cf426479c922ede7e70ce637f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=2), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                     \n",
      "    0      nan        nan        0.1       \n",
      "    1      nan        nan        0.1                     \n",
      "\n",
      "CPU times: user 17.1 s, sys: 8.8 s, total: 25.9 s\n",
      "Wall time: 26.4 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([nan]), 0.1]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time learn.fit(lrs=1, n_cycle=1, wds=1e-4, cycle_len=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fastai DataLoader - Torch Dataset - Same as Torch Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from fastai.dataset import FilesArrayDataset, folder_source, read_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfms = torch_tfms(sz, to_numpy=True)\n",
    "dsets = torch_ds(PATH, tfms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdl_tds_data = ImageData(PATH, list(dsets)+[None,None,None,None], bs, num_workers=workers, classes=dsets[0].classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = get_learner(fdl_tds_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time learn.fit(lrs=1, n_cycle=1, wds=1e-4, cycle_len=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "266px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
