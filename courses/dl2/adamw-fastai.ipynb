{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse , os , shutil , time\n",
    "\n",
    "from fastai.transforms import *\n",
    "from fastai.dataset import *\n",
    "from fastai.fp16 import *\n",
    "from fastai.conv_learner import *\n",
    "from pathlib import *\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.distributed as dist\n",
    "import torch.optim\n",
    "import torch.utils.data\n",
    "import torch.utils.data.distributed\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "# import models\n",
    "from datetime import datetime\n",
    "\n",
    "# model_names = sorted(name for name in models.__dict__\n",
    "#                      if name.islower() and not name.startswith(\"__\")\n",
    "#                      and callable(models.__dict__[name]))\n",
    "# print(model_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_parser():\n",
    "    parser = argparse.ArgumentParser(description='PyTorch ImageNet Training')\n",
    "    parser.add_argument('data', metavar='DIR', help='path to dataset')\n",
    "    parser.add_argument('--warmonly', action='store_true', help='Just 1 epoch of each size')\n",
    "    parser.add_argument('--save-dir', type=str, default=Path.home()/'imagenet_training',\n",
    "                        help='Directory to save logs and models.')\n",
    "    # parser.add_argument('--arch', '-a', metavar='ARCH', default='resnet18',\n",
    "    #                     choices=model_names,\n",
    "    #                     help='model architecture: ' +\n",
    "    #                     ' | '.join(model_names) +\n",
    "    #                     ' (default: resnet18)')\n",
    "    parser.add_argument('-j', '--workers', default=8, type=int, metavar='N',\n",
    "                        help='number of data loading workers (default: 4)')\n",
    "    parser.add_argument('--epochs', default=45, type=int, metavar='N',\n",
    "                        help='number of total epochs to run')\n",
    "    parser.add_argument('-b', '--batch-size', default=192, type=int,\n",
    "                        metavar='N', help='mini-batch size (default: 256)')\n",
    "    parser.add_argument('--lr', '--learning-rate', default=0.1, type=float,\n",
    "                        metavar='LR', help='initial learning rate')\n",
    "    parser.add_argument('--schedule', default='0,0.1,0.4,0.47,0.78,0.92,0.95,1', type=str,\n",
    "                        help='Learning rate scheduler warmup -> lr -> upsize -> lr/10 -> upsize -> lr/100 -> lr/1000')\n",
    "    parser.add_argument('--momentum', default=0.9, type=float, metavar='M', help='momentum')\n",
    "    parser.add_argument('--weight-decay', '--wd', default=1e-2, type=float,\n",
    "                        metavar='W', help='weight decay (default: 1e-4)')\n",
    "    parser.add_argument('--print-freq', '-p', default=50, type=int,\n",
    "                        metavar='N', help='print frequency (default: 10)')\n",
    "    parser.add_argument('--pretrained', dest='pretrained', action='store_true', help='use pre-trained model')\n",
    "    parser.add_argument('--fp16', action='store_true', help='Run model fp16 mode.')\n",
    "    parser.add_argument('--sz', default=224, type=int, help='Size of transformed image.')\n",
    "    # parser.add_argument('--decay-int', default=30, type=int, help='Decay LR by 10 every decay-int epochs')\n",
    "    parser.add_argument('--use-clr', type=str,\n",
    "                        help='div,pct,max_mom,min_mom. Pass in a string delimited by commas. Ex: \"20,2,0.95,0.85\"')\n",
    "    parser.add_argument('--loss-scale', type=float, default=1,\n",
    "                        help='Loss scaling, positive power of 2 values can improve fp16 convergence.')\n",
    "    parser.add_argument('--prof', dest='prof', action='store_true', help='Only run a few iters for profiling.')\n",
    "\n",
    "    parser.add_argument('--distributed', action='store_true', help='Run distributed training')\n",
    "    parser.add_argument('--world-size', default=-1, type=int, \n",
    "                        help='Number of gpus per machine. Param only needed for single machine training when using (faster) file sync')\n",
    "    parser.add_argument('--dist-url', default='file://sync.file', type=str,\n",
    "                        help='url used to set up distributed training')\n",
    "    parser.add_argument('--dist-backend', default='nccl', type=str, help='distributed backend')\n",
    "    parser.add_argument('--local_rank', default=0, type=int,\n",
    "                        help='Used for multi-process training. Can either be manually set ' +\n",
    "                        'or automatically set by using \\'python -m multiproc\\'.')\n",
    "    return parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def torch_loader(data_path, size, use_val_sampler=True, min_scale=0.08, max_scale=1.0, bs=192):\n",
    "    traindir = os.path.join(data_path, 'train')\n",
    "    valdir = os.path.join(data_path, 'validation')\n",
    "    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    tensor_tfm = [transforms.ToTensor(), normalize]\n",
    "\n",
    "    train_dataset = datasets.ImageFolder(\n",
    "        traindir, transforms.Compose([\n",
    "            transforms.RandomResizedCrop(size, scale=(min_scale, max_scale)),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "        ] + tensor_tfm))\n",
    "    val_dataset = datasets.ImageFolder(\n",
    "        valdir, transforms.Compose([\n",
    "            transforms.Resize(int(size*1.14)),\n",
    "            transforms.CenterCrop(size),\n",
    "        ] + tensor_tfm))\n",
    "\n",
    "    train_sampler = (torch.utils.data.distributed.DistributedSampler(train_dataset) if args.distributed else None)\n",
    "    val_sampler = (torch.utils.data.distributed.DistributedSampler(val_dataset) if args.distributed and use_val_sampler else None)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=bs, shuffle=(train_sampler is None),\n",
    "        num_workers=args.workers, pin_memory=True, sampler=train_sampler)\n",
    "\n",
    "    val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=bs, shuffle=False,\n",
    "        num_workers=args.workers, pin_memory=True, sampler=val_sampler)\n",
    "\n",
    "    data = ModelData(data_path, train_loader, val_loader)\n",
    "    data.sz = size\n",
    "    if train_sampler is not None: data.trn_sampler = train_sampler\n",
    "    if val_sampler is not None: data.val_sampler = val_sampler\n",
    "    return data\n",
    "\n",
    "# Seems to speed up training by ~2%\n",
    "class DataPrefetcher():\n",
    "    def __init__(self, loader, stop_after=None):\n",
    "        self.loader = loader\n",
    "        self.dataset = loader.dataset\n",
    "        self.stream = torch.cuda.Stream()\n",
    "        self.stop_after = stop_after\n",
    "        self.next_input = None\n",
    "        self.next_target = None\n",
    "\n",
    "    def __len__(self): return len(self.loader)\n",
    "\n",
    "    def preload(self):\n",
    "        try:\n",
    "            self.next_input, self.next_target = next(self.loaditer)\n",
    "        except StopIteration:\n",
    "            self.next_input = None\n",
    "            self.next_target = None\n",
    "            return\n",
    "        with torch.cuda.stream(self.stream):\n",
    "            self.next_input = self.next_input.cuda(async=True)\n",
    "            self.next_target = self.next_target.cuda(async=True)\n",
    "\n",
    "    def __iter__(self):\n",
    "        count = 0\n",
    "        self.loaditer = iter(self.loader)\n",
    "        self.preload()\n",
    "        while self.next_input is not None:\n",
    "            torch.cuda.current_stream().wait_stream(self.stream)\n",
    "            input = self.next_input\n",
    "            target = self.next_target\n",
    "            self.preload()\n",
    "            count += 1\n",
    "            yield input, target\n",
    "            if type(self.stop_after) is int and (count > self.stop_after):\n",
    "                break\n",
    "\n",
    "\n",
    "def top5(output, target):\n",
    "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
    "    top5 = 5\n",
    "    batch_size = target.size(0)\n",
    "    _, pred = output.topk(top5, 1, True, True)\n",
    "    pred = pred.t()\n",
    "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "    correct_k = correct[:top5].view(-1).float().sum(0, keepdim=True)\n",
    "    return correct_k.mul_(1.0 / batch_size)\n",
    "\n",
    "class ImagenetLoggingCallback(Callback):\n",
    "    start_time = 0\n",
    "    def __init__(self, save_path, print_every=50):\n",
    "        super().__init__()\n",
    "        self.save_path=save_path\n",
    "        self.print_every=print_every\n",
    "        self.start_time = datetime.now()\n",
    "    def on_train_begin(self):\n",
    "        self.batch = 0\n",
    "        self.epoch = 0\n",
    "        self.f = open(self.save_path, \"a\", 1)   \n",
    "        self.log(\"epoch\\thours\\tAccuracy\\ttop1Accuracy\\ttop5Accuracy\")\n",
    "    def on_epoch_end(self, metrics):\n",
    "        current_time = datetime.now()\n",
    "        time_diff = current_time - self.start_time\n",
    "        log_str = f'{self.epoch}\\t{float(time_diff.total_seconds() / 3600.0)}\\t{metrics[1]}\\t{metrics[2]}\\t{metrics[3]}'\n",
    "        self.log(log_str)\n",
    "        self.epoch += 1\n",
    "    def on_batch_end(self, metrics):\n",
    "        self.last_loss = metrics\n",
    "        self.batch += 1\n",
    "    def on_train_end(self): self.f.close()\n",
    "    def log(self, string): self.f.write(string+\"\\n\")\n",
    "\n",
    "def save_args(name, save_dir):\n",
    "    if (args.local_rank != 0) or not args.save_dir: return {}\n",
    "\n",
    "    log_dir = f'{save_dir}/training_logs'\n",
    "    os.makedirs(log_dir, exist_ok=True)\n",
    "    return {\n",
    "        'best_save_name': f'{name}_best_model',\n",
    "        'callbacks': [\n",
    "            ImagenetLoggingCallback(f'{log_dir}/{name}_log.txt', args.print_freq)\n",
    "        ]\n",
    "    }\n",
    "\n",
    "def save_sched(sched, save_dir):\n",
    "    if (args.local_rank != 0) or not args.save_dir: return {}\n",
    "    log_dir = f'{save_dir}/training_logs'\n",
    "    sched.save_path = log_dir\n",
    "    sched.plot_loss()\n",
    "    sched.plot_lr()\n",
    "\n",
    "def update_model_dir(learner, base_dir):\n",
    "    learner.tmp_path = f'{base_dir}/tmp'\n",
    "    os.makedirs(learner.tmp_path, exist_ok=True)\n",
    "    learner.models_path = f'{base_dir}/models'\n",
    "    os.makedirs(learner.models_path, exist_ok=True)\n",
    "\n",
    "def top_k(output, target, k=5):\n",
    "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
    "    batch_size = target.size(0)\n",
    "    _, pred = output.topk(k, 1, True, True)\n",
    "    pred = pred.t()\n",
    "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "    correct_k = correct[:k].view(-1).float().sum(0, keepdim=True)\n",
    "    return correct_k.mul_(1.0 / batch_size)\n",
    "\n",
    "def top1(output, target): return top_k(output, target, 1)\n",
    "def top5(output, target): return top_k(output, target, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running script with args: Namespace(batch_size=192, data='/home/paperspace/data/imagenet', dist_backend='nccl', dist_url='file://sync.file', distributed=False, epochs=45, fp16=True, local_rank=0, loss_scale=512.0, lr=0.1, momentum=0.9, pretrained=False, print_freq=50, prof=False, save_dir=PosixPath('/home/paperspace/imagenet_training'), schedule=[0.0, 0.1, 0.4, 0.47, 0.78, 0.92, 0.95, 1.0], sz=224, use_clr=None, warmonly=False, weight_decay=0.01, workers=8, world_size=-1)\n"
     ]
    }
   ],
   "source": [
    "cudnn.benchmark = True\n",
    "args = get_parser().parse_args(['/home/paperspace/data/imagenet', '--fp16', '--loss-scale', '512'])\n",
    "if args.local_rank > 0: sys.stdout = open(f'{args.save_dir}/GPU_{args.local_rank}.log', 'w')\n",
    "if isinstance(args.schedule, str): args.schedule = [float(i) for i in args.schedule.split(',')]\n",
    "print('Running script with args:', args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.distributed:\n",
    "    torch.cuda.set_device(args.local_rank)\n",
    "    dist.init_process_group(backend=args.dist_backend, init_method=args.dist_url, world_size=args.world_size)\n",
    "    assert(args.world_size == dist.get_world_size())\n",
    "\n",
    "# if args.pretrained: model = models.__dict__[args.arch](pretrained=True)\n",
    "# else:               model = models.__dict__[args.arch]()\n",
    "# import resnet\n",
    "from fastai.models import resnet\n",
    "\n",
    "model = resnet.resnet50()\n",
    "\n",
    "model = model.cuda()\n",
    "if args.fp16: model = FP16(model) # Seeing if half precision works if we set it before DistributedDataParallel\n",
    "if args.distributed: model = nn.parallel.DistributedDataParallel(model, device_ids=[args.local_rank], output_device=args.local_rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data1 = torch_loader(f'{args.data}-sz/320', size=args.sz, bs=192) # AS Try this laters\n",
    "data1 = torch_loader(args.data, size=args.sz, bs=192) # AS Try this laters\n",
    "learner = Learner.from_model_data(model, data1)\n",
    "learner.crit = F.cross_entropy\n",
    "learner.metrics = [accuracy, top1, top5]\n",
    "if args.fp16: learner.half()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db1b4a82e39c4b9f9addd438a3a26877",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 16%|█▋        | 1092/6673 [05:43<29:15,  3.18it/s, loss=6.94]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/PIL/TiffImagePlugin.py:739: UserWarning: Possibly corrupt EXIF data.  Expecting to read 2555904 bytes but only got 0. Skipping tag 0\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 19%|█▊        | 1245/6673 [06:30<28:24,  3.19it/s, loss=6.93]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/PIL/TiffImagePlugin.py:756: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 0. \n",
      "  warnings.warn(str(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 1730/6673 [08:57<25:36,  3.22it/s, loss=6.89]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/PIL/TiffImagePlugin.py:739: UserWarning: Possibly corrupt EXIF data.  Expecting to read 2555904 bytes but only got 0. Skipping tag 0\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 2104/6673 [10:53<23:38,  3.22it/s, loss=6.88]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/PIL/TiffImagePlugin.py:739: UserWarning: Possibly corrupt EXIF data.  Expecting to read 2555904 bytes but only got 0. Skipping tag 0\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 2130/6673 [11:00<23:29,  3.22it/s, loss=6.88]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/PIL/TiffImagePlugin.py:739: UserWarning: Possibly corrupt EXIF data.  Expecting to read 2555904 bytes but only got 0. Skipping tag 0\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 44%|████▎     | 2903/6673 [14:56<19:23,  3.24it/s, loss=6.85]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/PIL/TiffImagePlugin.py:739: UserWarning: Possibly corrupt EXIF data.  Expecting to read 1835008 bytes but only got 0. Skipping tag 0\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 45%|████▍     | 2978/6673 [15:19<19:00,  3.24it/s, loss=6.82]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/PIL/TiffImagePlugin.py:739: UserWarning: Possibly corrupt EXIF data.  Expecting to read 2555904 bytes but only got 0. Skipping tag 0\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 5372/6673 [27:26<06:38,  3.26it/s, loss=6.89]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/PIL/TiffImagePlugin.py:739: UserWarning: Possibly corrupt EXIF data.  Expecting to read 19660800 bytes but only got 0. Skipping tag 0\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/PIL/TiffImagePlugin.py:739: UserWarning: Possibly corrupt EXIF data.  Expecting to read 18481152 bytes but only got 0. Skipping tag 0\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/PIL/TiffImagePlugin.py:739: UserWarning: Possibly corrupt EXIF data.  Expecting to read 37093376 bytes but only got 0. Skipping tag 0\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/PIL/TiffImagePlugin.py:739: UserWarning: Possibly corrupt EXIF data.  Expecting to read 39976960 bytes but only got 0. Skipping tag 0\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/PIL/TiffImagePlugin.py:739: UserWarning: Possibly corrupt EXIF data.  Expecting to read 34865152 bytes but only got 0. Skipping tag 0\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/PIL/TiffImagePlugin.py:756: UserWarning: Corrupt EXIF data.  Expecting to read 12 bytes but only got 10. \n",
      "  warnings.warn(str(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 6194/6673 [31:36<02:26,  3.27it/s, loss=6.91]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/PIL/TiffImagePlugin.py:739: UserWarning: Possibly corrupt EXIF data.  Expecting to read 2555904 bytes but only got 0. Skipping tag 0\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-7:\n",
      "Process Process-10:\n",
      "Process Process-5:\n",
      "Process Process-12:\n",
      "Process Process-2:\n",
      "Process Process-4:\n",
      "Process Process-8:\n",
      "Traceback (most recent call last):\n",
      "Process Process-16:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Process Process-1:\n",
      "Process Process-3:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Process Process-6:\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Process Process-11:\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Process Process-9:\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 57, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 57, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 57, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torchvision/datasets/folder.py\", line 101, in __getitem__\n",
      "    sample = self.loader(path)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 57, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torchvision/datasets/folder.py\", line 147, in default_loader\n",
      "    return pil_loader(path)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torchvision/datasets/folder.py\", line 101, in __getitem__\n",
      "    sample = self.loader(path)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 57, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torchvision/datasets/folder.py\", line 130, in pil_loader\n",
      "    return img.convert('RGB')\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torchvision/datasets/folder.py\", line 147, in default_loader\n",
      "    return pil_loader(path)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 57, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Process Process-13:\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torchvision/datasets/folder.py\", line 130, in pil_loader\n",
      "    return img.convert('RGB')\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 57, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "Traceback (most recent call last):\n",
      "Process Process-14:\n",
      "KeyboardInterrupt\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/PIL/Image.py\", line 879, in convert\n",
      "    self.load()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 57, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/PIL/Image.py\", line 879, in convert\n",
      "    self.load()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/PIL/ImageFile.py\", line 231, in load\n",
      "    n, err_code = decoder.decode(b)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torchvision/datasets/folder.py\", line 103, in __getitem__\n",
      "    sample = self.transform(sample)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torchvision/transforms/transforms.py\", line 49, in __call__\n",
      "    img = t(img)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torchvision/transforms/transforms.py\", line 175, in __call__\n",
      "    return F.resize(img, self.size, self.interpolation)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torchvision/transforms/functional.py\", line 200, in resize\n",
      "    return img.resize((ow, oh), interpolation)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/PIL/ImageFile.py\", line 215, in load\n",
      "    s = read(self.decodermaxblock)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/PIL/JpegImagePlugin.py\", line 362, in load_read\n",
      "    s = self.fp.read(read_bytes)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/PIL/Image.py\", line 1749, in resize\n",
      "    return self._new(self.im.resize(size, resample, box))\n",
      "KeyboardInterrupt\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 57, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "KeyboardInterrupt\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torchvision/datasets/folder.py\", line 103, in __getitem__\n",
      "    sample = self.transform(sample)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 57, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torchvision/transforms/transforms.py\", line 49, in __call__\n",
      "    img = t(img)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torchvision/transforms/transforms.py\", line 76, in __call__\n",
      "    return F.to_tensor(pic)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torchvision/datasets/folder.py\", line 101, in __getitem__\n",
      "    sample = self.loader(path)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torchvision/transforms/functional.py\", line 70, in to_tensor\n",
      "    img = torch.ByteTensor(torch.ByteStorage.from_buffer(pic.tobytes()))\n",
      "KeyboardInterrupt\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torchvision/datasets/folder.py\", line 147, in default_loader\n",
      "    return pil_loader(path)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "KeyboardInterrupt\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torchvision/datasets/folder.py\", line 130, in pil_loader\n",
      "    return img.convert('RGB')\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 57, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 57, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 57, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "Process Process-15:\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/PIL/Image.py\", line 879, in convert\n",
      "    self.load()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torchvision/datasets/folder.py\", line 101, in __getitem__\n",
      "    sample = self.loader(path)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 57, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 138, in default_collate\n",
      "    return [default_collate(samples) for samples in transposed]\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 57, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 138, in <listcomp>\n",
      "    return [default_collate(samples) for samples in transposed]\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torchvision/datasets/folder.py\", line 101, in __getitem__\n",
      "    sample = self.loader(path)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 115, in default_collate\n",
      "    return torch.stack(batch, 0, out=out)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torchvision/datasets/folder.py\", line 147, in default_loader\n",
      "    return pil_loader(path)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torchvision/datasets/folder.py\", line 147, in default_loader\n",
      "    return pil_loader(path)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torchvision/datasets/folder.py\", line 130, in pil_loader\n",
      "    return img.convert('RGB')\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torchvision/datasets/folder.py\", line 130, in pil_loader\n",
      "    return img.convert('RGB')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-8-6b0752a6d199>\", line 1, in <module>\n",
      "    learner.lr_find(wds=1e-2)\n",
      "  File \"/home/paperspace/fastai/courses/dl2/fastai/learner.py\", line 341, in lr_find\n",
      "    self.fit_gen(self.model, self.data, layer_opt, 1, **kwargs)\n",
      "  File \"/home/paperspace/fastai/courses/dl2/fastai/learner.py\", line 245, in fit_gen\n",
      "    swa_eval_freq=swa_eval_freq, **kwargs)\n",
      "  File \"/home/paperspace/fastai/courses/dl2/fastai/model.py\", line 162, in fit\n",
      "    vals = validate(model_stepper, cur_data.val_dl, metrics, seq_first=seq_first)\n",
      "  File \"/home/paperspace/fastai/courses/dl2/fastai/model.py\", line 238, in validate\n",
      "    loss.append(to_np(l))\n",
      "  File \"/home/paperspace/fastai/courses/dl2/fastai/core.py\", line 67, in to_np\n",
      "    return v.cpu().numpy()\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 1863, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 1095, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 311, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 345, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/inspect.py\", line 1483, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/inspect.py\", line 1441, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/inspect.py\", line 742, in getmodule\n",
      "    os.path.realpath(f)] = module.__name__\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/posixpath.py\", line 388, in realpath\n",
      "    path, ok = _joinrealpath(filename[:0], filename, {})\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/posixpath.py\", line 422, in _joinrealpath\n",
      "    if not islink(newpath):\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/posixpath.py\", line 171, in islink\n",
      "    st = os.lstat(path)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 178, in handler\n",
      "    _error_if_any_worker_fails()\n",
      "RuntimeError: DataLoader worker (pid 2728) exited unexpectedly with exit code 1.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "KeyboardInterrupt\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/PIL/Image.py\", line 879, in convert\n",
      "    self.load()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/PIL/Image.py\", line 888, in convert\n",
      "    return self.copy()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/PIL/Image.py\", line 1057, in copy\n",
      "    return self._new(self.im.copy())\n",
      "KeyboardInterrupt\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/PIL/ImageFile.py\", line 231, in load\n",
      "    n, err_code = decoder.decode(b)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/PIL/ImageFile.py\", line 231, in load\n",
      "    n, err_code = decoder.decode(b)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "learner.lr_find(wds=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learner.sched.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data1 = torch_loader(f'{args.data}-sz/320', size=args.sz, bs=192) # AS Try this laters\n",
    "data1 = torch_loader(args.data, size=args.sz, bs=192) # AS Try this laters\n",
    "learner = Learner.from_model_data(model, data1)\n",
    "learner.crit = F.cross_entropy\n",
    "learner.metrics = [accuracy, top1, top5]\n",
    "if args.fp16: learner.half()\n",
    "learner.opt_fn = partial(optim.Adam, betas=(0.95,0.99))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c7e796dca044e4aa803bded7afcc2e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 1013/6673 [05:05<28:26,  3.32it/s, loss=7.08]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/PIL/TiffImagePlugin.py:739: UserWarning: Possibly corrupt EXIF data.  Expecting to read 1835008 bytes but only got 0. Skipping tag 0\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 1331/6673 [06:41<26:52,  3.31it/s, loss=7.06]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/PIL/TiffImagePlugin.py:739: UserWarning: Possibly corrupt EXIF data.  Expecting to read 2555904 bytes but only got 0. Skipping tag 0\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 21%|██        | 1369/6673 [06:52<26:39,  3.32it/s, loss=7.05]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/PIL/TiffImagePlugin.py:739: UserWarning: Possibly corrupt EXIF data.  Expecting to read 2555904 bytes but only got 0. Skipping tag 0\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 1541/6673 [07:43<25:43,  3.32it/s, loss=7.04]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/PIL/TiffImagePlugin.py:739: UserWarning: Possibly corrupt EXIF data.  Expecting to read 2555904 bytes but only got 0. Skipping tag 0\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 1746/6673 [08:45<24:44,  3.32it/s, loss=7.02]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/PIL/TiffImagePlugin.py:739: UserWarning: Possibly corrupt EXIF data.  Expecting to read 2555904 bytes but only got 0. Skipping tag 0\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 2863/6673 [14:22<19:08,  3.32it/s, loss=6.86]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/PIL/TiffImagePlugin.py:739: UserWarning: Possibly corrupt EXIF data.  Expecting to read 19660800 bytes but only got 0. Skipping tag 0\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/PIL/TiffImagePlugin.py:739: UserWarning: Possibly corrupt EXIF data.  Expecting to read 18481152 bytes but only got 0. Skipping tag 0\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/PIL/TiffImagePlugin.py:739: UserWarning: Possibly corrupt EXIF data.  Expecting to read 37093376 bytes but only got 0. Skipping tag 0\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/PIL/TiffImagePlugin.py:739: UserWarning: Possibly corrupt EXIF data.  Expecting to read 39976960 bytes but only got 0. Skipping tag 0\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/PIL/TiffImagePlugin.py:739: UserWarning: Possibly corrupt EXIF data.  Expecting to read 34865152 bytes but only got 0. Skipping tag 0\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/PIL/TiffImagePlugin.py:756: UserWarning: Corrupt EXIF data.  Expecting to read 12 bytes but only got 10. \n",
      "  warnings.warn(str(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 3518/6673 [17:39<15:50,  3.32it/s, loss=6.74]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/PIL/TiffImagePlugin.py:739: UserWarning: Possibly corrupt EXIF data.  Expecting to read 2555904 bytes but only got 0. Skipping tag 0\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 5598/6673 [28:14<05:25,  3.30it/s, loss=6.05]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/PIL/TiffImagePlugin.py:739: UserWarning: Possibly corrupt EXIF data.  Expecting to read 2555904 bytes but only got 0. Skipping tag 0\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 96%|█████████▋| 6439/6673 [32:27<01:10,  3.31it/s, loss=6.94]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/PIL/TiffImagePlugin.py:756: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 0. \n",
      "  warnings.warn(str(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-6:\n",
      "Process Process-4:\n",
      "Process Process-8:\n",
      "Process Process-12:\n",
      "Process Process-10:\n",
      "Process Process-11:\n",
      "Traceback (most recent call last):\n",
      "Process Process-3:\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "Process Process-1:\n",
      "Process Process-7:\n",
      "Process Process-2:\n",
      "Process Process-5:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Process Process-16:\n",
      "Process Process-9:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 57, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 57, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 57, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torchvision/datasets/folder.py\", line 101, in __getitem__\n",
      "    sample = self.loader(path)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 57, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torchvision/datasets/folder.py\", line 147, in default_loader\n",
      "    return pil_loader(path)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "Process Process-14:\n",
      "Process Process-15:\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 57, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torchvision/datasets/folder.py\", line 101, in __getitem__\n",
      "    sample = self.loader(path)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 57, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 57, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torchvision/datasets/folder.py\", line 130, in pil_loader\n",
      "    return img.convert('RGB')\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torchvision/datasets/folder.py\", line 147, in default_loader\n",
      "    return pil_loader(path)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 57, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "KeyboardInterrupt\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/PIL/Image.py\", line 879, in convert\n",
      "    self.load()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 57, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 57, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "KeyboardInterrupt\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torchvision/datasets/folder.py\", line 130, in pil_loader\n",
      "    return img.convert('RGB')\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torchvision/datasets/folder.py\", line 101, in __getitem__\n",
      "    sample = self.loader(path)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torchvision/datasets/folder.py\", line 103, in __getitem__\n",
      "    sample = self.transform(sample)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/PIL/ImageFile.py\", line 231, in load\n",
      "    n, err_code = decoder.decode(b)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torchvision/datasets/folder.py\", line 101, in __getitem__\n",
      "    sample = self.loader(path)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torchvision/datasets/folder.py\", line 147, in default_loader\n",
      "    return pil_loader(path)\n",
      "Process Process-13:\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 57, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "KeyboardInterrupt\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/PIL/Image.py\", line 879, in convert\n",
      "    self.load()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torchvision/datasets/folder.py\", line 130, in pil_loader\n",
      "    return img.convert('RGB')\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 57, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 57, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torchvision/datasets/folder.py\", line 101, in __getitem__\n",
      "    sample = self.loader(path)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torchvision/datasets/folder.py\", line 147, in default_loader\n",
      "    return pil_loader(path)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torchvision/datasets/folder.py\", line 129, in pil_loader\n",
      "    img = Image.open(f)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/PIL/Image.py\", line 879, in convert\n",
      "    self.load()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/PIL/ImageFile.py\", line 215, in load\n",
      "    s = read(self.decodermaxblock)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torchvision/transforms/transforms.py\", line 49, in __call__\n",
      "    img = t(img)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/PIL/Image.py\", line 2557, in open\n",
      "    prefix = fp.read(16)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/PIL/JpegImagePlugin.py\", line 362, in load_read\n",
      "    s = self.fp.read(read_bytes)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/PIL/ImageFile.py\", line 231, in load\n",
      "    n, err_code = decoder.decode(b)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 57, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torchvision/datasets/folder.py\", line 101, in __getitem__\n",
      "    sample = self.loader(path)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torchvision/datasets/folder.py\", line 147, in default_loader\n",
      "    return pil_loader(path)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 57, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 57, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "KeyboardInterrupt\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torchvision/transforms/transforms.py\", line 175, in __call__\n",
      "    return F.resize(img, self.size, self.interpolation)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torchvision/datasets/folder.py\", line 147, in default_loader\n",
      "    return pil_loader(path)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torchvision/datasets/folder.py\", line 130, in pil_loader\n",
      "    return img.convert('RGB')\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torchvision/datasets/folder.py\", line 129, in pil_loader\n",
      "    img = Image.open(f)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/PIL/Image.py\", line 879, in convert\n",
      "    self.load()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torchvision/transforms/functional.py\", line 204, in resize\n",
      "    return img.resize((ow, oh), interpolation)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/PIL/Image.py\", line 2557, in open\n",
      "    prefix = fp.read(16)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torchvision/datasets/folder.py\", line 101, in __getitem__\n",
      "    sample = self.loader(path)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/PIL/ImageFile.py\", line 231, in load\n",
      "    n, err_code = decoder.decode(b)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/PIL/Image.py\", line 1749, in resize\n",
      "    return self._new(self.im.resize(size, resample, box))\n",
      "KeyboardInterrupt\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torchvision/datasets/folder.py\", line 147, in default_loader\n",
      "    return pil_loader(path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-8-182c9c719888>\", line 1, in <module>\n",
      "    learner.lr_find(wds=1e-3, start_lr=1e-8, end_lr=1e-1, use_wd_sched=True)\n",
      "  File \"/home/paperspace/fastai/courses/dl2/fastai/learner.py\", line 341, in lr_find\n",
      "    self.fit_gen(self.model, self.data, layer_opt, 1, **kwargs)\n",
      "  File \"/home/paperspace/fastai/courses/dl2/fastai/learner.py\", line 245, in fit_gen\n",
      "    swa_eval_freq=swa_eval_freq, **kwargs)\n",
      "  File \"/home/paperspace/fastai/courses/dl2/fastai/model.py\", line 162, in fit\n",
      "    vals = validate(model_stepper, cur_data.val_dl, metrics, seq_first=seq_first)\n",
      "  File \"/home/paperspace/fastai/courses/dl2/fastai/model.py\", line 238, in validate\n",
      "    loss.append(to_np(l))\n",
      "  File \"/home/paperspace/fastai/courses/dl2/fastai/core.py\", line 67, in to_np\n",
      "    return v.cpu().numpy()\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 1863, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 1095, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 311, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 345, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/inspect.py\", line 1483, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/inspect.py\", line 1441, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/inspect.py\", line 739, in getmodule\n",
      "    f = getabsfile(module)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/inspect.py\", line 708, in getabsfile\n",
      "    _filename = getsourcefile(object) or getfile(object)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/inspect.py\", line 693, in getsourcefile\n",
      "    if os.path.exists(filename):\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/genericpath.py\", line 19, in exists\n",
      "    os.stat(path)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 178, in handler\n",
      "    _error_if_any_worker_fails()\n",
      "RuntimeError: DataLoader worker (pid 7562) exited unexpectedly with exit code 1.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torchvision/datasets/folder.py\", line 130, in pil_loader\n",
      "    return img.convert('RGB')\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/PIL/Image.py\", line 879, in convert\n",
      "    self.load()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/PIL/ImageFile.py\", line 231, in load\n",
      "    n, err_code = decoder.decode(b)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "learner.lr_find(wds=1e-3, start_lr=1e-8, end_lr=1e-1, use_wd_sched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learner.sched.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learner.sched.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.prof: args.epochs = 1\n",
    "if args.use_clr: args.use_clr = tuple(map(float, args.use_clr.split(',')))\n",
    "data0 = torch_loader(f'{args.data}-sz/160', size=128, bs=256)\n",
    "data2 = torch_loader(args.data, size=288, bs=128, min_scale=0.5)\n",
    "data3 = torch_loader(args.data, size=288, bs=128, min_scale=0.5, use_val_sampler=False)\n",
    "\n",
    "update_model_dir(learner, args.save_dir)\n",
    "sargs = save_args('first_run', args.save_dir)\n",
    "# opt_fn = partial(optim.Adam, betas=(0.95,0.99))\n",
    "# def_phase = {'opt_fn':opt_fn, 'wds':args.weight_decay}\n",
    "# def_phase = {'opt_fn':opt_fn, 'wds':args.weight_decay}\n",
    "opt_fn = partial(optim.SGD, momentum=args.momentum)\n",
    "def_phase = {'opt_fn':opt_fn, 'wds':args.weight_decay}\n",
    "lr = args.lr\n",
    "# epoch_sched = [int(args.epochs*o+0.5) for o in (0, 0.1, 0.4, 0.47, 0.78, 0.92, 0.95, 1)]\n",
    "epoch_sched = [int(args.epochs*o+0.5) for o in args.schedule]\n",
    "# epoch_sched = [int(args.epochs*o+0.5) for o in (0, 0.3, 0.45, 0.52, 0.82, 0.92, 0.95, 1)]\n",
    "num_epochs = [epoch_sched[n]-epoch_sched[n-1] for n in range(1,len(epoch_sched))]\n",
    "if args.warmonly:\n",
    "    data = [data0,data1]\n",
    "    phases = [\n",
    "        TrainingPhase(**def_phase, epochs=1, lr=(lr/100,lr), lr_decay=DecayType.LINEAR),\n",
    "        TrainingPhase(**def_phase, epochs=1, lr=(lr,lr/100), lr_decay=DecayType.LINEAR)]\n",
    "else:\n",
    "    data = [data0,data0,data1,data1,data1,data2,data3]\n",
    "    phases = [\n",
    "        TrainingPhase(**def_phase, epochs=num_epochs[0], lr=(lr/20,lr), lr_decay=DecayType.LINEAR),\n",
    "        TrainingPhase(**def_phase, epochs=num_epochs[1], lr=lr),\n",
    "        TrainingPhase(**def_phase, epochs=num_epochs[2], lr=lr),\n",
    "        TrainingPhase(**def_phase, epochs=num_epochs[3],   lr=lr/10),\n",
    "        TrainingPhase(**def_phase, epochs=num_epochs[4], lr=lr/100),\n",
    "        TrainingPhase(**def_phase, epochs=num_epochs[5], lr=lr/100),\n",
    "        TrainingPhase(**def_phase, epochs=num_epochs[6],   lr=lr/1000)]\n",
    "\n",
    "# getting out of memory. Maybe we need to collect memory?\n",
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "learner.fit_opt_sched(phases, data_list=data, loss_scale=args.loss_scale, **sargs)\n",
    "save_sched(learner.sched, args.save_dir)\n",
    "\n",
    "print('Finished!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
