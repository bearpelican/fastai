{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CIFAR 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.conv_learner import *\n",
    "from fastai.models.cifar10.wideresnet import wrn_22\n",
    "torch.backends.cudnn.benchmark = True\n",
    "PATH = Path(\"data/cifar10/\")\n",
    "os.makedirs(PATH,exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "stats = (np.array([ 0.4914 ,  0.48216,  0.44653]), np.array([ 0.24703,  0.24349,  0.26159]))\n",
    "\n",
    "bs=512\n",
    "sz=32\n",
    "workers=7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "\n",
    "def pad(img, p=4, padding_mode='reflect'):\n",
    "        return Image.fromarray(np.pad(np.asarray(img), ((p, p), (p, p), (0, 0)), padding_mode))\n",
    "def to_pil(img): return Image.fromarray(img)\n",
    "\n",
    "def torch_tfms(size, conv_pil=False, to_numpy=False):\n",
    "    mean,std=[0.4914 , 0.48216, 0.44653], [0.24703, 0.24349, 0.26159]\n",
    "    normalize = transforms.Normalize(mean=mean, std=std)\n",
    "    tfms = [transforms.ToTensor(), normalize]\n",
    "    \n",
    "    # Torch transforms with fastai dl\n",
    "    if to_numpy: tfms = [np.array, Normalize(mean,std), lambda x: x[0].T]\n",
    "        \n",
    "    aug_tfms = [\n",
    "        pad, # TODO: use `padding` rather than assuming 4\n",
    "        transforms.RandomCrop(size),\n",
    "        transforms.ColorJitter(.25,.25,.25),\n",
    "        transforms.RandomRotation(2),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "    ]\n",
    "    scale_size = 40\n",
    "    padding = int((scale_size - size) / 2)\n",
    "    \n",
    "    train_tfms = transforms.Compose(aug_tfms + tfms)\n",
    "    train_tfms.sz = size\n",
    "    val_tfms = transforms.Compose(tfms)\n",
    "    val_tfms.sz = size\n",
    "    if conv_pil:\n",
    "        train_tfms.transforms.insert(0, to_pil)\n",
    "        val_tfms.transforms.insert(0, to_pil)\n",
    "    return train_tfms, val_tfms\n",
    "    \n",
    "def torch_ds(data_path, tfms):\n",
    "    train_tfms, val_tfms = tfms\n",
    "    \n",
    "    # Data loading code\n",
    "    traindir = os.path.join(data_path, 'train')\n",
    "    valdir = os.path.join(data_path, 'test')\n",
    "\n",
    "    train_dataset = datasets.ImageFolder(traindir, train_tfms)\n",
    "    val_dataset = datasets.ImageFolder(valdir, val_tfms)\n",
    "    return train_dataset, val_dataset\n",
    "\n",
    "def torch_loader(data_path, datasets):\n",
    "    train_dataset, val_dataset = datasets\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=bs, shuffle=True,\n",
    "        num_workers=workers, pin_memory=True)\n",
    "\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        val_dataset, batch_size=bs*2, shuffle=False,\n",
    "        num_workers=workers, pin_memory=True)\n",
    "\n",
    "    data = ModelData(data_path, train_loader, val_loader)\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_learner(data):\n",
    "    m = wrn_22()\n",
    "    learn = ConvLearner.from_model_data(m, data)\n",
    "    learn.crit = nn.CrossEntropyLoss()\n",
    "    learn.metrics = [accuracy]\n",
    "    return learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Torch Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfms = torch_tfms(sz)\n",
    "dsets = torch_ds(PATH, tfms)\n",
    "torch_data = torch_loader(str(PATH), dsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = get_learner(torch_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f82491a0bae4130ab53d29fc04b7f6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                 \n",
      "    0      2.220326   2.10418    0.1978    \n",
      "\n",
      "CPU times: user 17.8 s, sys: 9.77 s, total: 27.6 s\n",
      "Wall time: 31.4 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([2.10418]), 0.1978]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Warmup session\n",
    "%time learn.fit(lrs=1, n_cycle=1, wds=1e-4, cycle_len=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c35eaa1a287d400282589a67fc3547cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=2), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                 \n",
      "    0      2.009644   1.923166   0.2344    \n",
      "    1      1.914014   1.838584   0.2715                   \n",
      "\n",
      "CPU times: user 34.6 s, sys: 18.7 s, total: 53.4 s\n",
      "Wall time: 54.9 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([1.83858]), 0.2714999995946884]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time learn.fit(lrs=1, n_cycle=1, wds=1e-4, cycle_len=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fastai Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfms = tfms_from_stats(stats, sz, aug_tfms=[RandomCrop(sz), RandomFlip()], pad=sz//8)\n",
    "fastai_data = ImageClassifierData.from_paths(PATH, val_name='test', tfms=tfms, bs=bs, num_workers=workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = get_learner(fastai_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "698f998c0cf749ceb7e883f3bc0aece2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=2), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                 \n",
      "    0      2.31463    2.272603   0.1246    \n",
      "    1      2.161199   2.113671   0.1875                   \n",
      "\n",
      "CPU times: user 2min 15s, sys: 3min 42s, total: 5min 57s\n",
      "Wall time: 1min 6s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([2.11367]), 0.187500000166893]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time learn.fit(lrs=1, n_cycle=1, wds=1e-4, cycle_len=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fastai Default Collate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfms = tfms_from_stats(stats, sz, aug_tfms=[RandomCrop(sz), RandomFlip()], pad=sz//8)\n",
    "fastai_dc_data = ImageClassifierData.from_paths(PATH, val_name='test', tfms=tfms, bs=bs, num_workers=workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hack to get the hidden collate function out of the torch dataloader class. \n",
    "collate_fn = torch.utils.data.DataLoader(None).collate_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "fastai_dc_data.trn_dl.collate_fn = collate_fn\n",
    "fastai_dc_data.val_dl.collate_fn = collate_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = get_learner(fastai_dc_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "238acb28cef6416da774ed3b1f7a7514",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=2), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                 \n",
      "    0      2.105816   1.978059   0.2379    \n",
      "    1      1.968836   1.918824   0.2612                   \n",
      "\n",
      "CPU times: user 2min 16s, sys: 3min 38s, total: 5min 54s\n",
      "Wall time: 1min 5s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([1.91882]), 0.26119999985694886]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time learn.fit(lrs=1, n_cycle=1, wds=1e-4, cycle_len=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fastai DataLoader - Torch Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfms = torch_tfms(sz, to_numpy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdl_tds_data = ImageClassifierData.from_paths(PATH, val_name='test', tfms=tfms, bs=bs, num_workers=workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdl_tds_data.trn_ds.open_fn = Image.open\n",
    "fdl_tds_data.val_ds.open_fn = Image.open"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = get_learner(fdl_tds_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8365206b420646559bdf8a681876d032",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=2), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                 \n",
      "    0      2.085024   2.094643   0.2199    \n",
      "    1      1.878126   1.761554   0.3321                   \n",
      "\n",
      "CPU times: user 3min 26s, sys: 4min 13s, total: 7min 39s\n",
      "Wall time: 2min 32s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([1.76155]), 0.33209999980926513]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time learn.fit(lrs=1, n_cycle=1, wds=1e-4, cycle_len=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Torch DataLoader - Fastai Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfms = tfms_from_stats(stats, sz, aug_tfms=[RandomCrop(sz), RandomFlip()], pad=sz//8)\n",
    "fdl = ImageClassifierData.from_paths(PATH, val_name='test', tfms=tfms, bs=bs, num_workers=workers)\n",
    "tdl_fds = fdl.trn_ds, fdl.val_ds\n",
    "torch_data = torch_loader(str(PATH), tdl_fds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = get_learner(torch_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b69a373039a74133b58b001efbfc35a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=2), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                 \n",
      "    0      2.23888    2.134263   0.1867    \n",
      "    1      1.998574   1.913979   0.2573                   \n",
      "\n",
      "CPU times: user 34 s, sys: 19.6 s, total: 53.7 s\n",
      "Wall time: 54.1 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([1.91398]), 0.25729999997615816]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time learn.fit(lrs=1, n_cycle=1, wds=1e-4, cycle_len=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fastai DataLoader - Torch Dataset - Same as Torch Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from fastai.dataset import FilesArrayDataset, folder_source, read_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfms = torch_tfms(sz, to_numpy=True)\n",
    "dsets = torch_ds(PATH, tfms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdl_tds_data = ImageData(PATH, list(dsets)+[None,None,None,None], bs, num_workers=workers, classes=dsets[0].classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = get_learner(fdl_tds_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time learn.fit(lrs=1, n_cycle=1, wds=1e-4, cycle_len=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "266px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
