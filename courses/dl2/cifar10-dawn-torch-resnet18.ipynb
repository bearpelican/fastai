{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CIFAR 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.conv_learner import *\n",
    "from fastai.models.cifar10.wideresnet import wrn_22_cat, wrn_22, WideResNetConcat\n",
    "torch.backends.cudnn.benchmark = True\n",
    "PATH = Path(\"data/cifar10/\")\n",
    "os.makedirs(PATH,exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "stats = (np.array([ 0.4914 ,  0.48216,  0.44653]), np.array([ 0.24703,  0.24349,  0.26159]))\n",
    "\n",
    "bs=512\n",
    "sz=32\n",
    "workers=7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "\n",
    "def pad(img, p=4, padding_mode='reflect'):\n",
    "    return Image.fromarray(np.pad(np.asarray(img), ((p, p), (p, p), (0, 0)), padding_mode))\n",
    "\n",
    "def torch_loader(data_path, size):\n",
    "    if not os.path.exists(data_path+'/train'): download_cifar10(data_path)\n",
    "\n",
    "    # Data loading code\n",
    "    traindir = os.path.join(data_path, 'train')\n",
    "    valdir = os.path.join(data_path, 'test')\n",
    "    normalize = transforms.Normalize(mean=[0.4914 , 0.48216, 0.44653], std=[0.24703, 0.24349, 0.26159])\n",
    "    tfms = [transforms.ToTensor(), normalize]\n",
    "\n",
    "    train_tfms = transforms.Compose([\n",
    "        pad, # TODO: use `padding` rather than assuming 4\n",
    "        transforms.RandomCrop(size),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "    ] + tfms)\n",
    "    val_tfms = transforms.Compose(tfms)\n",
    "\n",
    "    train_dataset = datasets.ImageFolder(traindir, train_tfms)\n",
    "    val_dataset = datasets.ImageFolder(valdir, val_tfms)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=bs, shuffle=True,\n",
    "        num_workers=workers, pin_memory=True)\n",
    "\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        val_dataset, batch_size=bs*2, shuffle=False,\n",
    "        num_workers=workers, pin_memory=True)\n",
    "\n",
    "    train_loader = DataPrefetcher(train_loader)\n",
    "    val_loader = DataPrefetcher(val_loader)\n",
    "    \n",
    "    data = ModelData(data_path, train_loader, val_loader)\n",
    "    data.sz = size\n",
    "    return data\n",
    "\n",
    "# Seems to speed up training by ~2%\n",
    "class DataPrefetcher():\n",
    "    def __init__(self, loader, stop_after=None):\n",
    "        self.loader = loader\n",
    "        self.dataset = loader.dataset\n",
    "        self.stream = torch.cuda.Stream()\n",
    "        self.stop_after = stop_after\n",
    "        self.next_input = None\n",
    "        self.next_target = None\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.loader)\n",
    "\n",
    "    def preload(self):\n",
    "        try:\n",
    "            self.next_input, self.next_target = next(self.loaditer)\n",
    "        except StopIteration:\n",
    "            self.next_input = None\n",
    "            self.next_target = None\n",
    "            return\n",
    "        with torch.cuda.stream(self.stream):\n",
    "            self.next_input = self.next_input.cuda(async=True)\n",
    "            self.next_target = self.next_target.cuda(async=True)\n",
    "\n",
    "    def __iter__(self):\n",
    "        count = 0\n",
    "        self.loaditer = iter(self.loader)\n",
    "        self.preload()\n",
    "        while self.next_input is not None:\n",
    "            torch.cuda.current_stream().wait_stream(self.stream)\n",
    "            input = self.next_input\n",
    "            target = self.next_target\n",
    "            self.preload()\n",
    "            count += 1\n",
    "            yield input, target\n",
    "            if type(self.stop_after) is int and (count > self.stop_after):\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch_loader(str(PATH), sz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Pre-activation ResNet in PyTorch.\n",
    "\n",
    "Reference:\n",
    "[1] Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun\n",
    "    Identity Mappings in Deep Residual Networks. arXiv:1603.05027\n",
    "'''\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "class AdaptiveConcatPool2d(nn.Module):\n",
    "    def __init__(self, sz=None):\n",
    "        super().__init__()\n",
    "        sz = sz or (1,1)\n",
    "        self.ap = nn.AdaptiveAvgPool2d(sz)\n",
    "        self.mp = nn.AdaptiveMaxPool2d(sz)\n",
    "    def forward(self, x): return torch.cat([self.mp(x), self.ap(x)], 1)\n",
    "    \n",
    "\n",
    "class PreActBlock(nn.Module):\n",
    "    '''Pre-activation version of the BasicBlock.'''\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(PreActBlock, self).__init__()\n",
    "        self.bn1 = nn.BatchNorm2d(in_planes)\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(x))\n",
    "        shortcut = self.shortcut(out) if hasattr(self, 'shortcut') else x\n",
    "        out = self.conv1(out)\n",
    "        out = self.conv2(F.relu(self.bn2(out)))\n",
    "        out += shortcut\n",
    "        return out\n",
    "\n",
    "\n",
    "class PreActBottleneck(nn.Module):\n",
    "    '''Pre-activation version of the original Bottleneck module.'''\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(PreActBottleneck, self).__init__()\n",
    "        self.bn1 = nn.BatchNorm2d(in_planes)\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, self.expansion*planes, kernel_size=1, bias=False)\n",
    "\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(x))\n",
    "        shortcut = self.shortcut(out) if hasattr(self, 'shortcut') else x\n",
    "        out = self.conv1(out)\n",
    "        out = self.conv2(F.relu(self.bn2(out)))\n",
    "        out = self.conv3(F.relu(self.bn3(out)))\n",
    "        out += shortcut\n",
    "        return out\n",
    "\n",
    "\n",
    "class PreActResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=10, concatpool=False):\n",
    "        super(PreActResNet, self).__init__()\n",
    "        self.in_planes = 64\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
    "        self.pool = AdaptiveConcatPool2d() if concatpool else nn.AdaptiveMaxPool2d((1,1))\n",
    "        \n",
    "        self.linear = nn.Linear(512*block.expansion*(concatpool+1), num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "#         out = F.adaptive_max_pool2d(out, 1)\n",
    "        out = self.pool(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        return F.log_softmax(self.linear(out))\n",
    "\n",
    "def preact_resnet18(): return PreActResNet(PreActBlock, [2,2,2,2])\n",
    "def preact_resnet2332(): return PreActResNet(PreActBlock, [2,3,3,2])\n",
    "def preact_resnet3333(): return PreActResNet(PreActBlock, [3,3,3,3])\n",
    "def preact_resnet34(): return PreActResNet(PreActBlock, [3,4,6,3])\n",
    "def preact_resnet50(): return PreActResNet(PreActBottleneck, [3,4,6,3])\n",
    "def preActResNet101(): return PreActResNet(PreActBottleneck, [3,4,23,3])\n",
    "def preActResNet152(): return PreActResNet(PreActBottleneck, [3,8,36,3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m = WideResNetConcat(num_groups=3, N=3, num_classes=10, k=1, drop_p=0.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd456eb721534b71a7d542cfc01c8674",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=23), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                 \n",
      "    0      1.548514   1.458414   0.5059    \n",
      "    1      1.197921   1.095902   0.6147                   \n",
      "    2      0.973413   1.059713   0.638                     \n",
      "    3      0.814994   0.797659   0.722                     \n",
      "    4      0.679065   0.919106   0.7008                    \n",
      "    5      0.595604   0.731411   0.7461                    \n",
      "    6      0.528443   0.61003    0.79                      \n",
      "    7      0.475986   0.525616   0.8199                    \n",
      "    8      0.432675   0.662902   0.7817                    \n",
      "    9      0.404445   0.477596   0.8416                    \n",
      "    10     0.365769   0.565556   0.822                     \n",
      "    11     0.34004    0.496644   0.8357                    \n",
      "    12     0.299456   0.45601    0.8493                    \n",
      "    13     0.283647   0.403581   0.8611                    \n",
      "    14     0.239966   0.355904   0.8836                    \n",
      "    15     0.213908   0.346475   0.8852                    \n",
      "    16     0.179667   0.322777   0.8958                    \n",
      "    17     0.14106    0.290177   0.9065                    \n",
      "    18     0.10665    0.277277   0.9141                    \n",
      "    19     0.088274   0.278283   0.9142                     \n",
      "    20     0.071866   0.271222   0.9201                     \n",
      "    21     0.060893   0.268681   0.9222                     \n",
      "    22     0.054586   0.26741    0.9224                     \n",
      "\n",
      "CPU times: user 1min 58s, sys: 57.8 s, total: 2min 56s\n",
      "Wall time: 3min 15s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([0.26741]), 0.9224000018119812]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = preact_resnet18()\n",
    "learn = ConvLearner.from_model_data(m, data)\n",
    "learn.half()\n",
    "learn.crit = nn.CrossEntropyLoss()\n",
    "learn.metrics = [accuracy]\n",
    "wd=1e-4\n",
    "lr=.6\n",
    "learn.clip = 3e-1\n",
    "def_phase = {'opt_fn':optim.SGD, 'wds':wd}\n",
    "# TODO: add momentum\n",
    "%time learn.fit(lr, 1, wds=wd, cycle_len=23, use_clr_beta=(12,22,0.95,0.85), loss_scale=512)\n",
    "# phases = [\n",
    "#     TrainingPhase(**def_phase, epochs=1, lr=(.005,.05), lr_decay=DecayType.EXPONENTIAL, momentum=0.95),\n",
    "#     TrainingPhase(**def_phase, epochs=6, lr=(.05,.9), lr_decay=DecayType.COSINE, momentum=(0.95,0.85), momentum_decay=DecayType.COSINE),\n",
    "#     TrainingPhase(**def_phase, epochs=4, lr=1, momentum=0.85),\n",
    "#     TrainingPhase(**def_phase, epochs=7, lr=(.9,.01), lr_decay=DecayType.COSINE, momentum=(0.85,0.95), momentum_decay=DecayType.COSINE),\n",
    "#     TrainingPhase(**def_phase, epochs=3, lr=(.01,.0005), lr_decay=DecayType.LINEAR, momentum=(0.95))]\n",
    "\n",
    "# learn.fit_opt_sched(phases, data_list=[data], loss_scale=512)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7e07597c5c14940bd715d7918f2f7e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=23), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                 \n",
      "    0      1.575032   1.724038   0.4309    \n",
      "    1      1.187866   1.314066   0.572                    \n",
      "    2      0.956739   1.07919    0.6446                    \n",
      "    3      0.771508   0.812311   0.7199                    \n",
      "    4      0.651959   0.917808   0.7014                    \n",
      "    5      0.565921   0.725721   0.7607                    \n",
      "    6      0.529047   0.651835   0.7864                    \n",
      "    7      0.482334   0.7427     0.7582                    \n",
      "    8      0.443646   0.556046   0.8103                    \n",
      "    9      0.412336   0.515939   0.8264                    \n",
      "    10     0.376727   0.572458   0.8153                    \n",
      "    11     0.341356   0.597042   0.815                     \n",
      "    12     0.314225   0.520334   0.839                     \n",
      "    13     0.281799   0.383897   0.8744                    \n",
      "    14     0.245815   0.383549   0.8775                    \n",
      "    15     0.217316   0.419567   0.8651                    \n",
      "    16     0.185396   0.341323   0.8897                    \n",
      "    17     0.13935    0.318796   0.9028                    \n",
      "    18     0.103292   0.296072   0.911                     \n",
      "    19     0.085553   0.287663   0.9156                     \n",
      "    20     0.070444   0.290111   0.9168                     \n",
      "    21     0.058995   0.284167   0.9164                     \n",
      "    22     0.052097   0.285414   0.9172                     \n",
      "\n",
      "CPU times: user 2min, sys: 59.3 s, total: 2min 59s\n",
      "Wall time: 3min 16s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([0.28541]), 0.9171999992370605]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = PreActResNet(PreActBlock, [2,2,2,2], concatpool=True)\n",
    "learn = ConvLearner.from_model_data(m, data)\n",
    "learn.half()\n",
    "learn.crit = nn.CrossEntropyLoss()\n",
    "learn.metrics = [accuracy]\n",
    "wd=1e-4\n",
    "lr=.6\n",
    "learn.clip = 3e-1\n",
    "def_phase = {'opt_fn':optim.SGD, 'wds':wd}\n",
    "# TODO: add momentum\n",
    "%time learn.fit(lr, 1, wds=wd, cycle_len=23, use_clr_beta=(12,22,0.95,0.85), loss_scale=512)\n",
    "# phases = [\n",
    "#     TrainingPhase(**def_phase, epochs=1, lr=(.005,.05), lr_decay=DecayType.EXPONENTIAL, momentum=0.95),\n",
    "#     TrainingPhase(**def_phase, epochs=6, lr=(.05,.9), lr_decay=DecayType.COSINE, momentum=(0.95,0.85), momentum_decay=DecayType.COSINE),\n",
    "#     TrainingPhase(**def_phase, epochs=4, lr=1, momentum=0.85),\n",
    "#     TrainingPhase(**def_phase, epochs=7, lr=(.9,.01), lr_decay=DecayType.COSINE, momentum=(0.85,0.95), momentum_decay=DecayType.COSINE),\n",
    "#     TrainingPhase(**def_phase, epochs=3, lr=(.01,.0005), lr_decay=DecayType.LINEAR, momentum=(0.95))]\n",
    "\n",
    "# learn.fit_opt_sched(phases, data_list=[data], loss_scale=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1947cd0a4bc945d18b36ed53087378e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=23), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 30%|██▉       | 29/98 [00:02<00:06, 11.32it/s, loss=2.02]\n",
      " 32%|███▏      | 31/98 [00:02<00:06, 11.11it/s, loss=1.98]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-146:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/tqdm/_monitor.py\", line 62, in run\n",
      "    for instance in self.tqdm_cls._instances:\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/_weakrefset.py\", line 60, in __iter__\n",
      "    for itemref in self.data:\n",
      "RuntimeError: Set changed size during iteration\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                 \n",
      "    0      1.680362   3.253288   0.3729    \n",
      "    1      1.482544   1.609691   0.4481                   \n",
      "    2      1.163796   1.195272   0.6053                   \n",
      "    3      0.987197   1.034303   0.6383                    \n",
      "    4      0.840345   0.922554   0.6994                    \n",
      "    5      nan        nan        0.1                       \n",
      "    6      nan        nan        0.1                     \n",
      " 30%|██▉       | 29/98 [00:02<00:06, 11.07it/s, loss=nan]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-777:\n",
      "Process Process-771:\n",
      "Process Process-775:\n",
      "Process Process-776:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 50, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 50, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 55, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 55, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "Process Process-774:\n",
      "Process Process-773:\n",
      "Process Process-772:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torchvision/datasets/folder.py\", line 124, in __getitem__\n",
      "    img = self.transform(img)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torchvision/transforms/transforms.py\", line 42, in __call__\n",
      "    img = t(img)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 55, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-4-1ee755e8a818>\", line 5, in pad\n",
      "    return Image.fromarray(np.pad(np.asarray(img), ((p, p), (p, p), (0, 0)), padding_mode))\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 50, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 55, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 55, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/PIL/Image.py\", line 2438, in fromarray\n",
      "    return frombuffer(mode, size, obj, \"raw\", rawmode, 0, 1)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 55, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torchvision/datasets/folder.py\", line 122, in __getitem__\n",
      "    img = self.loader(path)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torchvision/datasets/folder.py\", line 124, in __getitem__\n",
      "    img = self.transform(img)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/PIL/Image.py\", line 2391, in frombuffer\n",
      "    return frombytes(mode, size, data, decoder_name, args)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torchvision/datasets/folder.py\", line 65, in default_loader\n",
      "    from torchvision import get_image_backend\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torchvision/transforms/transforms.py\", line 42, in __call__\n",
      "    img = t(img)\n",
      "  File \"<frozen importlib._bootstrap>\", line 997, in _handle_fromlist\n",
      "KeyboardInterrupt\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/PIL/Image.py\", line 2324, in frombytes\n",
      "    im.frombytes(data, decoder_name, args)\n",
      "  File \"<ipython-input-4-1ee755e8a818>\", line 5, in pad\n",
      "    return Image.fromarray(np.pad(np.asarray(img), ((p, p), (p, p), (0, 0)), padding_mode))\n",
      "KeyboardInterrupt\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/PIL/Image.py\", line 779, in frombytes\n",
      "    d = _getdecoder(self.mode, decoder_name, args)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/PIL/Image.py\", line 2438, in fromarray\n",
      "    return frombuffer(mode, size, obj, \"raw\", rawmode, 0, 1)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/PIL/Image.py\", line 433, in _getdecoder\n",
      "    return decoder(mode, *args + extra)\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 50, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/PIL/Image.py\", line 2391, in frombuffer\n",
      "    return frombytes(mode, size, data, decoder_name, args)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/PIL/Image.py\", line 2323, in frombytes\n",
      "    im = new(mode, size)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/PIL/Image.py\", line 2287, in new\n",
      "    return Image()._new(core.fill(mode, size, color))\n",
      "KeyboardInterrupt\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <generator object tqdm_notebook.__iter__ at 0x7fe6900f1f10>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/tqdm/_tqdm_notebook.py\", line 187, in __iter__\n",
      "    yield obj\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 175, in handler\n",
      "    _error_if_any_worker_fails()\n",
      "RuntimeError: DataLoader worker (pid 15900) exited unexpectedly with exit code 1.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed eval>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/fastai/courses/dl2/fastai/learner.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, lrs, n_cycle, wds, **kwargs)\u001b[0m\n\u001b[1;32m    285\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0mlayer_opt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_layer_opt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 287\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_gen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer_opt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_cycle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwarm_up\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/fastai/courses/dl2/fastai/learner.py\u001b[0m in \u001b[0;36mfit_gen\u001b[0;34m(self, model, data, layer_opt, n_cycle, cycle_len, cycle_mult, cycle_save_name, best_save_name, use_clr, use_clr_beta, metrics, callbacks, use_wd_sched, norm_wds, wds_sched_mult, use_swa, swa_start, swa_eval_freq, **kwargs)\u001b[0m\n\u001b[1;32m    232\u001b[0m             \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreg_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreg_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclip\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp16\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m             \u001b[0mswa_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mswa_model\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0muse_swa\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswa_start\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswa_start\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m             swa_eval_freq=swa_eval_freq, **kwargs)\n\u001b[0m\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_layer_groups\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_layer_groups\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/fastai/courses/dl2/fastai/model.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(model, data, n_epochs, opt, crit, metrics, callbacks, stepper, swa_model, swa_start, swa_eval_freq, **kwargs)\u001b[0m\n\u001b[1;32m    127\u001b[0m             \u001b[0mbatch_num\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mcb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_stepper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m             \u001b[0mavg_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mavg_loss\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mavg_mom\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mavg_mom\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m             \u001b[0mdebias_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mavg_loss\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mavg_mom\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mbatch_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/fastai/courses/dl2/fastai/model.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, xs, y, epoch)\u001b[0m\n\u001b[1;32m     58\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp32_params\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiv_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_scale\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m:\u001b[0m   \u001b[0;31m# Gradient clipping\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m             \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainable_params_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp16\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/nn/utils/clip_grad.py\u001b[0m in \u001b[0;36mclip_grad_norm\u001b[0;34m(parameters, max_norm, norm_type)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mtotal_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m             \u001b[0mparam_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m             \u001b[0mtotal_norm\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mparam_norm\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mtotal_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtotal_norm\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1.\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "m = PreActResNet(PreActBlock, [2,2,2,2], concatpool=True)\n",
    "learn = ConvLearner.from_model_data(m, data)\n",
    "learn.half()\n",
    "learn.crit = nn.CrossEntropyLoss()\n",
    "learn.metrics = [accuracy]\n",
    "wd=5e-5\n",
    "lr=1.2\n",
    "learn.clip = 3e-1\n",
    "def_phase = {'opt_fn':optim.SGD, 'wds':wd}\n",
    "# TODO: add momentum\n",
    "%time learn.fit(lr, 1, wds=wd, cycle_len=23, use_clr_beta=(20,22,0.95,0.85), loss_scale=512)\n",
    "# phases = [\n",
    "#     TrainingPhase(**def_phase, epochs=1, lr=(.005,.05), lr_decay=DecayType.EXPONENTIAL, momentum=0.95),\n",
    "#     TrainingPhase(**def_phase, epochs=6, lr=(.05,.9), lr_decay=DecayType.COSINE, momentum=(0.95,0.85), momentum_decay=DecayType.COSINE),\n",
    "#     TrainingPhase(**def_phase, epochs=4, lr=1, momentum=0.85),\n",
    "#     TrainingPhase(**def_phase, epochs=7, lr=(.9,.01), lr_decay=DecayType.COSINE, momentum=(0.85,0.95), momentum_decay=DecayType.COSINE),\n",
    "#     TrainingPhase(**def_phase, epochs=3, lr=(.01,.0005), lr_decay=DecayType.LINEAR, momentum=(0.95))]\n",
    "\n",
    "# learn.fit_opt_sched(phases, data_list=[data], loss_scale=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f53a6c14708c4a868bb5c762332e9641",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=21), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                 \n",
      "    0      1.58888    2.268781   0.358     \n",
      "    1      1.330952   2.700681   0.3216                   \n",
      "    2      1.0324     1.909272   0.5134                   \n",
      "    3      0.806186   1.007916   0.6665                    \n",
      "    4      0.695327   1.068196   0.679                     \n",
      "    5      0.615858   0.575531   0.8014                    \n",
      "    6      0.573678   0.83847    0.7455                    \n",
      "    7      0.547463   0.812909   0.7374                    \n",
      "    8      0.504218   0.614202   0.8032                    \n",
      "    9      0.476235   0.54882    0.8191                    \n",
      "    10     0.445325   1.151848   0.719                     \n",
      "    11     0.393621   0.47237    0.8542                    \n",
      "    12     0.376854   0.506546   0.8463                    \n",
      "    13     0.330198   0.426037   0.8653                    \n",
      "    14     0.291321   0.420512   0.8608                    \n",
      "    15     0.240045   0.37889    0.8779                    \n",
      "    16     0.172085   0.286532   0.9119                    \n",
      "    17     0.133108   0.272656   0.9177                    \n",
      "    18     0.118869   0.272181   0.9166                    \n",
      "    19     0.11182    0.271186   0.9171                    \n",
      "    20     0.10757    0.27203    0.9175                    \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([0.27203]), 0.9175000017166137]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = PreActResNet(PreActBlock, [2,2,2,2], concatpool=True)\n",
    "learn = ConvLearner.from_model_data(m, data)\n",
    "learn.half()\n",
    "learn.crit = nn.CrossEntropyLoss()\n",
    "learn.metrics = [accuracy]\n",
    "wd=5e-5\n",
    "lr=1.2\n",
    "learn.clip = 3e-1\n",
    "def_phase = {'opt_fn':optim.SGD, 'wds':wd}\n",
    "# TODO: add momentum\n",
    "# %time learn.fit(lr, 1, wds=wd, cycle_len=23, use_clr_beta=(20,22,0.95,0.85), loss_scale=512)\n",
    "phases = [\n",
    "    TrainingPhase(**def_phase, epochs=1, lr=(.005,.05), lr_decay=DecayType.EXPONENTIAL, momentum=0.95),\n",
    "    TrainingPhase(**def_phase, epochs=6, lr=(.05,.9), lr_decay=DecayType.COSINE, momentum=(0.95,0.85), momentum_decay=DecayType.COSINE),\n",
    "    TrainingPhase(**def_phase, epochs=4, lr=1, momentum=0.85),\n",
    "    TrainingPhase(**def_phase, epochs=7, lr=(.9,.01), lr_decay=DecayType.COSINE, momentum=(0.85,0.95), momentum_decay=DecayType.COSINE),\n",
    "    TrainingPhase(**def_phase, epochs=3, lr=(.01,.0005), lr_decay=DecayType.LINEAR, momentum=(0.95))]\n",
    "\n",
    "learn.fit_opt_sched(phases, data_list=[data], loss_scale=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "829dd66f78f24ed7ab0b0090190ca490",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                 \n",
      "    0      1.513263   1.572274   0.4598    \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([1.57227]), 0.45979999990463255]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = PreActResNet(PreActBlock, [2,2,2,2], concatpool=True)\n",
    "learn = ConvLearner.from_model_data(m, data)\n",
    "learn.half()\n",
    "learn.crit = nn.CrossEntropyLoss()\n",
    "learn.metrics = [accuracy]\n",
    "wd=5e-5\n",
    "lr=1.2\n",
    "learn.clip = 3e-1\n",
    "def_phase = {'opt_fn':optim.SGD, 'wds':wd}\n",
    "# TODO: add momentum\n",
    "# %time learn.fit(lr, 1, wds=wd, cycle_len=23, use_clr_beta=(20,22,0.95,0.85), loss_scale=512)\n",
    "phases = [\n",
    "    TrainingPhase(**def_phase, epochs=1, lr=(.01,.02), lr_decay=DecayType.EXPONENTIAL, momentum=0.95)]\n",
    "\n",
    "learn.fit_opt_sched(phases, data_list=[data], loss_scale=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f648a22d56b4d5cb4a16d013e05c38d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=26), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                 \n",
      "    0      1.519843   1.447052   0.4779    \n",
      "    1      1.162748   2.281788   0.4349                   \n",
      "    2      1.141875   1.403912   0.6048                   \n",
      "    3      0.852955   0.893409   0.7146                    \n",
      "    4      0.685746   0.914835   0.7071                    \n",
      "    5      0.61813    0.651454   0.7834                    \n",
      "    6      0.616182   0.731231   0.7676                    \n",
      "    7      0.562869   1.166888   0.6899                    \n",
      "    8      0.484735   0.5032     0.83                      \n",
      "    9      0.46338    0.704105   0.785                     \n",
      "    10     0.441603   0.507102   0.8327                    \n",
      "    11     0.42213    0.65801    0.7793                    \n",
      "    12     0.389854   0.438473   0.8564                    \n",
      "    13     0.364727   0.63655    0.8154                    \n",
      "    14     0.3442     0.546502   0.8253                    \n",
      "    15     0.321018   0.445805   0.8609                    \n",
      "    16     0.279551   0.399258   0.8692                    \n",
      "    17     0.237956   0.356332   0.8871                    \n",
      "    18     0.190874   0.303751   0.9047                    \n",
      "    19     0.139129   0.262517   0.9173                    \n",
      "    20     0.103906   0.259448   0.9205                    \n",
      "    21     0.091122   0.257059   0.9216                     \n",
      "    22     0.090097   0.256586   0.9229                     \n",
      "    23     0.086141   0.257966   0.9228                     \n",
      "    24     0.082368   0.257738   0.9226                     \n",
      "    25     0.081714   0.256816   0.9225                     \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([0.25682]), 0.9225000015258789]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = PreActResNet(PreActBlock, [2,2,2,2], concatpool=True)\n",
    "learn = ConvLearner.from_model_data(m, data)\n",
    "learn.half()\n",
    "learn.crit = nn.CrossEntropyLoss()\n",
    "learn.metrics = [accuracy]\n",
    "wd=5e-5\n",
    "lr=1.2\n",
    "learn.clip = 1e-1\n",
    "def_phase = {'opt_fn':optim.SGD, 'wds':wd}\n",
    "# TODO: add momentum\n",
    "# %time learn.fit(lr, 1, wds=wd, cycle_len=23, use_clr_beta=(20,22,0.95,0.85), loss_scale=512)\n",
    "phases = [\n",
    "    TrainingPhase(**def_phase, epochs=1, lr=(.01,.02), lr_decay=DecayType.EXPONENTIAL, momentum=0.95),\n",
    "    TrainingPhase(**def_phase, epochs=8, lr=(.02,1), lr_decay=DecayType.COSINE, momentum=(0.95,0.85), momentum_decay=DecayType.COSINE),\n",
    "    TrainingPhase(**def_phase, epochs=4, lr=1, momentum=0.85),\n",
    "    TrainingPhase(**def_phase, epochs=8, lr=(1,.01), lr_decay=DecayType.COSINE, momentum=(0.85,0.95), momentum_decay=DecayType.COSINE),\n",
    "    TrainingPhase(**def_phase, epochs=5, lr=(.01,.0005), lr_decay=DecayType.LINEAR, momentum=(0.95))]\n",
    "\n",
    "learn.fit_opt_sched(phases, data_list=[data], loss_scale=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e722fc51104d459f8c2d4217342321c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                 \n",
      "    0      1.434231   1.189548   0.5689    \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([1.18955]), 0.5688999989509582]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = PreActResNet(PreActBlock, [2,2,2,2], concatpool=True)\n",
    "learn = ConvLearner.from_model_data(m, data)\n",
    "learn.half()\n",
    "learn.crit = nn.CrossEntropyLoss()\n",
    "learn.metrics = [accuracy]\n",
    "wd=5e-5\n",
    "lr=1.2\n",
    "learn.clip = 3e-1\n",
    "def_phase = {'opt_fn':optim.SGD, 'wds':wd}\n",
    "# TODO: add momentum\n",
    "# %time learn.fit(lr, 1, wds=wd, cycle_len=23, use_clr_beta=(20,22,0.95,0.85), loss_scale=512)\n",
    "phases = [\n",
    "    TrainingPhase(**def_phase, epochs=1, lr=(.04), lr_decay=DecayType.LINEAR, momentum=0.95)]\n",
    "\n",
    "learn.fit_opt_sched(phases, data_list=[data], loss_scale=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4366a43d96a48baa5b753b7a55334ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=9), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                 \n",
      "    0      1.445796   1.215815   0.5574    \n",
      "    1      1.1894     2.79712    0.4001                   \n",
      "    2      1.219395   1.813344   0.5312                   \n",
      "    3      0.873536   1.315986   0.6321                    \n",
      "    4      0.742008   0.931552   0.6865                    \n",
      "    5      0.647099   0.668615   0.7715                    \n",
      "    6      0.612087   1.124609   0.6898                    \n",
      "    7      0.559995   0.653557   0.777                     \n",
      "    8      0.527178   0.576201   0.8114                    \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([0.5762]), 0.8114000003814698]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = PreActResNet(PreActBlock, [2,2,2,2], concatpool=True)\n",
    "learn = ConvLearner.from_model_data(m, data)\n",
    "learn.half()\n",
    "learn.crit = nn.CrossEntropyLoss()\n",
    "learn.metrics = [accuracy]\n",
    "wd=5e-5\n",
    "lr=1.2\n",
    "learn.clip = 3e-1\n",
    "def_phase = {'opt_fn':optim.SGD, 'wds':wd}\n",
    "# TODO: add momentum\n",
    "# %time learn.fit(lr, 1, wds=wd, cycle_len=23, use_clr_beta=(20,22,0.95,0.85), loss_scale=512)\n",
    "phases = [\n",
    "    TrainingPhase(**def_phase, epochs=1, lr=(.04), lr_decay=DecayType.LINEAR, momentum=0.95),\n",
    "    TrainingPhase(**def_phase, epochs=8, lr=(.02,1), lr_decay=DecayType.COSINE, momentum=(0.95,0.85), momentum_decay=DecayType.LINEAR)]\n",
    "\n",
    "learn.fit_opt_sched(phases, data_list=[data], loss_scale=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13d98531507748e2925c9a8575107cd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=9), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                 \n",
      "    0      1.421114   1.177442   0.575     \n",
      "    1      1.235079   1.302384   0.568                    \n",
      "    2      1.020289   1.431194   0.5482                   \n",
      "    3      0.799422   1.088784   0.6679                    \n",
      "    4      0.681878   1.054612   0.6722                    \n",
      "    5      0.601654   0.626858   0.7836                    \n",
      "    6      0.555011   0.734665   0.7649                    \n",
      "    7      0.565445   0.818552   0.7348                    \n",
      "    8      0.597936   1.045264   0.6987                    \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([1.04526]), 0.6987000011444092]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = PreActResNet(PreActBlock, [2,2,2,2], concatpool=True)\n",
    "learn = ConvLearner.from_model_data(m, data)\n",
    "learn.half()\n",
    "learn.crit = nn.CrossEntropyLoss()\n",
    "learn.metrics = [accuracy]\n",
    "wd=5e-5\n",
    "lr=1.2\n",
    "learn.clip = 3e-1\n",
    "def_phase = {'opt_fn':optim.SGD, 'wds':wd}\n",
    "# TODO: add momentum\n",
    "# %time learn.fit(lr, 1, wds=wd, cycle_len=23, use_clr_beta=(20,22,0.95,0.85), loss_scale=512)\n",
    "phases = [\n",
    "    TrainingPhase(**def_phase, epochs=1, lr=(.04), lr_decay=DecayType.LINEAR, momentum=0.95),\n",
    "    TrainingPhase(**def_phase, epochs=8, lr=(.04,1), lr_decay=DecayType.EXPONENTIAL, momentum=(0.95,0.85), momentum_decay=DecayType.LINEAR)]\n",
    "\n",
    "learn.fit_opt_sched(phases, data_list=[data], loss_scale=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.sched.plot_lr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41dcfc5709814b3cbeed4c5771f7bb96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=11), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 66%|██████▋   | 65/98 [00:05<00:02, 12.21it/s, loss=1.62]\n",
      " 68%|██████▊   | 67/98 [00:05<00:02, 12.27it/s, loss=1.6] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-436:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/tqdm/_monitor.py\", line 62, in run\n",
      "    for instance in self.tqdm_cls._instances:\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/_weakrefset.py\", line 60, in __iter__\n",
      "    for itemref in self.data:\n",
      "RuntimeError: Set changed size during iteration\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                 \n",
      "    0      1.44591    1.190425   0.5626    \n",
      "    1      1.207164   1.193157   0.6051                   \n",
      "    2      0.990962   0.870603   0.7023                    \n",
      "    3      0.801405   0.972999   0.6834                    \n",
      "    4      0.692669   0.786937   0.7417                    \n",
      "    5      0.600746   0.593546   0.7948                    \n",
      "    6      0.536652   0.649064   0.7884                    \n",
      "    7      0.514753   0.562664   0.8095                    \n",
      "    8      0.474542   0.630671   0.8012                    \n",
      "    9      0.482716   0.724706   0.7753                    \n",
      "    10     0.514703   1.059147   0.6616                    \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([1.05915]), 0.6616000004291535]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = PreActResNet(PreActBlock, [2,2,2,2], concatpool=True)\n",
    "learn = ConvLearner.from_model_data(m, data)\n",
    "learn.half()\n",
    "learn.crit = nn.CrossEntropyLoss()\n",
    "learn.metrics = [accuracy]\n",
    "wd=5e-5\n",
    "lr=1.2\n",
    "learn.clip = 1e-1\n",
    "def_phase = {'opt_fn':optim.SGD, 'wds':wd}\n",
    "# TODO: add momentum\n",
    "# %time learn.fit(lr, 1, wds=wd, cycle_len=23, use_clr_beta=(20,22,0.95,0.85), loss_scale=512)\n",
    "phases = [\n",
    "    TrainingPhase(**def_phase, epochs=1, lr=(.04), lr_decay=DecayType.LINEAR, momentum=0.95),\n",
    "    TrainingPhase(**def_phase, epochs=10, lr=(.04,.9), lr_decay=DecayType.EXPONENTIAL, momentum=(0.95,0.85), momentum_decay=DecayType.LINEAR)]\n",
    "\n",
    "learn.fit_opt_sched(phases, data_list=[data], loss_scale=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86e5d482649e409f8a1e36bbac0b1c1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=12), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                 \n",
      "    0      1.516574   1.523376   0.4545    \n",
      "    1      1.216384   1.386647   0.5568                   \n",
      "    2      0.989549   1.046911   0.6554                    \n",
      "    3      0.802942   0.930375   0.6757                    \n",
      "    4      0.683606   1.049417   0.6817                    \n",
      "    5      0.606584   0.695874   0.7714                    \n",
      "    6      0.553311   0.849601   0.7435                    \n",
      "    7      0.492958   0.601467   0.8071                    \n",
      "    8      0.468651   0.947667   0.7236                    \n",
      "    9      0.461695   0.633913   0.7988                    \n",
      "    10     0.443599   0.735604   0.7846                    \n",
      "    11     0.418904   0.692418   0.7818                    \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([0.69242]), 0.7817999978065491]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = PreActResNet(PreActBlock, [2,2,2,2], concatpool=True)\n",
    "learn = ConvLearner.from_model_data(m, data)\n",
    "learn.half()\n",
    "learn.crit = nn.CrossEntropyLoss()\n",
    "learn.metrics = [accuracy]\n",
    "wd=5e-5\n",
    "lr=1.2\n",
    "learn.clip = 1e-1\n",
    "def_phase = {'opt_fn':optim.SGD, 'wds':wd}\n",
    "# TODO: add momentum\n",
    "# %time learn.fit(lr, 1, wds=wd, cycle_len=23, use_clr_beta=(20,22,0.95,0.85), loss_scale=512)\n",
    "phases = [\n",
    "    TrainingPhase(**def_phase, epochs=2, lr=(.04, .08), lr_decay=DecayType.LINEAR, momentum=0.95),\n",
    "    TrainingPhase(**def_phase, epochs=10, lr=(.08,.9), lr_decay=DecayType.LINEAR, momentum=(0.95,0.85), momentum_decay=DecayType.LINEAR)]\n",
    "\n",
    "learn.fit_opt_sched(phases, data_list=[data], loss_scale=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eecb860c9f5f4f9b8a80fae6fbaa2873",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=12), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                 \n",
      "    0      1.560654   1.449268   0.4913    \n",
      "    1      1.205908   1.148933   0.6068                   \n",
      "    2      1.02553    1.304383   0.5993                   \n",
      "    3      0.835705   1.025464   0.643                     \n",
      "    4      0.698056   0.882131   0.7014                    \n",
      "    5      0.596322   0.771745   0.7491                    \n",
      "    6      0.537337   0.696305   0.7705                    \n",
      "    7      0.494024   1.272275   0.6775                    \n",
      "    8      0.474927   0.677568   0.785                     \n",
      "    9      0.44198    0.612871   0.8004                    \n",
      "    10     0.447866   0.982635   0.7595                    \n",
      "    11     0.418682   0.595285   0.8063                    \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([0.59529]), 0.806299999332428]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = PreActResNet(PreActBlock, [2,2,2,2], concatpool=True)\n",
    "learn = ConvLearner.from_model_data(m, data)\n",
    "learn.half()\n",
    "learn.crit = nn.CrossEntropyLoss()\n",
    "learn.metrics = [accuracy]\n",
    "wd=5e-5\n",
    "lr=1.2\n",
    "learn.clip = 1e-1\n",
    "def_phase = {'opt_fn':optim.SGD, 'wds':wd}\n",
    "# TODO: add momentum\n",
    "# %time learn.fit(lr, 1, wds=wd, cycle_len=23, use_clr_beta=(20,22,0.95,0.85), loss_scale=512)\n",
    "phases = [\n",
    "    TrainingPhase(**def_phase, epochs=2, lr=(.04, .08), lr_decay=DecayType.LINEAR, momentum=0.95),\n",
    "    TrainingPhase(**def_phase, epochs=10, lr=(.08,.8), lr_decay=DecayType.LINEAR, momentum=(0.95,0.85), momentum_decay=DecayType.LINEAR)]\n",
    "\n",
    "learn.fit_opt_sched(phases, data_list=[data], loss_scale=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30ed2d680f054a91b2e89acd65bcc739",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=26), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                 \n",
      "    0      1.557638   2.299671   0.3591    \n",
      "    1      1.212952   1.153321   0.6076                   \n",
      "    2      0.980975   0.89169    0.6906                    \n",
      "    3      0.806878   1.259274   0.626                     \n",
      "    4      0.67743    0.853906   0.7202                    \n",
      "    5      0.577781   0.602288   0.7997                    \n",
      "    6      0.530176   0.657255   0.7797                    \n",
      "    7      0.491681   0.793932   0.7381                    \n",
      "    8      0.454081   0.660317   0.7803                    \n",
      "    9      0.429935   0.599835   0.7968                    \n",
      "    10     0.403083   0.587469   0.8186                    \n",
      "    11     0.386966   0.497521   0.8387                    \n",
      "    12     0.385295   0.600526   0.8167                    \n",
      "    13     0.362977   0.516909   0.8317                    \n",
      "    14     0.343218   0.533029   0.8243                    \n",
      "    15     0.319177   0.470309   0.8471                    \n",
      "    16     0.296087   0.480664   0.8488                    \n",
      "    17     0.274298   0.425076   0.8708                    \n",
      "    18     0.261381   0.478177   0.8474                    \n",
      "    19     0.236124   0.470619   0.8621                    \n",
      "    20     0.223473   0.477014   0.8627                    \n",
      "    21     0.195174   0.422449   0.8747                    \n",
      "    22     0.17769    0.379077   0.8863                    \n",
      "    23     0.150535   0.332532   0.8993                    \n",
      "    24     0.120081   0.299106   0.9114                    \n",
      "    25     0.08985    0.295152   0.9195                     \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([0.29515]), 0.9194999994277954]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = PreActResNet(PreActBlock, [2,2,2,2], concatpool=True)\n",
    "learn = ConvLearner.from_model_data(m, data)\n",
    "learn.half()\n",
    "learn.crit = nn.CrossEntropyLoss()\n",
    "learn.metrics = [accuracy]\n",
    "wd=5e-5\n",
    "lr=1.2\n",
    "learn.clip = 3e-2\n",
    "def_phase = {'opt_fn':optim.SGD, 'wds':wd}\n",
    "# TODO: add momentum\n",
    "# %time learn.fit(lr, 1, wds=wd, cycle_len=23, use_clr_beta=(20,22,0.95,0.85), loss_scale=512)\n",
    "phases = [\n",
    "    TrainingPhase(**def_phase, epochs=2, lr=(.04, .08), lr_decay=DecayType.LINEAR, momentum=0.95),\n",
    "    TrainingPhase(**def_phase, epochs=12, lr=(.08,.8), lr_decay=DecayType.LINEAR, momentum=(0.95,0.85), momentum_decay=DecayType.LINEAR),\n",
    "    TrainingPhase(**def_phase, epochs=12, lr=(.8,.08), lr_decay=DecayType.LINEAR, momentum=(0.85,0.95), momentum_decay=DecayType.LINEAR)]\n",
    "\n",
    "learn.fit_opt_sched(phases, data_list=[data], loss_scale=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "649c35b8d1ba4f1ab176a8de8abb46ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=32), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                 \n",
      "    0      1.519103   1.424092   0.5225    \n",
      "    1      1.150624   1.184188   0.6162                   \n",
      "    2      0.946004   0.992027   0.6635                    \n",
      "    3      0.762649   0.779844   0.7419                    \n",
      "    4      0.636289   0.741833   0.7529                    \n",
      "    5      0.561814   0.717107   0.7598                    \n",
      "    6      0.514578   0.593027   0.8026                    \n",
      "    7      0.479064   0.63399    0.7983                    \n",
      "    8      0.452762   0.558991   0.8204                    \n",
      "    9      0.415817   0.618625   0.799                     \n",
      "    10     0.390795   0.491766   0.8374                    \n",
      "    11     0.375982   0.58053    0.8117                    \n",
      "    12     0.365253   0.493909   0.8436                    \n",
      "    13     0.33955    0.455188   0.8628                    \n",
      "    14     0.321202   0.453856   0.8528                    \n",
      "    15     0.3091     0.443087   0.8606                    \n",
      "    16     0.290657   0.482931   0.8456                    \n",
      "    17     0.273898   0.413584   0.8716                    \n",
      "    18     0.249475   0.354954   0.888                     \n",
      "    19     0.217254   0.477372   0.858                     \n",
      "    20     0.213413   0.4047     0.8733                    \n",
      "    21     0.198407   0.338721   0.8959                    \n",
      "    22     0.168584   0.363589   0.8959                    \n",
      "    23     0.144208   0.361371   0.8905                    \n",
      "    24     0.129404   0.331302   0.9028                    \n",
      "    25     0.106259   0.331938   0.905                     \n",
      "    26     0.082054   0.308093   0.916                      \n",
      "    27     0.055138   0.29559    0.9225                     \n",
      "    28     0.041301   0.287937   0.9257                     \n",
      "    29     0.032677   0.294427   0.9257                     \n",
      "    30     0.028413   0.290703   0.9264                     \n",
      "    31     0.02559    0.288903   0.9273                     \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([0.2889]), 0.9273000017166138]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = PreActResNet(PreActBlock, [2,2,2,2], concatpool=True)\n",
    "learn = ConvLearner.from_model_data(m, data)\n",
    "learn.half()\n",
    "learn.crit = nn.CrossEntropyLoss()\n",
    "learn.metrics = [accuracy]\n",
    "wd=5e-5\n",
    "lr=1.2\n",
    "learn.clip = 3e-2\n",
    "def_phase = {'opt_fn':optim.SGD, 'wds':wd}\n",
    "# TODO: add momentum\n",
    "# %time learn.fit(lr, 1, wds=wd, cycle_len=23, use_clr_beta=(20,22,0.95,0.85), loss_scale=512)\n",
    "phases = [\n",
    "    TrainingPhase(**def_phase, epochs=2, lr=(.04, .08), lr_decay=DecayType.LINEAR, momentum=0.95),\n",
    "    TrainingPhase(**def_phase, epochs=13, lr=(.08,.7), lr_decay=DecayType.LINEAR, momentum=(0.95,0.85), momentum_decay=DecayType.LINEAR),\n",
    "    TrainingPhase(**def_phase, epochs=13, lr=(.7,.04), lr_decay=DecayType.LINEAR, momentum=(0.85,0.95), momentum_decay=DecayType.LINEAR),\n",
    "    TrainingPhase(**def_phase, epochs=4, lr=(.04,.004), lr_decay=DecayType.LINEAR, momentum=(0.95))]\n",
    "\n",
    "learn.fit_opt_sched(phases, data_list=[data], loss_scale=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b6e1a12c99e4490acc9d59438f8a3be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=32), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                 \n",
      "    0      1.592334   2.61505    0.3586    \n",
      "    1      1.22685    1.158192   0.5936                   \n",
      "    2      0.980555   1.431943   0.5561                    \n",
      "    3      0.817612   0.773175   0.7283                    \n",
      "    4      0.674902   0.813979   0.7189                    \n",
      "    5      0.599276   0.534584   0.8153                    \n",
      "    6      0.547498   0.568246   0.8075                    \n",
      "    7      0.499838   0.707054   0.7696                    \n",
      "    8      0.481806   0.526269   0.817                     \n",
      "    9      0.449996   0.56823    0.8215                    \n",
      "    10     0.425169   0.530011   0.8213                    \n",
      "    11     0.41142    0.614642   0.8066                    \n",
      "    12     0.3927     0.587804   0.8254                    \n",
      "    13     0.38734    0.556392   0.8242                    \n",
      "    14     0.374561   0.701079   0.7809                    \n",
      "    15     0.366373   0.649447   0.7988                    \n",
      "    16     0.343805   0.508667   0.8398                    \n",
      "    17     0.314071   0.40359    0.8683                    \n",
      "    18     0.285562   0.478273   0.8511                    \n",
      "    19     0.274275   0.466383   0.8566                    \n",
      "    20     0.24181    0.43267    0.8641                    \n",
      "    21     0.235316   0.558052   0.8351                    \n",
      "    22     0.215716   0.351288   0.8862                    \n",
      "    23     0.19007    0.388906   0.8838                    \n",
      "    24     0.161402   0.343329   0.8944                    \n",
      "    25     0.128041   0.276345   0.9141                    \n",
      "    26     0.103821   0.289493   0.9177                    \n",
      "    27     0.068854   0.244004   0.9302                     \n",
      "    28     0.04855    0.247674   0.9302                     \n",
      "    29     0.037275   0.244547   0.934                      \n",
      "    30     0.030277   0.24766    0.9337                     \n",
      "    31     0.028235   0.246602   0.9323                     \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([0.2466]), 0.9322999992370605]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = PreActResNet(PreActBlock, [2,2,2,2], concatpool=True)\n",
    "learn = ConvLearner.from_model_data(m, data)\n",
    "learn.half()\n",
    "learn.crit = nn.CrossEntropyLoss()\n",
    "learn.metrics = [accuracy]\n",
    "wd=1e-4\n",
    "lr=1.2\n",
    "learn.clip = 3e-1\n",
    "def_phase = {'opt_fn':optim.SGD, 'wds':wd}\n",
    "# TODO: add momentum\n",
    "# %time learn.fit(lr, 1, wds=wd, cycle_len=23, use_clr_beta=(20,22,0.95,0.85), loss_scale=512)\n",
    "phases = [\n",
    "    TrainingPhase(**def_phase, epochs=2, lr=(.04, .08), lr_decay=DecayType.LINEAR, momentum=0.95),\n",
    "    TrainingPhase(**def_phase, epochs=13, lr=(.08,.8), lr_decay=DecayType.LINEAR, momentum=(0.95,0.85), momentum_decay=DecayType.LINEAR),\n",
    "    TrainingPhase(**def_phase, epochs=13, lr=(.8,.04), lr_decay=DecayType.LINEAR, momentum=(0.85,0.95), momentum_decay=DecayType.LINEAR),\n",
    "    TrainingPhase(**def_phase, epochs=4, lr=(.04,.004), lr_decay=DecayType.LINEAR, momentum=(0.95))]\n",
    "\n",
    "learn.fit_opt_sched(phases, data_list=[data], loss_scale=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56ab0e5f33364a4e85eb9bffed8472a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=32), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                 \n",
      "    0      1.557802   1.595108   0.4547    \n",
      "    1      1.241909   1.107443   0.6018                   \n",
      "    2      0.976047   0.955262   0.6627                    \n",
      "    3      0.797054   0.733082   0.7405                    \n",
      "    4      0.689586   1.110039   0.6382                    \n",
      "    5      0.624121   0.912516   0.6856                    \n",
      "    6      0.574387   0.731395   0.7501                    \n",
      "    7      0.558561   1.033392   0.6729                    \n",
      "    8      0.523074   1.060453   0.7047                    \n",
      "    9      0.523337   0.929236   0.6952                    \n",
      "    10     0.522421   0.664197   0.7778                    \n",
      "    11     0.504242   0.665434   0.7818                    \n",
      "    12     0.511172   2.021752   0.5536                    \n",
      "    13     0.519933   1.089162   0.6502                    \n",
      "    14     0.508697   0.614903   0.8005                    \n",
      "    15     0.472782   0.893891   0.702                     \n",
      "    16     0.463143   0.697403   0.7738                    \n",
      "    17     0.451395   0.99462    0.6954                    \n",
      "    18     0.438609   0.564616   0.8067                    \n",
      "    19     0.423693   0.746527   0.756                     \n",
      "    20     0.422321   0.522526   0.8294                    \n",
      "    21     0.386031   0.666569   0.7939                    \n",
      "    22     0.360129   0.589897   0.8044                    \n",
      "    23     0.341046   0.506786   0.83                      \n",
      "    24     0.309207   0.460662   0.8425                    \n",
      "    25     0.271594   0.469501   0.8412                    \n",
      "    26     0.228185   0.340979   0.8872                    \n",
      "    27     0.17152    0.252913   0.9163                    \n",
      "    28     0.1249     0.237675   0.9234                    \n",
      "    29     0.099031   0.239283   0.9233                     \n",
      "    30     0.081482   0.219403   0.9304                     \n",
      "    31     0.06613    0.211139   0.9319                     \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([0.21114]), 0.9319000017166138]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = PreActResNet(PreActBlock, [2,2,2,2], concatpool=True)\n",
    "learn = ConvLearner.from_model_data(m, data)\n",
    "learn.half()\n",
    "learn.crit = nn.CrossEntropyLoss()\n",
    "learn.metrics = [accuracy]\n",
    "wd=2e-4\n",
    "lr=1.2\n",
    "learn.clip = 3e-1\n",
    "def_phase = {'opt_fn':optim.SGD, 'wds':wd}\n",
    "# TODO: add momentum\n",
    "# %time learn.fit(lr, 1, wds=wd, cycle_len=23, use_clr_beta=(20,22,0.95,0.85), loss_scale=512)\n",
    "phases = [\n",
    "    TrainingPhase(**def_phase, epochs=2, lr=(.04, .08), lr_decay=DecayType.LINEAR, momentum=0.95),\n",
    "    TrainingPhase(**def_phase, epochs=13, lr=(.08,.8), lr_decay=DecayType.LINEAR, momentum=(0.95,0.85), momentum_decay=DecayType.LINEAR),\n",
    "    TrainingPhase(**def_phase, epochs=13, lr=(.8,.04), lr_decay=DecayType.LINEAR, momentum=(0.85,0.95), momentum_decay=DecayType.LINEAR),\n",
    "    TrainingPhase(**def_phase, epochs=4, lr=(.04,.01), lr_decay=DecayType.LINEAR, momentum=(0.95))]\n",
    "\n",
    "learn.fit_opt_sched(phases, data_list=[data], loss_scale=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = PreActResNet(PreActBlock, [2,2,2,2], concatpool=True)\n",
    "learn = ConvLearner.from_model_data(m, data)\n",
    "learn.half()\n",
    "learn.crit = nn.CrossEntropyLoss()\n",
    "learn.metrics = [accuracy]\n",
    "wd=2e-4\n",
    "lr=1.2\n",
    "learn.clip = 3e-1\n",
    "def_phase = {'opt_fn':optim.SGD, 'wds':wd}\n",
    "# TODO: add momentum\n",
    "# %time learn.fit(lr, 1, wds=wd, cycle_len=23, use_clr_beta=(20,22,0.95,0.85), loss_scale=512)\n",
    "phases = [\n",
    "    TrainingPhase(**def_phase, epochs=2, lr=(.04, .08), lr_decay=DecayType.LINEAR, momentum=0.95),\n",
    "    TrainingPhase(**def_phase, epochs=13, lr=(.08,.8), lr_decay=DecayType.LINEAR, momentum=(0.95,0.85), momentum_decay=DecayType.LINEAR),\n",
    "    TrainingPhase(**def_phase, epochs=13, lr=(.8,.04), lr_decay=DecayType.LINEAR, momentum=(0.85,0.95), momentum_decay=DecayType.LINEAR),\n",
    "    TrainingPhase(**def_phase, epochs=4, lr=(.04,.01), lr_decay=DecayType.LINEAR, momentum=(0.95))]\n",
    "\n",
    "learn.fit_opt_sched(phases, data_list=[data], loss_scale=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_TTA_accuracy(learn):\n",
    "    preds, targs = learn.TTA()\n",
    "    # combining the predictions across augmented and non augmented inputs\n",
    "    preds = 0.6 * preds[0] + 0.4 * preds[1:].sum(0)\n",
    "    return accuracy_np(preds, targs)\n",
    "\n",
    "def get_TTA_accuracy_2(learn):\n",
    "    log_preds,y = learn.TTA()\n",
    "    preds = np.mean(np.exp(log_preds),0)\n",
    "    acc = accuracy(torch.FloatTensor(preds),torch.LongTensor(y))\n",
    "    print('TTA acc:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ModelData' object has no attribute 'aug_dl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-5457c6e8f82d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_TTA_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-57-e711ae20ceee>\u001b[0m in \u001b[0;36mget_TTA_accuracy\u001b[0;34m(learn)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_TTA_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTTA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;31m# combining the predictions across augmented and non augmented inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.6\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m0.4\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0maccuracy_np\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/fastai/courses/dl2/fastai/learner.py\u001b[0m in \u001b[0;36mTTA\u001b[0;34m(self, n_aug, is_test)\u001b[0m\n\u001b[1;32m    387\u001b[0m         \"\"\"\n\u001b[1;32m    388\u001b[0m         \u001b[0mdl1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_dl\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_test\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval_dl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 389\u001b[0;31m         \u001b[0mdl2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_aug_dl\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_test\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maug_dl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    390\u001b[0m         \u001b[0mpreds1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_with_targs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdl1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m         \u001b[0mpreds1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpreds1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mceil\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_aug\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'ModelData' object has no attribute 'aug_dl'"
     ]
    }
   ],
   "source": [
    "get_TTA_accuracy(learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ModelData' object has no attribute 'aug_dl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-aae691aee1fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_TTA_accuracy_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-57-e711ae20ceee>\u001b[0m in \u001b[0;36mget_TTA_accuracy_2\u001b[0;34m(learn)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_TTA_accuracy_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mlog_preds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTTA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_preds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/fastai/courses/dl2/fastai/learner.py\u001b[0m in \u001b[0;36mTTA\u001b[0;34m(self, n_aug, is_test)\u001b[0m\n\u001b[1;32m    387\u001b[0m         \"\"\"\n\u001b[1;32m    388\u001b[0m         \u001b[0mdl1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_dl\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_test\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval_dl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 389\u001b[0;31m         \u001b[0mdl2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_aug_dl\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_test\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maug_dl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    390\u001b[0m         \u001b[0mpreds1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_with_targs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdl1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m         \u001b[0mpreds1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpreds1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mceil\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_aug\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'ModelData' object has no attribute 'aug_dl'"
     ]
    }
   ],
   "source": [
    "get_TTA_accuracy_2(learn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### END TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = pre_resnet18()\n",
    "learn = ConvLearner.from_model_data(m, data)\n",
    "learn.half()\n",
    "learn.crit = nn.CrossEntropyLoss()\n",
    "learn.metrics = [accuracy]\n",
    "wd=1e-4\n",
    "lr=.6\n",
    "learn.clip = 3e-1\n",
    "def_phase = {'opt_fn':optim.SGD, 'wds':wd}\n",
    "# TODO: add momentum\n",
    "lr=0.6\n",
    "phases = [\n",
    "    TrainingPhase(**def_phase, epochs=1, lr=(.005,.05), lr_decay=DecayType.EXPONENTIAL, momentum=0.95),\n",
    "    TrainingPhase(**def_phase, epochs=6, lr=(.05,.9), lr_decay=DecayType.COSINE, momentum=(0.95,0.85), momentum_decay=DecayType.COSINE),\n",
    "    TrainingPhase(**def_phase, epochs=4, lr=1, momentum=0.85),\n",
    "    TrainingPhase(**def_phase, epochs=7, lr=(.9,.01), lr_decay=DecayType.COSINE, momentum=(0.85,0.95), momentum_decay=DecayType.COSINE),\n",
    "    TrainingPhase(**def_phase, epochs=3, lr=(.01,.0005), lr_decay=DecayType.LINEAR, momentum=(0.95))]\n",
    "\n",
    "learn.fit_opt_sched(phases, data_list=[data], loss_scale=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.sched.plot_lr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = WideResNetConcat(num_groups=3, N=3, num_classes=10, k=1, drop_p=0.)\n",
    "learn = ConvLearner.from_model_data(m, data)\n",
    "learn.half()\n",
    "learn.crit = nn.CrossEntropyLoss()\n",
    "learn.metrics = [accuracy]\n",
    "wd=1e-4\n",
    "lr=1.5\n",
    "learn.clip = 3e-1\n",
    "%time learn.fit(lr, 1, wds=wd, cycle_len=23, use_clr_beta=(12,22,0.95,0.85), loss_scale=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "266px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
