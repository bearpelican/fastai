{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CIFAR 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/paperspace')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.conv_learner import *\n",
    "from fastai.models.cifar10.wideresnet import wrn_22_cat, wrn_22, WideResNetConcat\n",
    "torch.backends.cudnn.benchmark = True\n",
    "PATH = Path.home()/\"data/cifar10/\"\n",
    "os.makedirs(PATH,exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/paperspace/fastai/courses/dl2'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "stats = (np.array([ 0.4914 ,  0.48216,  0.44653]), np.array([ 0.24703,  0.24349,  0.26159]))\n",
    "workers=7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader\n",
    "def pad(img, p=4, padding_mode='reflect'):\n",
    "    return Image.fromarray(np.pad(np.asarray(img), ((p, p), (p, p), (0, 0)), padding_mode))\n",
    "\n",
    "def torch_loader(data_path, size, bs, val_bs=None, prefetcher=True):\n",
    "#     if not os.path.exists(data_path/'train'): download_cifar10(data_path)\n",
    "\n",
    "    val_bs = val_bs or bs\n",
    "    # Data loading code\n",
    "    traindir = str(data_path/'train')\n",
    "    valdir = str(data_path/'test')\n",
    "    tfms = [transforms.ToTensor(), transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))]\n",
    "\n",
    "    train_tfms = transforms.Compose([\n",
    "        pad, # TODO: use `padding` rather than assuming 4\n",
    "        transforms.RandomCrop(size),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "    ] + tfms)\n",
    "\n",
    "    train_dataset = datasets.ImageFolder(traindir, train_tfms)\n",
    "    val_dataset = datasets.ImageFolder(valdir, transforms.Compose(tfms))\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, batch_size=bs, shuffle=True,\n",
    "        num_workers=workers, pin_memory=True)\n",
    "\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset, batch_size=val_bs, shuffle=False,\n",
    "        num_workers=workers, pin_memory=True)\n",
    "    \n",
    "    aug_loader = DataLoader(\n",
    "        datasets.ImageFolder(valdir, train_tfms),\n",
    "        batch_size=bs, shuffle=False,\n",
    "        num_workers=workers, pin_memory=True)\n",
    "\n",
    "    if prefetcher:\n",
    "        train_loader = DataPrefetcher(train_loader)\n",
    "        val_loader = DataPrefetcher(val_loader)\n",
    "        aug_loader = DataPrefetcher(aug_loader)\n",
    "    \n",
    "    data = ModelData(data_path, train_loader, val_loader)\n",
    "    data.sz = size\n",
    "    data.aug_dl = aug_loader\n",
    "    return data\n",
    "\n",
    "# Seems to speed up training by ~2%\n",
    "class DataPrefetcher():\n",
    "    def __init__(self, loader, stop_after=None):\n",
    "        self.loader = loader\n",
    "        self.dataset = loader.dataset\n",
    "        self.stream = torch.cuda.Stream()\n",
    "        self.stop_after = stop_after\n",
    "        self.next_input = None\n",
    "        self.next_target = None\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.loader)\n",
    "\n",
    "    def preload(self):\n",
    "        try:\n",
    "            self.next_input, self.next_target = next(self.loaditer)\n",
    "        except StopIteration:\n",
    "            self.next_input = None\n",
    "            self.next_target = None\n",
    "            return\n",
    "        with torch.cuda.stream(self.stream):\n",
    "            self.next_input = self.next_input.cuda(async=True)\n",
    "            self.next_target = self.next_target.cuda(async=True)\n",
    "\n",
    "    def __iter__(self):\n",
    "        count = 0\n",
    "        self.loaditer = iter(self.loader)\n",
    "        self.preload()\n",
    "        while self.next_input is not None:\n",
    "            torch.cuda.current_stream().wait_stream(self.stream)\n",
    "            input = self.next_input\n",
    "            target = self.next_target\n",
    "            self.preload()\n",
    "            count += 1\n",
    "            yield input, target\n",
    "            if type(self.stop_after) is int and (count > self.stop_after):\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m = WideResNetConcat(num_groups=3, N=3, num_classes=10, k=1, drop_p=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.models.cifar10.wideresnet import wrn_22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bf8da7741e74b0995a283f23ae48c5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=30), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                   \n",
      "    0      1.176328   1.536508   0.5127    \n",
      "    1      0.919135   1.020056   0.6475                      \n",
      " 93%|█████████▎| 364/391 [00:48<00:03,  7.49it/s, loss=0.796]"
     ]
    }
   ],
   "source": [
    "bs=128\n",
    "sz=32\n",
    "data = torch_loader(PATH, sz, bs, 512)\n",
    "\n",
    "# m = PreActResNet(PreActBlock, [2,2,2,2], concatpool=True)\n",
    "# m = ResNet18()\n",
    "m = wrn_22()\n",
    "\n",
    "# m = FP16(m.cuda())\n",
    "learn = Learner.from_model_data(m, data)\n",
    "learn.half()\n",
    "learn.crit = F.cross_entropy\n",
    "# learn.opt_fn = optim.Adam\n",
    "learn.metrics = [accuracy]\n",
    "wd=1e-4\n",
    "lr=0.5\n",
    "# learn.clip = 1e-2\n",
    "\n",
    "learn.opt_fn = partial(optim.SGD, nesterov=True, momentum=0.9)\n",
    "\n",
    "%time learn.fit(lr, 1, wds=wd, cycle_len=30, use_clr_beta=(20,20,0.95,0.85))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs=128\n",
    "sz=32\n",
    "data = torch_loader(PATH, sz, bs, 512)\n",
    "\n",
    "# m = PreActResNet(PreActBlock, [2,2,2,2], concatpool=True)\n",
    "# m = ResNet18()\n",
    "m = wrn_22()\n",
    "\n",
    "# m = FP16(m.cuda())\n",
    "learn = Learner.from_model_data(m, data)\n",
    "learn.half()\n",
    "learn.crit = F.cross_entropy\n",
    "# learn.opt_fn = optim.Adam\n",
    "learn.metrics = [accuracy]\n",
    "wd=1e-4\n",
    "lr=1e-3\n",
    "# learn.clip = 1e-2\n",
    "\n",
    "learn.opt_fn = partial(optim.Adam, betas=(0.95,0.99))\n",
    "\n",
    "%time learn.fit(lr, 1, wds=wd, cycle_len=30, use_clr_beta=(10,7.5,0.95,0.85))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs=128\n",
    "sz=32\n",
    "data = torch_loader(PATH, sz, bs, 512)\n",
    "\n",
    "# m = PreActResNet(PreActBlock, [2,2,2,2], concatpool=True)\n",
    "# m = ResNet18()\n",
    "m = wrn_22()\n",
    "\n",
    "# m = FP16(m.cuda())\n",
    "learn = Learner.from_model_data(m, data)\n",
    "learn.half()\n",
    "learn.crit = F.cross_entropy\n",
    "# learn.opt_fn = optim.Adam\n",
    "learn.metrics = [accuracy]\n",
    "wd=1e-4\n",
    "lr=3e-3\n",
    "# learn.clip = 1e-2\n",
    "\n",
    "learn.opt_fn = partial(optim.Adam, betas=(0.95,0.99))\n",
    "\n",
    "%time learn.fit(lr, 1, wds=wd, cycle_len=30, use_clr_beta=(10,7.5,0.95,0.85))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --\n",
    "# Model definition\n",
    "# Derived from models in `https://github.com/kuangliu/pytorch-cifar`\n",
    "\n",
    "class PreActBlock(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.bn1   = nn.BatchNorm2d(in_channels)\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn2   = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        \n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False)\n",
    "            )\n",
    "            \n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(x))\n",
    "        shortcut = self.shortcut(out) if hasattr(self, 'shortcut') else x\n",
    "        out = self.conv1(out)\n",
    "        out = self.conv2(F.relu(self.bn2(out)))\n",
    "        return out + shortcut\n",
    "\n",
    "\n",
    "class ResNet18(nn.Module):\n",
    "    def __init__(self, num_blocks=[2, 2, 2, 2], num_classes=10):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.in_channels = 64\n",
    "        \n",
    "        self.prep = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            self._make_layer(64, 64, num_blocks[0], stride=1),\n",
    "            self._make_layer(64, 128, num_blocks[1], stride=2),\n",
    "            self._make_layer(128, 256, num_blocks[2], stride=2),\n",
    "            self._make_layer(256, 256, num_blocks[3], stride=2),\n",
    "        )\n",
    "        \n",
    "        self.classifier = nn.Linear(512, num_classes)\n",
    "        \n",
    "    def _make_layer(self, in_channels, out_channels, num_blocks, stride):\n",
    "        \n",
    "        strides = [stride] + [1] * (num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(PreActBlock(in_channels=in_channels, out_channels=out_channels, stride=stride))\n",
    "            in_channels = out_channels\n",
    "        \n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.half()\n",
    "        x = self.prep(x)\n",
    "        \n",
    "        x = self.layers(x)\n",
    "        \n",
    "        x_avg = F.adaptive_avg_pool2d(x, (1, 1))\n",
    "        x_avg = x_avg.view(x_avg.size(0), -1)\n",
    "        \n",
    "        x_max = F.adaptive_max_pool2d(x, (1, 1))\n",
    "        x_max = x_max.view(x_max.size(0), -1)\n",
    "        \n",
    "        x = torch.cat([x_avg, x_max], dim=-1)\n",
    "        \n",
    "        x = self.classifier(x)\n",
    "        \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_TTA_accuracy(learn):\n",
    "    preds, targs = learn.TTA()\n",
    "    # combining the predictions across augmented and non augmented inputs\n",
    "    preds = 0.6 * preds[0] + 0.4 * preds[1:].sum(0)\n",
    "    return accuracy_np(preds, targs)\n",
    "\n",
    "def get_TTA_accuracy_2(learn):\n",
    "    log_preds,y = learn.TTA()\n",
    "    preds = np.mean(np.exp(log_preds),0)\n",
    "    acc = accuracy(torch.FloatTensor(preds),torch.LongTensor(y))\n",
    "    print('TTA acc:', acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "266px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
