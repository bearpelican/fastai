{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CIFAR 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.conv_learner import *\n",
    "from fastai.models.cifar10.wideresnet import wrn_22_cat, wrn_22, WideResNetConcat\n",
    "torch.backends.cudnn.benchmark = True\n",
    "PATH = Path(\"data/cifar10/\")\n",
    "os.makedirs(PATH,exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "stats = (np.array([ 0.4914 ,  0.48216,  0.44653]), np.array([ 0.24703,  0.24349,  0.26159]))\n",
    "\n",
    "bs=512\n",
    "sz=32\n",
    "workers=7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader\n",
    "def pad(img, p=4, padding_mode='reflect'):\n",
    "    return Image.fromarray(np.pad(np.asarray(img), ((p, p), (p, p), (0, 0)), padding_mode))\n",
    "\n",
    "def torch_loader(data_path, size, prefetcher=True):\n",
    "    if not os.path.exists(data_path/'train'): download_cifar10(data_path)\n",
    "\n",
    "    # Data loading code\n",
    "    traindir = str(data_path/'train')\n",
    "    valdir = str(data_path/'test')\n",
    "    tfms = [transforms.ToTensor(), transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))]\n",
    "\n",
    "    train_tfms = transforms.Compose([\n",
    "        pad, # TODO: use `padding` rather than assuming 4\n",
    "        transforms.RandomCrop(size),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "    ] + tfms)\n",
    "\n",
    "    train_dataset = datasets.ImageFolder(traindir, train_tfms)\n",
    "    val_dataset = datasets.ImageFolder(valdir, transforms.Compose(tfms))\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, batch_size=bs, shuffle=True,\n",
    "        num_workers=workers, pin_memory=True)\n",
    "\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset, batch_size=bs, shuffle=False,\n",
    "        num_workers=workers, pin_memory=True)\n",
    "    \n",
    "    aug_loader = DataLoader(\n",
    "        datasets.ImageFolder(valdir, train_tfms),\n",
    "        batch_size=bs, shuffle=False,\n",
    "        num_workers=workers, pin_memory=True)\n",
    "\n",
    "    if prefetcher:\n",
    "        train_loader = DataPrefetcher(train_loader)\n",
    "        val_loader = DataPrefetcher(val_loader)\n",
    "        aug_loader = DataPrefetcher(aug_loader)\n",
    "    \n",
    "    data = ModelData(data_path, train_loader, val_loader)\n",
    "    data.sz = size\n",
    "    data.aug_dl = aug_loader\n",
    "    return data\n",
    "\n",
    "# Seems to speed up training by ~2%\n",
    "class DataPrefetcher():\n",
    "    def __init__(self, loader, stop_after=None):\n",
    "        self.loader = loader\n",
    "        self.dataset = loader.dataset\n",
    "        self.stream = torch.cuda.Stream()\n",
    "        self.stop_after = stop_after\n",
    "        self.next_input = None\n",
    "        self.next_target = None\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.loader)\n",
    "\n",
    "    def preload(self):\n",
    "        try:\n",
    "            self.next_input, self.next_target = next(self.loaditer)\n",
    "        except StopIteration:\n",
    "            self.next_input = None\n",
    "            self.next_target = None\n",
    "            return\n",
    "        with torch.cuda.stream(self.stream):\n",
    "            self.next_input = self.next_input.cuda(async=True)\n",
    "            self.next_target = self.next_target.cuda(async=True)\n",
    "\n",
    "    def __iter__(self):\n",
    "        count = 0\n",
    "        self.loaditer = iter(self.loader)\n",
    "        self.preload()\n",
    "        while self.next_input is not None:\n",
    "            torch.cuda.current_stream().wait_stream(self.stream)\n",
    "            input = self.next_input\n",
    "            target = self.next_target\n",
    "            self.preload()\n",
    "            count += 1\n",
    "            yield input, target\n",
    "            if type(self.stop_after) is int and (count > self.stop_after):\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch_loader(PATH, sz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Pre-activation ResNet in PyTorch.\n",
    "\n",
    "Reference:\n",
    "[1] Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun\n",
    "    Identity Mappings in Deep Residual Networks. arXiv:1603.05027\n",
    "'''\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "class AdaptiveConcatPool2d(nn.Module):\n",
    "    def __init__(self, sz=None):\n",
    "        super().__init__()\n",
    "        sz = sz or (1,1)\n",
    "        self.ap = nn.AdaptiveAvgPool2d(sz)\n",
    "        self.mp = nn.AdaptiveMaxPool2d(sz)\n",
    "    def forward(self, x): return torch.cat([self.mp(x), self.ap(x)], 1)\n",
    "    \n",
    "\n",
    "class PreActBlock(nn.Module):\n",
    "    '''Pre-activation version of the BasicBlock.'''\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(PreActBlock, self).__init__()\n",
    "        self.bn1 = nn.BatchNorm2d(in_planes)\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.bn2.bias.data.zero_()\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(x), inplace=True)\n",
    "        shortcut = self.shortcut(out) if hasattr(self, 'shortcut') else x\n",
    "        out = self.conv1(out)\n",
    "        out = self.conv2(F.relu(self.bn2(out), inplace=True))\n",
    "        out += shortcut\n",
    "        return out\n",
    "\n",
    "\n",
    "class PreActBottleneck(nn.Module):\n",
    "    '''Pre-activation version of the original Bottleneck module.'''\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(PreActBottleneck, self).__init__()\n",
    "        self.bn1 = nn.BatchNorm2d(in_planes)\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, self.expansion*planes, kernel_size=1, bias=False)\n",
    "\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(x))\n",
    "        shortcut = self.shortcut(out) if hasattr(self, 'shortcut') else x\n",
    "        out = self.conv1(out)\n",
    "        out = self.conv2(F.relu(self.bn2(out)))\n",
    "        out = self.conv3(F.relu(self.bn3(out)))\n",
    "        out += shortcut\n",
    "        return out\n",
    "\n",
    "\n",
    "class PreActResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=10, concatpool=False):\n",
    "        super(PreActResNet, self).__init__()\n",
    "        self.in_planes = 64\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
    "        self.pool = AdaptiveConcatPool2d() if concatpool else nn.AdaptiveMaxPool2d((1,1))\n",
    "        \n",
    "        self.linear = nn.Linear(512*block.expansion*(concatpool+1), num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "#         out = F.adaptive_max_pool2d(out, 1)\n",
    "        out = self.pool(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        return F.log_softmax(self.linear(out))\n",
    "\n",
    "def preact_resnet18(): return PreActResNet(PreActBlock, [2,2,2,2])\n",
    "def preact_resnet2332(): return PreActResNet(PreActBlock, [2,3,3,2])\n",
    "def preact_resnet3333(): return PreActResNet(PreActBlock, [3,3,3,3])\n",
    "def preact_resnet34(): return PreActResNet(PreActBlock, [3,4,6,3])\n",
    "def preact_resnet50(): return PreActResNet(PreActBottleneck, [3,4,6,3])\n",
    "def preActResNet101(): return PreActResNet(PreActBottleneck, [3,4,23,3])\n",
    "def preActResNet152(): return PreActResNet(PreActBottleneck, [3,8,36,3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m = WideResNetConcat(num_groups=3, N=3, num_classes=10, k=1, drop_p=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_TTA_accuracy(learn):\n",
    "    preds, targs = learn.TTA()\n",
    "    # combining the predictions across augmented and non augmented inputs\n",
    "    preds = 0.6 * preds[0] + 0.4 * preds[1:].sum(0)\n",
    "    return accuracy_np(preds, targs)\n",
    "\n",
    "def get_TTA_accuracy_2(learn):\n",
    "    log_preds,y = learn.TTA()\n",
    "    preds = np.mean(np.exp(log_preds),0)\n",
    "    acc = accuracy(torch.FloatTensor(preds),torch.LongTensor(y))\n",
    "    print('TTA acc:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f34c6fdf788b4daa9f27da7dd1a79829",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=27), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                 \n",
      "    0      1.412257   1.403386   0.5082    \n",
      "    1      1.059565   1.679631   0.4933                   \n",
      "    2      0.918801   1.390327   0.5803                    \n",
      "    3      0.88158    0.789558   0.7298                    \n",
      "    4      0.665848   0.786746   0.7241                    \n",
      "    5      0.583451   0.895092   0.7075                    \n",
      "    6      0.525627   0.800659   0.7372                    \n",
      "    7      0.485268   0.634775   0.7827                    \n",
      "    8      0.478545   0.624845   0.7952                    \n",
      "    9      0.477403   0.514541   0.824                     \n",
      "    10     0.466429   0.689879   0.7887                    \n",
      "    11     0.455498   0.855484   0.7408                    \n",
      "    12     0.433913   0.924021   0.7304                    \n",
      "    13     0.448637   0.790786   0.7451                    \n",
      "    14     0.439411   0.782915   0.7535                    \n",
      "    15     0.431638   0.541921   0.8207                    \n",
      "    16     0.39196    0.493584   0.8373                    \n",
      "    17     0.379957   0.609241   0.8017                    \n",
      "    18     0.374832   0.600218   0.7982                    \n",
      "    19     0.349529   0.599373   0.8126                    \n",
      "    20     0.338983   0.45155    0.8481                    \n",
      "    21     0.319884   0.520627   0.8371                    \n",
      "    22     0.288729   0.509973   0.8371                    \n",
      "    23     0.271475   0.401732   0.8679                    \n",
      "    24     0.237955   0.37921    0.874                     \n",
      "    25     0.197768   0.293051   0.9024                    \n",
      "    26     0.15262    0.26132    0.9122                    \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([0.26132]), 0.9122000007629395]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = PreActResNet(PreActBlock, [2,2,2,2], concatpool=True)\n",
    "learn = ConvLearner.from_model_data(m, data)\n",
    "learn.half()\n",
    "learn.crit = nn.CrossEntropyLoss()\n",
    "learn.metrics = [accuracy]\n",
    "wd=4e-4\n",
    "# learn.clip = 1e-1\n",
    "def_phase = {'opt_fn':optim.SGD, 'wds':wd}\n",
    "# TODO: add momentum\n",
    "# %time learn.fit(lr, 1, wds=wd, cycle_len=23, use_clr_beta=(20,22,0.95,0.85), loss_scale=512)\n",
    "phases = [\n",
    "    TrainingPhase(**def_phase, epochs=3, lr=(.04, .08), lr_decay=DecayType.LINEAR, momentum=(0.75,0.95), momentum_decay=DecayType.LINEAR),\n",
    "    TrainingPhase(**def_phase, epochs=12, lr=(.08,.7), lr_decay=DecayType.LINEAR, momentum=(0.95,0.85), momentum_decay=DecayType.LINEAR),\n",
    "    TrainingPhase(**def_phase, epochs=12, lr=(.7,.04), lr_decay=DecayType.LINEAR, momentum=(0.85,0.95), momentum_decay=DecayType.LINEAR),\n",
    "]\n",
    "\n",
    "learn.fit_opt_sched(phases, data_list=[data], loss_scale=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('att6-tta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ecbf1b165e14e00838e047944b7da33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=4), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                   \n",
      "    0      0.098208   0.243453   0.9231    \n",
      "    1      0.08352    0.228644   0.9297                     \n",
      "    2      0.068049   0.218568   0.9307                     \n",
      "    3      0.05425    0.213954   0.9319                     \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([0.21395]), 0.9319000005722046]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phases = [TrainingPhase(**def_phase, epochs=4, lr=(.04,.001), lr_decay=DecayType.LINEAR, momentum=(0.95))]\n",
    "learn.fit_opt_sched(phases, data_list=[data], loss_scale=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "tta_data = torch_loader(PATH, sz, prefetcher=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.data_ = tta_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9391"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_TTA_accuracy(learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TTA acc: 0.9383                              \n"
     ]
    }
   ],
   "source": [
    "get_TTA_accuracy_2(learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "584bdebc53da446ea514b0f7b8e5dd98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=27), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 40%|███▉      | 39/98 [00:03<00:05, 11.67it/s, loss=1.76]\n",
      " 42%|████▏     | 41/98 [00:03<00:04, 11.51it/s, loss=1.73]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-154:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/tqdm/_monitor.py\", line 62, in run\n",
      "    for instance in self.tqdm_cls._instances:\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/_weakrefset.py\", line 60, in __iter__\n",
      "    for itemref in self.data:\n",
      "RuntimeError: Set changed size during iteration\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                 \n",
      "    0      1.383582   1.218085   0.5638    \n",
      "    1      1.036185   1.419456   0.5673                   \n",
      "    2      0.910228   1.551581   0.5425                    \n",
      "    3      0.948948   1.163493   0.6279                    \n",
      "    4      0.700445   0.846213   0.7439                    \n",
      "    5      0.581425   0.622831   0.7913                    \n",
      "    6      0.54283    0.678693   0.7741                    \n",
      "    7      0.511617   0.695092   0.7629                    \n",
      "    8      0.476352   0.672634   0.7776                    \n",
      "    9      0.480119   0.597247   0.8089                    \n",
      "    10     0.477554   0.970222   0.7235                    \n",
      "    11     0.466223   0.655534   0.7844                    \n",
      "    12     0.456882   0.973388   0.6928                    \n",
      "    13     0.473979   0.657018   0.789                     \n",
      "    14     0.441907   0.71927    0.7778                    \n",
      "    15     0.450824   0.669261   0.7734                    \n",
      "    16     0.429042   1.461811   0.6863                    \n",
      "    17     0.407678   0.522277   0.8234                    \n",
      "    18     0.376072   0.541817   0.8231                    \n",
      "    19     0.362756   0.645247   0.7993                    \n",
      "    20     0.338842   0.655257   0.8117                    \n",
      "    21     0.314326   0.428773   0.864                     \n",
      "    22     0.284497   0.352003   0.8831                    \n",
      "    23     0.248891   0.388934   0.8738                    \n",
      "    24     0.216144   0.300945   0.9001                    \n",
      "    25     0.181015   0.300718   0.9023                    \n",
      "    26     0.129679   0.256808   0.9188                    \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([0.25681]), 0.9188000005722046]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = PreActResNet(PreActBlock, [2,2,2,2], concatpool=True)\n",
    "learn = ConvLearner.from_model_data(m, data)\n",
    "learn.half()\n",
    "learn.crit = nn.CrossEntropyLoss()\n",
    "learn.metrics = [accuracy]\n",
    "wd=2e-4\n",
    "learn.clip = 3e-1\n",
    "def_phase = {'opt_fn':optim.SGD, 'wds':wd}\n",
    "# TODO: add momentum\n",
    "# %time learn.fit(lr, 1, wds=wd, cycle_len=23, use_clr_beta=(20,22,0.95,0.85), loss_scale=512)\n",
    "phases = [\n",
    "    TrainingPhase(**def_phase, epochs=3, lr=(.04, .08), lr_decay=DecayType.LINEAR, momentum=(0.75,0.95), momentum_decay=DecayType.LINEAR),\n",
    "    TrainingPhase(**def_phase, epochs=12, lr=(.08,1), lr_decay=DecayType.LINEAR, momentum=(0.95,0.85), momentum_decay=DecayType.LINEAR),\n",
    "    TrainingPhase(**def_phase, epochs=12, lr=(1,.04), lr_decay=DecayType.LINEAR, momentum=(0.85,0.95), momentum_decay=DecayType.LINEAR),\n",
    "]\n",
    "\n",
    "learn.fit_opt_sched(phases, data_list=[data], loss_scale=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('att6-lr1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d356775f1e442f382e20e27eb47c87d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=4), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                   \n",
      "    0      0.066247   0.247223   0.9285    \n",
      "    1      0.057653   0.241219   0.9292                     \n",
      "    2      0.050102   0.238205   0.9301                     \n",
      "    3      0.042713   0.235338   0.9313                     \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([0.23534]), 0.9312999992370605]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phases = [TrainingPhase(**def_phase, epochs=4, lr=(.04,.001), lr_decay=DecayType.LINEAR, momentum=(0.95))]\n",
    "learn.fit_opt_sched(phases, data_list=[data], loss_scale=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TTA acc: 0.9358                              \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9385, None)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tta_data = torch_loader(PATH, sz, prefetcher=False)\n",
    "learn.data_ = tta_data\n",
    "get_TTA_accuracy(learn), get_TTA_accuracy_2(learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0dba353b521341e698bbf04e31a22964",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=28), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 35/98 [00:03<00:05, 11.21it/s, loss=1.79] \n",
      " 40%|███▉      | 39/98 [00:03<00:05, 11.72it/s, loss=1.77]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-354:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/tqdm/_monitor.py\", line 62, in run\n",
      "    for instance in self.tqdm_cls._instances:\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/_weakrefset.py\", line 60, in __iter__\n",
      "    for itemref in self.data:\n",
      "RuntimeError: Set changed size during iteration\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                 \n",
      "    0      1.404054   1.398838   0.5089    \n",
      "    1      1.125469   1.860868   0.5295                   \n",
      "    2      0.980382   1.011459   0.6895                    \n",
      "    3      0.740379   0.648137   0.7669                    \n",
      "    4      0.613539   0.834201   0.7225                    \n",
      "    5      0.548261   0.656363   0.7798                    \n",
      "    6      0.494997   0.787101   0.7415                    \n",
      "    7      0.472443   0.612136   0.7947                    \n",
      "    8      0.445408   0.723651   0.7686                    \n",
      "    9      0.430274   0.687877   0.7783                    \n",
      "    10     0.400086   0.58851    0.8105                    \n",
      "    11     0.386951   0.633652   0.7998                    \n",
      "    12     0.391113   0.604603   0.8081                    \n",
      "    13     0.396721   0.642429   0.8031                    \n",
      "    14     0.37233    0.483478   0.8406                    \n",
      "    15     0.355568   0.871443   0.7599                    \n",
      "    16     0.347717   0.602494   0.8051                    \n",
      "    17     0.316023   0.639003   0.808                     \n",
      "    18     0.304786   0.645079   0.8111                    \n",
      "    19     0.281974   0.506238   0.8409                    \n",
      "    20     0.257685   0.571645   0.8322                    \n",
      "    21     0.245392   0.591757   0.8227                    \n",
      "    22     0.228786   0.42865    0.86                      \n",
      "    23     0.210605   0.371441   0.8795                    \n",
      "    24     0.182332   0.40233    0.8747                    \n",
      "    25     0.154363   0.295925   0.905                     \n",
      "    26     0.122373   0.264357   0.9148                    \n",
      "    27     0.090617   0.247673   0.9233                     \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([0.24767]), 0.9233000000953674]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = PreActResNet(PreActBlock, [2,2,2,2], concatpool=True)\n",
    "learn = ConvLearner.from_model_data(m, data)\n",
    "learn.half()\n",
    "learn.crit = nn.CrossEntropyLoss()\n",
    "learn.metrics = [accuracy]\n",
    "wd=2e-4\n",
    "lr=1.2\n",
    "learn.clip = 3e-1\n",
    "def_phase = {'opt_fn':optim.SGD, 'wds':wd}\n",
    "# TODO: add momentum\n",
    "# %time learn.fit(lr, 1, wds=wd, cycle_len=23, use_clr_beta=(20,22,0.95,0.85), loss_scale=512)\n",
    "phases = [\n",
    "    TrainingPhase(**def_phase, epochs=2, lr=(.04, .08), lr_decay=DecayType.LINEAR, momentum=(0.85,0.95), momentum_decay=DecayType.LINEAR),\n",
    "    TrainingPhase(**def_phase, epochs=13, lr=(.08,.7), lr_decay=DecayType.LINEAR, momentum=(0.95,0.85), momentum_decay=DecayType.LINEAR),\n",
    "    TrainingPhase(**def_phase, epochs=13, lr=(.7,.04), lr_decay=DecayType.LINEAR, momentum=(0.85,0.95), momentum_decay=DecayType.LINEAR)\n",
    "]\n",
    "\n",
    "learn.fit_opt_sched(phases, data_list=[data], loss_scale=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('9233')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f639a242be584642ac80e8ce9bd88d01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=5), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                   \n",
      "    0      0.055303   0.235548   0.9271    \n",
      "    1      0.048198   0.240492   0.9281                     \n",
      "    2      0.038738   0.236836   0.9313                     \n",
      "    3      0.034984   0.233395   0.9323                     \n",
      "    4      0.02779    0.232784   0.9327                     \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([0.23278]), 0.9327000002861023]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phases = [TrainingPhase(**def_phase, epochs=5, lr=(.04,.001), lr_decay=DecayType.LINEAR, momentum=(0.95))]\n",
    "learn.fit_opt_sched(phases, data_list=[data], loss_scale=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TTA acc: 0.9391                              \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9396, None)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tta_data = torch_loader(PATH, sz, prefetcher=False)\n",
    "learn.data_ = tta_data\n",
    "get_TTA_accuracy(learn), get_TTA_accuracy_2(learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('9233')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4aa3ddcd3c164f4eab86be41ca56d09a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=5), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 81/98 [00:06<00:01, 12.82it/s, loss=0.0544]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-2596:\n",
      "Process Process-2595:\n",
      "Process Process-2597:\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "Process Process-2593:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Process Process-2592:\n",
      "Process Process-2591:\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 50, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "Process Process-2594:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "Traceback (most recent call last):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-54-e8bcff9ff780>\", line 2, in <module>\n",
      "    learn.fit_opt_sched(phases, data_list=[data], loss_scale=512)\n",
      "  File \"/home/paperspace/fastai/courses/dl2/fastai/learner.py\", line 426, in fit_opt_sched\n",
      "    metrics=metrics, callbacks=callbacks, reg_fn=self.reg_fn, clip=self.clip, fp16=self.fp16, **kwargs)\n",
      "  File \"/home/paperspace/fastai/courses/dl2/fastai/model.py\", line 129, in fit\n",
      "    loss = model_stepper.step(V(x),V(y), epoch)\n",
      "  File \"/home/paperspace/fastai/courses/dl2/fastai/model.py\", line 60, in step\n",
      "    nn.utils.clip_grad_norm(trainable_params_(self.m), self.clip)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/nn/utils/clip_grad.py\", line 26, in clip_grad_norm\n",
      "    param_norm = p.grad.data.norm(norm_type)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 1863, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 1095, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 311, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 345, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/inspect.py\", line 1483, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/inspect.py\", line 1441, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/inspect.py\", line 732, in getmodule\n",
      "    for modname, module in list(sys.modules.items()):\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 175, in handler\n",
      "    _error_if_any_worker_fails()\n",
      "RuntimeError: DataLoader worker (pid 11266) exited unexpectedly with exit code 1.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 50, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "KeyboardInterrupt\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 50, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 55, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 55, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 55, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 50, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torchvision/datasets/folder.py\", line 124, in __getitem__\n",
      "    img = self.transform(img)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 55, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torchvision/transforms/transforms.py\", line 42, in __call__\n",
      "    img = t(img)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torchvision/datasets/folder.py\", line 124, in __getitem__\n",
      "    img = self.transform(img)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torchvision/transforms/transforms.py\", line 42, in __call__\n",
      "    img = t(img)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 55, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "KeyboardInterrupt\n",
      "  File \"<ipython-input-4-957bdd2e6980>\", line 5, in pad\n",
      "    return Image.fromarray(np.pad(np.asarray(img), ((p, p), (p, p), (0, 0)), padding_mode))\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 55, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torchvision/transforms/transforms.py\", line 118, in __call__\n",
      "    return F.normalize(tensor, self.mean, self.std)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/numpy/lib/arraypad.py\", line 1297, in pad\n",
      "    if not np.asarray(pad_width).dtype.kind == 'i':\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torchvision/transforms/functional.py\", line 160, in normalize\n",
      "    for t, m, s in zip(tensor, mean, std):\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/numpy/core/numeric.py\", line 492, in asarray\n",
      "    return array(a, dtype, copy=False, order=order)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torchvision/datasets/folder.py\", line 124, in __getitem__\n",
      "    img = self.transform(img)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torchvision/transforms/transforms.py\", line 42, in __call__\n",
      "    img = t(img)\n",
      "KeyboardInterrupt\n",
      "  File \"<ipython-input-4-957bdd2e6980>\", line 5, in pad\n",
      "    return Image.fromarray(np.pad(np.asarray(img), ((p, p), (p, p), (0, 0)), padding_mode))\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/PIL/Image.py\", line 2438, in fromarray\n",
      "    return frombuffer(mode, size, obj, \"raw\", rawmode, 0, 1)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/PIL/Image.py\", line 2391, in frombuffer\n",
      "    return frombytes(mode, size, data, decoder_name, args)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/PIL/Image.py\", line 2320, in frombytes\n",
      "    if decoder_name == \"raw\" and args == ():\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "phases = [TrainingPhase(**def_phase, epochs=5, lr=(.04,.001), lr_decay=DecayType.LINEAR, momentum=(0.95))]\n",
    "learn.fit_opt_sched(phases, data_list=[data], loss_scale=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96bee696da9f4a74b510d1754a03f2b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=26), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/98 [00:00<?, ?it/s]                   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-535:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/tqdm/_monitor.py\", line 62, in run\n",
      "    for instance in self.tqdm_cls._instances:\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/_weakrefset.py\", line 60, in __iter__\n",
      "    for itemref in self.data:\n",
      "RuntimeError: Set changed size during iteration\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                 \n",
      "    0      1.406422   1.363898   0.5187    \n",
      "    1      1.143778   1.443159   0.5407                   \n",
      "    2      0.958711   0.92218    0.6963                    \n",
      "    3      0.726452   0.822333   0.7298                    \n",
      "    4      0.592805   0.730651   0.7525                    \n",
      "    5      0.523831   0.721372   0.7676                    \n",
      "    6      0.492072   0.555648   0.8184                    \n",
      "    7      0.454976   0.671316   0.7736                    \n",
      "    8      0.433841   0.5424     0.8194                    \n",
      "    9      0.408343   0.630389   0.7996                    \n",
      "    10     0.380653   0.501859   0.8373                    \n",
      "    11     0.36229    0.790254   0.7638                    \n",
      "    12     0.36454    0.798706   0.759                     \n",
      "    13     0.352369   0.544393   0.8193                    \n",
      "    14     0.320008   0.490618   0.8425                    \n",
      "    15     0.310419   0.677558   0.8042                    \n",
      "    16     0.287837   0.425762   0.8665                    \n",
      "    17     0.2661     0.494402   0.8497                    \n",
      "    18     0.256139   0.440512   0.8529                    \n",
      "    19     0.232767   0.348588   0.887                     \n",
      "    20     0.215108   0.431227   0.8712                    \n",
      "    21     0.190576   0.415757   0.8675                    \n",
      "    22     0.169567   0.338125   0.8966                    \n",
      "    23     0.147239   0.301426   0.9096                    \n",
      "    24     0.114129   0.284539   0.9127                    \n",
      "    25     0.085305   0.257131   0.9229                     \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([0.25713]), 0.9229000001907348]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = PreActResNet(PreActBlock, [2,2,2,2], concatpool=True)\n",
    "learn = ConvLearner.from_model_data(m, data)\n",
    "learn.half()\n",
    "learn.crit = nn.CrossEntropyLoss()\n",
    "learn.metrics = [accuracy]\n",
    "wd=2e-4\n",
    "lr=1.2\n",
    "learn.clip = 3e-1\n",
    "def_phase = {'opt_fn':optim.SGD, 'wds':wd}\n",
    "# TODO: add momentum\n",
    "# %time learn.fit(lr, 1, wds=wd, cycle_len=23, use_clr_beta=(20,22,0.95,0.85), loss_scale=512)\n",
    "phases = [\n",
    "    TrainingPhase(**def_phase, epochs=2, lr=(.04, .07), lr_decay=DecayType.LINEAR, momentum=(0.85,0.95), momentum_decay=DecayType.LINEAR),\n",
    "    TrainingPhase(**def_phase, epochs=11, lr=(.07,.6), lr_decay=DecayType.LINEAR, momentum=(0.95,0.85), momentum_decay=DecayType.LINEAR),\n",
    "    TrainingPhase(**def_phase, epochs=13, lr=(.6,.04), lr_decay=DecayType.LINEAR, momentum=(0.85,0.95), momentum_decay=DecayType.LINEAR)\n",
    "]\n",
    "\n",
    "learn.fit_opt_sched(phases, data_list=[data], loss_scale=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('9229')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba7dbf97c86b436d8e12da78e1e510e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=6), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                   \n",
      "    0      0.055875   0.239902   0.9263    \n",
      "    1      0.04695    0.248908   0.9281                     \n",
      "    2      0.036955   0.241113   0.9321                     \n",
      "    3      0.029449   0.241012   0.9338                     \n",
      "    4      0.025771   0.246175   0.9335                     \n",
      "    5      0.021908   0.240626   0.9351                     \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([0.24063]), 0.935100000667572]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phases = [TrainingPhase(**def_phase, epochs=6, lr=(.04,.001), lr_decay=DecayType.LINEAR, momentum=(0.95))]\n",
    "learn.fit_opt_sched(phases, data_list=[data], loss_scale=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TTA acc: 0.9393                              \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9414, None)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tta_data = torch_loader(PATH, sz, prefetcher=False)\n",
    "learn.data_ = tta_data\n",
    "get_TTA_accuracy(learn), get_TTA_accuracy_2(learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a4d4f7f02c94aa585f0187f8e12a88c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=26), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                 \n",
      "    0      1.401288   1.431436   0.5146    \n",
      "    1      1.128926   2.922088   0.3794                   \n",
      "    2      0.948805   1.142918   0.666                     \n",
      "    3      0.744348   0.710946   0.7587                    \n",
      "    4      0.61139    0.679687   0.77                      \n",
      "    5      0.542358   0.716951   0.771                     \n",
      "    6      0.470684   0.574388   0.8077                    \n",
      "    7      0.430563   0.605658   0.8065                    \n",
      "    8      0.404186   0.527993   0.8192                    \n",
      "    9      0.37285    0.484941   0.8285                    \n",
      "    10     0.363053   0.862881   0.7338                    \n",
      "    11     0.350714   0.499591   0.8293                    \n",
      "    12     0.346253   0.487284   0.8268                    \n",
      "    13     0.333914   0.552516   0.8181                    \n",
      "    14     0.297226   0.560681   0.8258                    \n",
      "    15     0.28224    0.472441   0.8566                    \n",
      "    16     0.255519   0.44014    0.8612                    \n",
      "    17     0.24434    0.446731   0.8549                    \n",
      "    18     0.228608   0.378746   0.8713                    \n",
      "    19     0.215422   0.405493   0.8709                    \n",
      "    20     0.197794   0.46489    0.8625                    \n",
      "    21     0.177147   0.337936   0.8938                    \n",
      "    22     0.1612     0.330391   0.8953                    \n",
      "    23     0.131283   0.377641   0.8878                    \n",
      "    24     0.110179   0.321023   0.902                     \n",
      "    25     0.077982   0.25818    0.9226                     \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([0.25818]), 0.9226000002861023]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = PreActResNet(PreActBlock, [2,2,2,2], concatpool=True)\n",
    "learn = ConvLearner.from_model_data(m, data)\n",
    "learn.half()\n",
    "learn.crit = nn.CrossEntropyLoss()\n",
    "learn.metrics = [accuracy]\n",
    "wd=2e-4\n",
    "lr=1.2\n",
    "learn.clip = 1e-1\n",
    "def_phase = {'opt_fn':optim.SGD, 'wds':wd}\n",
    "# TODO: add momentum\n",
    "# %time learn.fit(lr, 1, wds=wd, cycle_len=23, use_clr_beta=(20,22,0.95,0.85), loss_scale=512)\n",
    "phases = [\n",
    "    TrainingPhase(**def_phase, epochs=2, lr=(.04, .07), lr_decay=DecayType.LINEAR, momentum=(0.85,0.95), momentum_decay=DecayType.LINEAR),\n",
    "    TrainingPhase(**def_phase, epochs=10, lr=(.07,.5), lr_decay=DecayType.LINEAR, momentum=(0.95,0.85), momentum_decay=DecayType.LINEAR),\n",
    "    TrainingPhase(**def_phase, epochs=13, lr=(.5,.04), lr_decay=DecayType.LINEAR, momentum=(0.85,0.95), momentum_decay=DecayType.LINEAR)\n",
    "]\n",
    "\n",
    "learn.fit_opt_sched(phases, data_list=[data], loss_scale=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('9226')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1c5c989ae924e1eb9bd2d160f62a005",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=6), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                   \n",
      "    0      0.054579   0.259938   0.9234    \n",
      "    1      0.04359    0.254944   0.9286                     \n",
      "    2      0.035823   0.251349   0.9305                     \n",
      "    3      0.028213   0.246712   0.9333                     \n",
      "    4      0.022769   0.248657   0.9321                     \n",
      "    5      0.019539   0.247696   0.9339                     \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([0.2477]), 0.9339000003814697]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phases = [TrainingPhase(**def_phase, epochs=6, lr=(.04,.001), lr_decay=DecayType.LINEAR, momentum=(0.95))]\n",
    "learn.fit_opt_sched(phases, data_list=[data], loss_scale=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TTA acc: 0.9395                              \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9393, None)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tta_data = torch_loader(PATH, sz, prefetcher=False)\n",
    "learn.data_ = tta_data\n",
    "get_TTA_accuracy(learn), get_TTA_accuracy_2(learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9e3118840cf40f9817a5946774ce090",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=26), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                 \n",
      "    0      1.414748   1.664819   0.4772    \n",
      "    1      1.134363   1.457289   0.5645                   \n",
      "    2      1.015202   0.965186   0.6746                   \n",
      "    3      0.765109   0.752077   0.7422                    \n",
      "    4      0.642791   0.590479   0.8004                    \n",
      "    5      0.569069   0.658552   0.774                     \n",
      "    6      0.526559   0.699446   0.7631                    \n",
      "    7      0.506984   0.762919   0.7462                    \n",
      "    8      0.495577   0.660882   0.7777                    \n",
      "    9      0.470361   0.681891   0.7611                    \n",
      "    10     0.469142   0.791516   0.7358                    \n",
      "    11     0.450069   0.658498   0.7799                    \n",
      "    12     0.442187   0.752826   0.761                     \n",
      "    13     0.421857   0.599802   0.7982                    \n",
      "    14     0.407977   0.645302   0.7831                    \n",
      "    15     0.395819   0.4686     0.8443                    \n",
      "    16     0.384324   0.529405   0.8254                    \n",
      "    17     0.373684   0.498073   0.8294                    \n",
      "    18     0.359544   0.558181   0.8112                    \n",
      "    19     0.343794   0.585386   0.8094                    \n",
      "    20     0.31777    0.616827   0.8036                    \n",
      "    21     0.295358   0.39194    0.8649                    \n",
      "    22     0.270472   0.373388   0.8728                    \n",
      "    23     0.248052   0.330323   0.8873                    \n",
      "    24     0.203575   0.312367   0.8944                    \n",
      "    25     0.158038   0.280325   0.9067                    \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([0.28032]), 0.9066999999046326]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = PreActResNet(PreActBlock, [2,2,2,2], concatpool=True)\n",
    "learn = ConvLearner.from_model_data(m, data)\n",
    "learn.half()\n",
    "learn.crit = nn.CrossEntropyLoss()\n",
    "learn.metrics = [accuracy]\n",
    "wd=5e-4\n",
    "lr=1.2\n",
    "learn.clip = 3e-1\n",
    "def_phase = {'opt_fn':optim.SGD, 'wds':wd}\n",
    "# TODO: add momentum\n",
    "# %time learn.fit(lr, 1, wds=wd, cycle_len=23, use_clr_beta=(20,22,0.95,0.85), loss_scale=512)\n",
    "phases = [\n",
    "    TrainingPhase(**def_phase, epochs=2, lr=(.04, .07), lr_decay=DecayType.LINEAR, momentum=(0.85,0.95), momentum_decay=DecayType.LINEAR),\n",
    "    TrainingPhase(**def_phase, epochs=11, lr=(.07,.6), lr_decay=DecayType.LINEAR, momentum=(0.95,0.85), momentum_decay=DecayType.LINEAR),\n",
    "    TrainingPhase(**def_phase, epochs=13, lr=(.6,.04), lr_decay=DecayType.LINEAR, momentum=(0.85,0.95), momentum_decay=DecayType.LINEAR)\n",
    "]\n",
    "\n",
    "learn.fit_opt_sched(phases, data_list=[data], loss_scale=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8a45c442fbb456cb9527dfdee0713e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=6), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                  \n",
      "    0      0.110044   0.258751   0.9148    \n",
      "    1      0.093127   0.245846   0.9266                     \n",
      "    2      0.07675    0.243798   0.9239                     \n",
      "    3      0.063608   0.224439   0.9331                     \n",
      "    4      0.050007   0.22053    0.9326                     \n",
      "    5      0.039199   0.217854   0.9353                     \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([0.21785]), 0.935300000667572]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phases = [TrainingPhase(**def_phase, epochs=6, lr=(.04,.001), lr_decay=DecayType.LINEAR, momentum=(0.95))]\n",
    "learn.fit_opt_sched(phases, data_list=[data], loss_scale=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TTA acc: 0.9407                              \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9398, None)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tta_data = torch_loader(PATH, sz, prefetcher=False)\n",
    "learn.data_ = tta_data\n",
    "get_TTA_accuracy(learn), get_TTA_accuracy_2(learn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### END TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = pre_resnet18()\n",
    "learn = ConvLearner.from_model_data(m, data)\n",
    "learn.half()\n",
    "learn.crit = nn.CrossEntropyLoss()\n",
    "learn.metrics = [accuracy]\n",
    "wd=1e-4\n",
    "lr=.6\n",
    "learn.clip = 3e-1\n",
    "def_phase = {'opt_fn':optim.SGD, 'wds':wd}\n",
    "# TODO: add momentum\n",
    "lr=0.6\n",
    "phases = [\n",
    "    TrainingPhase(**def_phase, epochs=1, lr=(.005,.05), lr_decay=DecayType.EXPONENTIAL, momentum=0.95),\n",
    "    TrainingPhase(**def_phase, epochs=6, lr=(.05,.9), lr_decay=DecayType.COSINE, momentum=(0.95,0.85), momentum_decay=DecayType.COSINE),\n",
    "    TrainingPhase(**def_phase, epochs=4, lr=1, momentum=0.85),\n",
    "    TrainingPhase(**def_phase, epochs=7, lr=(.9,.01), lr_decay=DecayType.COSINE, momentum=(0.85,0.95), momentum_decay=DecayType.COSINE),\n",
    "    TrainingPhase(**def_phase, epochs=3, lr=(.01,.0005), lr_decay=DecayType.LINEAR, momentum=(0.95))]\n",
    "\n",
    "learn.fit_opt_sched(phases, data_list=[data], loss_scale=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.sched.plot_lr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = WideResNetConcat(num_groups=3, N=3, num_classes=10, k=1, drop_p=0.)\n",
    "learn = ConvLearner.from_model_data(m, data)\n",
    "learn.half()\n",
    "learn.crit = nn.CrossEntropyLoss()\n",
    "learn.metrics = [accuracy]\n",
    "wd=1e-4\n",
    "lr=1.5\n",
    "learn.clip = 3e-1\n",
    "%time learn.fit(lr, 1, wds=wd, cycle_len=23, use_clr_beta=(12,22,0.95,0.85), loss_scale=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "266px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
