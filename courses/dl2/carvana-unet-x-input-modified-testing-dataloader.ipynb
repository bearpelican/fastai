{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.conv_learner import *\n",
    "from fastai.dataset import *\n",
    "\n",
    "from pathlib import Path\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = Path('data/carvana')\n",
    "MASKS_FN = 'train_masks.csv'\n",
    "META_FN = 'metadata.csv'\n",
    "masks_csv = pd.read_csv(PATH/MASKS_FN)\n",
    "meta_csv = pd.read_csv(PATH/META_FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_img(im, figsize=None, ax=None, alpha=None):\n",
    "    if not ax: fig,ax = plt.subplots(figsize=figsize)\n",
    "    ax.imshow(im, alpha=alpha)\n",
    "    ax.set_axis_off()\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DN = 'train-128'\n",
    "MASKS_DN = 'train_masks-128'\n",
    "sz = 128\n",
    "bs = 64\n",
    "nw = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MatchedFilesDataset(FilesDataset):\n",
    "    def __init__(self, fnames, y, transform, path):\n",
    "        self.y=y\n",
    "        assert(len(fnames)==len(y))\n",
    "        super().__init__(fnames, transform, path)\n",
    "    def get_y(self, i): return open_image(os.path.join(self.path, self.y[i]))\n",
    "    def get_c(self): return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_names = np.array([Path(TRAIN_DN)/o for o in masks_csv['img']])\n",
    "y_names = np.array([Path(MASKS_DN)/f'{o[:-4]}_mask.png' for o in masks_csv['img']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_idxs = list(range(1008))\n",
    "((val_x,trn_x),(val_y,trn_y)) = split_by_idx(val_idxs, x_names, y_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_tfms = [RandomRotate(4, tfm_y=TfmType.PIXEL),\n",
    "            RandomFlip(tfm_y=TfmType.PIXEL),\n",
    "            RandomLighting(0.05, 0.05)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfms = tfms_from_model(resnet34, sz, crop_type=CropType.NO, tfm_y=TfmType.NO, aug_tfms=aug_tfms)\n",
    "datasets = ImageData.get_ds(MatchedFilesDataset, (trn_x[:10],trn_y[:10]), (val_x[:10],val_y[:10]), tfms, path=PATH)\n",
    "md = ImageData(PATH, datasets, bs, num_workers=16, classes=None)\n",
    "denorm = md.trn_ds.denorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fastai.dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "ltpe = fastai.dataloader.LazyThreadPoolExecutor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tpe = LazyThreadPoolExecutor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce5064b49a034ed89ba597e4cf4e521c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<fastai.dataset.ImageData at 0x7fd3923b9358>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "md.resize(64, PATH/'test/resized')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_dl_it = iter(md.trn_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "Chunking instead\n",
      "17 ms ± 118 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit for x in iter(md.trn_dl): pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunking instead\n",
      "37.4 ns ± 0.913 ns per loop (mean ± std. dev. of 7 runs, 10000000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit for x in trn_dl_it: pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying new data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "md2 = ImageData(PATH, datasets, bs, num_workers=16, classes=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_dl2 = md2.trn_dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_dl2.lazy_loader = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_dl2_it = iter(trn_dl2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "Using lazy threadpool- no batch\n",
      "17.1 ms ± 125 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit for x in iter(trn_dl2): pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using lazy threadpool- no batch\n",
      "37.7 ns ± 0.386 ns per loop (mean ± std. dev. of 7 runs, 10000000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit for x in trn_dl2_it: pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple upsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = resnet34\n",
    "cut,lr_cut = model_meta[f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_base():\n",
    "    layers = cut_model(f(True), cut)\n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_loss(pred,targ):\n",
    "    return F.binary_cross_entropy_with_logits(pred[:,0],targ[...,0])\n",
    "\n",
    "def mask_acc(pred,targ): return accuracy_multi(pred[:,0], targ[...,0], 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice(pred, targs):\n",
    "    m1 = (pred[:,0]>0).float()\n",
    "    m2 = targs[...,0]\n",
    "    return 2. * (m1*m2).sum() / (m1+m2).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StdUpsample(nn.Module):\n",
    "    def __init__(self, nin, nout):\n",
    "        super().__init__()\n",
    "        self.conv = nn.ConvTranspose2d(nin, nout, 2, stride=2)\n",
    "        self.bn = nn.BatchNorm2d(nout)\n",
    "        \n",
    "    def forward(self, x): return self.bn(F.relu(self.conv(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Upsample34(nn.Module):\n",
    "    def __init__(self, rn):\n",
    "        super().__init__()\n",
    "        self.rn = rn\n",
    "        self.up1 = StdUpsample(512,256)\n",
    "        self.up2 = StdUpsample(256,256)\n",
    "        self.up3 = StdUpsample(256,256)\n",
    "        self.up4 = StdUpsample(256,256)\n",
    "        self.up5 = nn.ConvTranspose2d(256, 1, 2, stride=2)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = F.relu(self.rn(x))\n",
    "        x = self.up1(x)\n",
    "        x = self.up2(x)\n",
    "        x = self.up3(x)        \n",
    "        x = self.up4(x)\n",
    "        x = self.up5(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_base = get_base()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
       "  (2): ReLU(inplace)\n",
       "  (3): MaxPool2d(kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), dilation=(1, 1), ceil_mode=False)\n",
       "  (4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
       "    )\n",
       "  )\n",
       "  (5): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "    )\n",
       "    (3): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "    )\n",
       "  )\n",
       "  (6): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "    )\n",
       "    (3): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "    )\n",
       "    (4): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "    )\n",
       "    (5): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "    )\n",
       "  )\n",
       "  (7): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UpsampleModel():\n",
    "    def __init__(self,model,name='upsample'):\n",
    "        self.model,self.name = model,name\n",
    "\n",
    "    def get_layer_groups(self, precompute):\n",
    "        lgs = list(split_by_idxs(children(self.model.rn), [lr_cut]))\n",
    "        return lgs + [children(self.model)[1:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = to_gpu(Upsample34(m_base))\n",
    "models = UpsampleModel(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = ConvLearner(md, models)\n",
    "learn.opt_fn=optim.Adam\n",
    "learn.crit=mask_loss\n",
    "learn.metrics=[mask_acc,dice]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.freeze_to(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23c48954f216427183ca412d80fb499a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 55/64 [00:11<00:01,  4.71it/s, loss=2.69]     "
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.lr_find()\n",
    "learn.sched.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=4e-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8668ed0305514bdb99c1135d16e9cef0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=4), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 29/64 [00:07<00:09,  3.75it/s, loss=0.206]\n",
      " 48%|████▊     | 31/64 [00:08<00:08,  3.87it/s, loss=0.195]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-12:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/tqdm/_tqdm.py\", line 144, in run\n",
      "    for instance in self.tqdm_cls._instances:\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/_weakrefset.py\", line 60, in __iter__\n",
      "    for itemref in self.data:\n",
      "RuntimeError: Set changed size during iteration\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   mask_acc   dice           \n",
      "    0      0.10468    0.053746   0.976766   0.946428  \n",
      "    1      0.056676   0.037985   0.983176   0.961703        \n",
      "    2      0.040433   0.036181   0.986258   0.963986        \n",
      "    3      0.032533   0.029013   0.987332   0.971693        \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.029013293, 0.9873316697776318, 0.9716928716679694]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.fit(lr,1,cycle_len=4,use_clr=(20,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('tmp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('tmp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()\n",
    "learn.bn_freeze(True)\n",
    "lrs = np.array([lr/100,lr/10,lr])/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40ef90e126514a38bb47abb14321812b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=4), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   mask_acc   dice            \n",
      "    0      0.027986   0.02791    0.987853   0.972623  \n",
      "    1      0.026095   0.025905   0.989134   0.974987        \n",
      "    2      0.024183   0.024827   0.989715   0.97614         \n",
      "    3      0.022674   0.023912   0.990234   0.977251        \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.023912037, 0.9902342148125172, 0.9772508550883112]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.fit(lrs,1,cycle_len=4,use_clr=(20,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('128')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## U-net (ish)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Upsample34' object has no attribute 'sfs'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-8ca9b0c980cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m[\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msfs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    396\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0;32m--> 398\u001b[0;31m             type(self).__name__, name))\n\u001b[0m\u001b[1;32m    399\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Upsample34' object has no attribute 'sfs'"
     ]
    }
   ],
   "source": [
    "[o.features.size() for o in m.sfs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SaveFeatures():\n",
    "    features=None\n",
    "    def __init__(self, m): self.hook = m.register_forward_hook(self.hook_fn)\n",
    "    def hook_fn(self, module, input, output):\n",
    "#         pdb.set_trace()\n",
    "        self.features = output\n",
    "    def remove(self): self.hook.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnetBlock(nn.Module):\n",
    "    def __init__(self, up_in, x_in, n_out):\n",
    "        super().__init__()\n",
    "        up_out = x_out = n_out//2\n",
    "        self.x_conv  = nn.Conv2d(x_in,  x_out,  1)\n",
    "        self.tr_conv = nn.ConvTranspose2d(up_in, up_out, 2, stride=2)\n",
    "        self.bn = nn.BatchNorm2d(n_out)\n",
    "        \n",
    "    def forward(self, up_p, x_p):\n",
    "        up_p = self.tr_conv(up_p)\n",
    "        x_p = self.x_conv(x_p)\n",
    "        cat_p = torch.cat([up_p,x_p], dim=1)\n",
    "        return self.bn(F.relu(cat_p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Unet34(nn.Module):\n",
    "    def __init__(self, rn):\n",
    "        super().__init__()\n",
    "        self.rn = rn\n",
    "        self.sfs = [SaveFeatures(rn[i]) for i in [2,4,5,6]]\n",
    "        self.up1 = UnetBlock(512,256,256)\n",
    "        self.up2 = UnetBlock(256,128,256)\n",
    "        self.up3 = UnetBlock(256,64,256)\n",
    "        self.up4 = UnetBlock(256,64,256)\n",
    "        self.up5 = UnetBlock(256,64,256)\n",
    "        self.up6  = nn.Conv2d(256,1,1)\n",
    "        self.x_skip = nn.Sequential(\n",
    "            nn.Conv2d(3,64,1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x_input = x\n",
    "        x_skip = self.x_skip(x_input)\n",
    "        x = F.relu(self.rn(x))\n",
    "        x = self.up1(x, self.sfs[3].features)\n",
    "        x = self.up2(x, self.sfs[2].features)\n",
    "        x = self.up3(x, self.sfs[1].features)\n",
    "        x = self.up4(x, self.sfs[0].features)\n",
    "        x = self.up5(x, x_skip)\n",
    "        x = self.up6(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_base = get_base()\n",
    "m = to_gpu(Unet34(m_base))\n",
    "models = UpsampleModel(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unet34(\n",
       "  (rn): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
       "    (2): ReLU(inplace)\n",
       "    (3): MaxPool2d(kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), dilation=(1, 1), ceil_mode=False)\n",
       "    (4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
       "      )\n",
       "    )\n",
       "    (5): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "      )\n",
       "      (3): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "      )\n",
       "    )\n",
       "    (6): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      )\n",
       "      (3): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      )\n",
       "      (4): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      )\n",
       "      (5): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      )\n",
       "    )\n",
       "    (7): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (up1): UnetBlock(\n",
       "    (x_conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (tr_conv): ConvTranspose2d(512, 128, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "  )\n",
       "  (up2): UnetBlock(\n",
       "    (x_conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (tr_conv): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "  )\n",
       "  (up3): UnetBlock(\n",
       "    (x_conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (tr_conv): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "  )\n",
       "  (up4): UnetBlock(\n",
       "    (x_conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (tr_conv): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "  )\n",
       "  (up5): UnetBlock(\n",
       "    (x_conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (tr_conv): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "  )\n",
       "  (up6): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (x_skip): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = ConvLearner(md, models)\n",
    "learn.opt_fn=optim.Adam\n",
    "learn.crit=mask_loss\n",
    "learn.metrics=[mask_acc,dice]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.freeze_to(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4e084dbc3d14cbd81aec3cdbdc541a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 57/64 [00:17<00:02,  3.21it/s, loss=1.59] "
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9fd2f260b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.lr_find()\n",
    "learn.sched.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=4e-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4c868d6134148fbad46416fd143b56d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=8), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   mask_acc   dice            \n",
      "    0      0.064692   0.039262   0.985964   0.964238  \n",
      "    1      0.036393   0.02568    0.989556   0.975803        \n",
      "    2      0.026931   0.023305   0.990196   0.978063        \n",
      "    3      0.023432   0.022783   0.990377   0.978733        \n",
      "    4      0.021797   0.021687   0.991637   0.979777        \n",
      "    5      0.020757   0.020986   0.992195   0.980544        \n",
      "    6      0.019293   0.019377   0.992117   0.982004        \n",
      "    7      0.018407   0.019017   0.9926     0.982423        \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.019017436, 0.9925998263061047, 0.9824233977022722]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.fit(lr,1,cycle_len=8,use_clr=(20,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('128urn-xrblock-tmp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('128urn-xrblock-tmp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.lr_find()\n",
    "learn.sched.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()\n",
    "learn.bn_freeze(True)\n",
    "lrs = np.array([lr/100,lr/10,lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb299ae97f74494ab20ceeab0d967d43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=40), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   mask_acc   dice            \n",
      "    0      0.020787   0.018369   0.992393   0.982856  \n",
      "    1      0.019764   0.01799    0.992471   0.983123        \n",
      "    2      0.021163   0.493888   0.821824   0.344646        \n",
      "    3      40.726054  1.184134   0.800399   0.059006       \n",
      "    4      11.463556  0.391348   0.862363   0.576072      \n",
      "    5      3.423854   0.381247   0.856357   0.581776      \n",
      "    6      1.217106   0.379563   0.865117   0.589644      \n",
      "    7      0.606364   0.378012   0.863082   0.59427        \n",
      "    8      0.43625    0.369244   0.865148   0.604186       \n",
      "    9      0.3907     0.370075   0.864737   0.623798       \n",
      "    10     0.388189   0.388279   0.862228   0.578523       \n",
      " 59%|█████▉    | 38/64 [00:15<00:10,  2.50it/s, loss=0.391]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-3e9cae1df711>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcycle_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0muse_clr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/fastai/courses/dl2/fastai/learner.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, lrs, n_cycle, wds, **kwargs)\u001b[0m\n\u001b[1;32m    212\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0mlayer_opt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_layer_opt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_gen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer_opt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_cycle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwarm_up\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/fastai/courses/dl2/fastai/learner.py\u001b[0m in \u001b[0;36mfit_gen\u001b[0;34m(self, model, data, layer_opt, n_cycle, cycle_len, cycle_mult, cycle_save_name, best_save_name, use_clr, metrics, callbacks, use_wd_sched, norm_wds, wds_sched_mult, **kwargs)\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0mn_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum_geom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcycle_len\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcycle_len\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcycle_mult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_cycle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m         return fit(model, data, n_epoch, layer_opt.opt, self.crit,\n\u001b[0;32m--> 161\u001b[0;31m             metrics=metrics, callbacks=callbacks, reg_fn=self.reg_fn, clip=self.clip, **kwargs)\n\u001b[0m\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_layer_groups\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_layer_groups\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/fastai/courses/dl2/fastai/model.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(model, data, epochs, opt, crit, metrics, callbacks, stepper, **kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m             \u001b[0mbatch_num\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mcb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstepper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m             \u001b[0mavg_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mavg_loss\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mavg_mom\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mavg_mom\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0mdebias_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mavg_loss\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mavg_mom\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mbatch_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/fastai/courses/dl2/fastai/model.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, xs, y, epoch)\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mraw_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcrit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreg_fn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreg_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxtra\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m:\u001b[0m   \u001b[0;31m# Gradient clipping\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainable_params_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m    165\u001b[0m                 \u001b[0mVariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m         \"\"\"\n\u001b[0;32m--> 167\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(variables, grad_variables, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m---> 99\u001b[0;31m         variables, grad_variables, retain_graph)\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "learn.fit(lrs,1,cycle_len=40,use_clr=(20,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('128urn-xrblock-0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('128urn-xrblock-0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = next(iter(md.val_dl))\n",
    "py = to_np(learn.model(V(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ax = show_img(denorm(x)[0])\n",
    "show_img(py[0][0]>0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ax = show_img(denorm(x)[0])\n",
    "show_img(y[0,...,-1]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 512x512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DN = 'train-512'\n",
    "MASKS_DN = 'train_masks-512'\n",
    "sz = 512\n",
    "bs = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_names = np.array([Path(TRAIN_DN)/o for o in masks_csv['img']])\n",
    "y_names = np.array([Path(MASKS_DN)/f'{o[:-4]}_mask.png' for o in masks_csv['img']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_idxs = list(range(1008))\n",
    "((val_x,trn_x),(val_y,trn_y)) = split_by_idx(val_idxs, x_names, y_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfms = tfms_from_model(vgg16, sz, crop_type=CropType.NO, tfm_y=TfmType.NO, aug_tfms=aug_tfms)\n",
    "datasets = ImageData.get_ds(MatchedFilesDataset, (trn_x,trn_y), (val_x,val_y), tfms, path=PATH)\n",
    "md = ImageData(PATH, datasets, bs, num_workers=4, classes=None)\n",
    "denorm = md.trn_ds.denorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_base = get_base()\n",
    "m = to_gpu(Unet34(m_base))\n",
    "models = UpsampleModel(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = ConvLearner(md, models)\n",
    "learn.opt_fn=optim.Adam\n",
    "learn.crit=mask_loss\n",
    "learn.metrics=[mask_acc,dice]\n",
    "\n",
    "learn.freeze_to(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('128urn-xrblock-0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=4e-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f21794e73f44d978c1cc35c5973961b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=5), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 43/510 [00:29<05:18,  1.46it/s, loss=0.0372]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-d2f0b97a920e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcycle_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0muse_clr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/fastai/courses/dl2/fastai/learner.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, lrs, n_cycle, wds, **kwargs)\u001b[0m\n\u001b[1;32m    212\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0mlayer_opt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_layer_opt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_gen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer_opt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_cycle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwarm_up\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/fastai/courses/dl2/fastai/learner.py\u001b[0m in \u001b[0;36mfit_gen\u001b[0;34m(self, model, data, layer_opt, n_cycle, cycle_len, cycle_mult, cycle_save_name, best_save_name, use_clr, metrics, callbacks, use_wd_sched, norm_wds, wds_sched_mult, **kwargs)\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0mn_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum_geom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcycle_len\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcycle_len\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcycle_mult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_cycle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m         return fit(model, data, n_epoch, layer_opt.opt, self.crit,\n\u001b[0;32m--> 161\u001b[0;31m             metrics=metrics, callbacks=callbacks, reg_fn=self.reg_fn, clip=self.clip, **kwargs)\n\u001b[0m\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_layer_groups\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_layer_groups\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/fastai/courses/dl2/fastai/model.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(model, data, epochs, opt, crit, metrics, callbacks, stepper, **kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m             \u001b[0mbatch_num\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mcb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstepper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m             \u001b[0mavg_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mavg_loss\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mavg_mom\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mavg_mom\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0mdebias_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mavg_loss\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mavg_mom\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mbatch_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/fastai/courses/dl2/fastai/model.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, xs, y, epoch)\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mxtra\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mraw_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcrit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreg_fn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreg_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxtra\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-6a325fd7e8a4>\u001b[0m in \u001b[0;36mmask_loss\u001b[0;34m(pred, targ)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmask_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_cross_entropy_with_logits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmask_acc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0maccuracy_multi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbinary_cross_entropy_with_logits\u001b[0;34m(input, target, weight, size_average)\u001b[0m\n\u001b[1;32m   1234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1235\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1236\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1237\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "learn.fit(lr,1,cycle_len=5,use_clr=(20,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('512urn-xrblock-tmp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('512urn-xrblock-tmp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr=1e-3\n",
    "lr=4e-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()\n",
    "learn.bn_freeze(True)\n",
    "lrs = np.array([lr/100,lr/10,lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5584f781d074a839a23261353496505",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=8), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/510 [00:00<?, ?it/s]                      "
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "cuda runtime error (2) : out of memory at /opt/conda/conda-bld/pytorch_1518244421288/work/torch/lib/THC/generic/THCStorage.cu:58",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-3c615a53f41a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcycle_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0muse_clr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/fastai/courses/dl2/fastai/learner.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, lrs, n_cycle, wds, **kwargs)\u001b[0m\n\u001b[1;32m    212\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0mlayer_opt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_layer_opt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_gen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer_opt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_cycle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwarm_up\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/fastai/courses/dl2/fastai/learner.py\u001b[0m in \u001b[0;36mfit_gen\u001b[0;34m(self, model, data, layer_opt, n_cycle, cycle_len, cycle_mult, cycle_save_name, best_save_name, use_clr, metrics, callbacks, use_wd_sched, norm_wds, wds_sched_mult, **kwargs)\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0mn_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum_geom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcycle_len\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcycle_len\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcycle_mult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_cycle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m         return fit(model, data, n_epoch, layer_opt.opt, self.crit,\n\u001b[0;32m--> 161\u001b[0;31m             metrics=metrics, callbacks=callbacks, reg_fn=self.reg_fn, clip=self.clip, **kwargs)\n\u001b[0m\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_layer_groups\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_layer_groups\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/fastai/courses/dl2/fastai/model.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(model, data, epochs, opt, crit, metrics, callbacks, stepper, **kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m             \u001b[0mbatch_num\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mcb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstepper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m             \u001b[0mavg_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mavg_loss\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mavg_mom\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mavg_mom\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0mdebias_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mavg_loss\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mavg_mom\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mbatch_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/fastai/courses/dl2/fastai/model.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, xs, y, epoch)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mxtra\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mxtra\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-21-79f45ea601b2>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mup2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msfs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mup3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msfs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mup4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msfs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mup5\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_skip\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mup6\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-20-8fd292dc4fbf>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, up_p, x_p)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mup_p\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtr_conv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mup_p\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mx_p\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_conv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_p\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mcat_p\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mup_p\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_p\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcat_p\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: cuda runtime error (2) : out of memory at /opt/conda/conda-bld/pytorch_1518244421288/work/torch/lib/THC/generic/THCStorage.cu:58"
     ]
    }
   ],
   "source": [
    "learn.fit(lrs,1,cycle_len=8,use_clr=(20,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('512urn-xrblock')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/carvana/models/512urn-xrblock.h5'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-f26cc508876c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'512urn-xrblock'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/fastai/courses/dl2/fastai/learner.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_model_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.h5'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_model_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_model_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mset_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/fastai/courses/dl2/fastai/torch_imports.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(m, p)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mm\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstorage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_pre\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpre\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module)\u001b[0m\n\u001b[1;32m    257\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpathlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[0mnew_fd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    260\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/carvana/models/512urn-xrblock.h5'"
     ]
    }
   ],
   "source": [
    "learn.load('512urn-xrblock')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = next(iter(md.val_dl))\n",
    "py = to_np(learn.model(V(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_img(py[0][0]>0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_img(y[0,...,-1]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1024x1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sz=1024\n",
    "bs=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfms = tfms_from_model(resnet34, sz, crop_type=CropType.NO, tfm_y=TfmType.PIXEL, aug_tfms=aug_tfms)\n",
    "datasets = ImageData.get_ds(MatchedFilesDataset, (trn_x,trn_y), (val_x,val_y), tfms, path=PATH)\n",
    "md = ImageData(PATH, datasets, bs, num_workers=4, classes=None)\n",
    "denorm = md.trn_ds.denorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_base = get_base()\n",
    "m = to_gpu(Unet34(m_base))\n",
    "models = UpsampleModel(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = ConvLearner(md, models)\n",
    "learn.opt_fn=optim.Adam\n",
    "learn.crit=mask_loss\n",
    "learn.metrics=[mask_acc,dice]\n",
    "\n",
    "learn.freeze_to(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('512urn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(lr,1,cycle_len=2,use_clr=(20,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('1024urn-tmp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()\n",
    "learn.bn_freeze(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(lrs/2,1,cycle_len=4,use_clr=(20,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('1024urn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('1024urn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = next(iter(md.val_dl))\n",
    "py = to_np(learn.model(V(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_img(py[0][0]>0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_img(y[0,...,-1]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "86px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
