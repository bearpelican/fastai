{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CIFAR 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.conv_learner import *\n",
    "from fastai.models.cifar10.wideresnet import wrn_22_cat, wrn_22, WideResNetConcat\n",
    "torch.backends.cudnn.benchmark = True\n",
    "PATH = Path(\"data/cifar10/\")\n",
    "os.makedirs(PATH,exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "stats = (np.array([ 0.4914 ,  0.48216,  0.44653]), np.array([ 0.24703,  0.24349,  0.26159]))\n",
    "\n",
    "bs=512\n",
    "sz=32\n",
    "workers=7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "\n",
    "def pad(img, p=4, padding_mode='reflect'):\n",
    "    return Image.fromarray(np.pad(np.asarray(img), ((p, p), (p, p), (0, 0)), padding_mode))\n",
    "\n",
    "\n",
    "def get_loaders(bs, num_workers):\n",
    "    traindir = str(PATH/'train')\n",
    "    valdir = str(PATH/'test')\n",
    "    tfms = [transforms.ToTensor(),\n",
    "            transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))]\n",
    "\n",
    "    aug_tfms =transforms.Compose([\n",
    "            transforms.RandomCrop(32, padding=4),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "        ] + tfms)\n",
    "    \n",
    "    train_dataset = datasets.ImageFolder(\n",
    "        traindir,\n",
    "        aug_tfms)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=bs, shuffle=True, num_workers=num_workers, pin_memory=True)\n",
    "\n",
    "    val_dataset = datasets.ImageFolder(valdir, transforms.Compose(tfms))\n",
    "\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        val_dataset, batch_size=bs, shuffle=False, num_workers=num_workers, pin_memory=True)\n",
    "    \n",
    "    aug_dataset = datasets.ImageFolder(valdir, aug_tfms)\n",
    "\n",
    "    aug_loader = torch.utils.data.DataLoader(\n",
    "        aug_dataset, batch_size=bs, shuffle=False, num_workers=num_workers, pin_memory=True)\n",
    "    \n",
    "    return train_loader, val_loader, aug_loader\n",
    "\n",
    "def torch_loader(data_path, size):\n",
    "    if not os.path.exists(data_path+'/train'): download_cifar10(data_path)\n",
    "\n",
    "    # Data loading code\n",
    "    traindir = os.path.join(data_path, 'train')\n",
    "    valdir = os.path.join(data_path, 'test')\n",
    "    normalize = transforms.Normalize(mean=[0.4914 , 0.48216, 0.44653], std=[0.24703, 0.24349, 0.26159])\n",
    "    tfms = [transforms.ToTensor(), normalize]\n",
    "\n",
    "    train_tfms = transforms.Compose([\n",
    "        pad, # TODO: use `padding` rather than assuming 4\n",
    "        transforms.RandomCrop(size),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "    ] + tfms)\n",
    "    val_tfms = transforms.Compose(tfms)\n",
    "\n",
    "    train_dataset = datasets.ImageFolder(traindir, train_tfms)\n",
    "    val_dataset = datasets.ImageFolder(valdir, val_tfms)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=bs, shuffle=True,\n",
    "        num_workers=workers, pin_memory=True)\n",
    "\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        val_dataset, batch_size=bs*2, shuffle=False,\n",
    "        num_workers=workers, pin_memory=True)\n",
    "    \n",
    "    aug_loader = torch.utils.data.DataLoader(\n",
    "        datasets.ImageFolder(valdir, train_tfms),\n",
    "        batch_size=bs*2, shuffle=False,\n",
    "        num_workers=workers, pin_memory=True)\n",
    "\n",
    "    train_loader = DataPrefetcher(train_loader)\n",
    "    val_loader = DataPrefetcher(val_loader)\n",
    "    aug_loader = DataPrefetcher(aug_loader)\n",
    "    \n",
    "    data = ModelData(data_path, train_loader, val_loader)\n",
    "    data.sz = size\n",
    "    data.aug_dl = aug_loader\n",
    "    return data\n",
    "\n",
    "# Seems to speed up training by ~2%\n",
    "class DataPrefetcher():\n",
    "    def __init__(self, loader, stop_after=None):\n",
    "        self.loader = loader\n",
    "        self.dataset = loader.dataset\n",
    "        self.stream = torch.cuda.Stream()\n",
    "        self.stop_after = stop_after\n",
    "        self.next_input = None\n",
    "        self.next_target = None\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.loader)\n",
    "\n",
    "    def preload(self):\n",
    "        try:\n",
    "            self.next_input, self.next_target = next(self.loaditer)\n",
    "        except StopIteration:\n",
    "            self.next_input = None\n",
    "            self.next_target = None\n",
    "            return\n",
    "        with torch.cuda.stream(self.stream):\n",
    "            self.next_input = self.next_input.cuda(async=True)\n",
    "            self.next_target = self.next_target.cuda(async=True)\n",
    "\n",
    "    def __iter__(self):\n",
    "        count = 0\n",
    "        self.loaditer = iter(self.loader)\n",
    "        self.preload()\n",
    "        while self.next_input is not None:\n",
    "            torch.cuda.current_stream().wait_stream(self.stream)\n",
    "            input = self.next_input\n",
    "            target = self.next_target\n",
    "            self.preload()\n",
    "            count += 1\n",
    "            yield input, target\n",
    "            if type(self.stop_after) is int and (count > self.stop_after):\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch_loader(str(PATH), sz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Pre-activation ResNet in PyTorch.\n",
    "\n",
    "Reference:\n",
    "[1] Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun\n",
    "    Identity Mappings in Deep Residual Networks. arXiv:1603.05027\n",
    "'''\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "class AdaptiveConcatPool2d(nn.Module):\n",
    "    def __init__(self, sz=None):\n",
    "        super().__init__()\n",
    "        sz = sz or (1,1)\n",
    "        self.ap = nn.AdaptiveAvgPool2d(sz)\n",
    "        self.mp = nn.AdaptiveMaxPool2d(sz)\n",
    "    def forward(self, x): return torch.cat([self.mp(x), self.ap(x)], 1)\n",
    "    \n",
    "\n",
    "class PreActBlock(nn.Module):\n",
    "    '''Pre-activation version of the BasicBlock.'''\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(PreActBlock, self).__init__()\n",
    "        self.bn1 = nn.BatchNorm2d(in_planes)\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.bn2.bias.data.zero_()\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(x), inplace=True)\n",
    "        shortcut = self.shortcut(out) if hasattr(self, 'shortcut') else x\n",
    "        out = self.conv1(out)\n",
    "        out = self.conv2(F.relu(self.bn2(out), inplace=True))\n",
    "        out += shortcut\n",
    "        return out\n",
    "\n",
    "\n",
    "class PreActBottleneck(nn.Module):\n",
    "    '''Pre-activation version of the original Bottleneck module.'''\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(PreActBottleneck, self).__init__()\n",
    "        self.bn1 = nn.BatchNorm2d(in_planes)\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, self.expansion*planes, kernel_size=1, bias=False)\n",
    "\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(x))\n",
    "        shortcut = self.shortcut(out) if hasattr(self, 'shortcut') else x\n",
    "        out = self.conv1(out)\n",
    "        out = self.conv2(F.relu(self.bn2(out)))\n",
    "        out = self.conv3(F.relu(self.bn3(out)))\n",
    "        out += shortcut\n",
    "        return out\n",
    "\n",
    "\n",
    "class PreActResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=10, concatpool=False):\n",
    "        super(PreActResNet, self).__init__()\n",
    "        self.in_planes = 64\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
    "        self.pool = AdaptiveConcatPool2d() if concatpool else nn.AdaptiveMaxPool2d((1,1))\n",
    "        \n",
    "        self.linear = nn.Linear(512*block.expansion*(concatpool+1), num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "#         out = F.adaptive_max_pool2d(out, 1)\n",
    "        out = self.pool(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        return F.log_softmax(self.linear(out))\n",
    "\n",
    "def preact_resnet18(): return PreActResNet(PreActBlock, [2,2,2,2])\n",
    "def preact_resnet2332(): return PreActResNet(PreActBlock, [2,3,3,2])\n",
    "def preact_resnet3333(): return PreActResNet(PreActBlock, [3,3,3,3])\n",
    "def preact_resnet34(): return PreActResNet(PreActBlock, [3,4,6,3])\n",
    "def preact_resnet50(): return PreActResNet(PreActBottleneck, [3,4,6,3])\n",
    "def preActResNet101(): return PreActResNet(PreActBottleneck, [3,4,23,3])\n",
    "def preActResNet152(): return PreActResNet(PreActBottleneck, [3,8,36,3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m = WideResNetConcat(num_groups=3, N=3, num_classes=10, k=1, drop_p=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_TTA_accuracy(learn):\n",
    "    preds, targs = learn.TTA()\n",
    "    # combining the predictions across augmented and non augmented inputs\n",
    "    preds = 0.6 * preds[0] + 0.4 * preds[1:].sum(0)\n",
    "    return accuracy_np(preds, targs)\n",
    "\n",
    "def get_TTA_accuracy_2(learn):\n",
    "    log_preds,y = learn.TTA()\n",
    "    preds = np.mean(np.exp(log_preds),0)\n",
    "    acc = accuracy(torch.FloatTensor(preds),torch.LongTensor(y))\n",
    "    print('TTA acc:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a23c589c11724171bfcefa036de07890",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=35), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                 \n",
      "    0      1.54745    1.341417   0.516     \n",
      "    1      1.199921   1.162127   0.6105                   \n",
      "    2      0.952421   0.844205   0.7047                    \n",
      "    3      0.754694   0.783398   0.7247                    \n",
      "    4      0.655994   0.763181   0.7423                    \n",
      "    5      0.574407   0.60161    0.7945                    \n",
      "    6      0.525335   0.675541   0.7738                    \n",
      "    7      0.488829   0.673738   0.7684                    \n",
      "    8      0.471731   0.550068   0.8135                    \n",
      "    9      0.431304   0.626316   0.8019                    \n",
      "    10     0.414254   0.625968   0.8013                    \n",
      "    11     0.406064   0.612051   0.8159                    \n",
      "    12     0.401669   0.573889   0.819                     \n",
      "    13     0.386631   0.62647    0.8072                    \n",
      "    14     0.386211   0.556812   0.8231                    \n",
      "    15     0.368219   0.810465   0.7484                    \n",
      "    16     0.336425   0.663652   0.7945                    \n",
      "    17     0.324329   0.477124   0.8431                    \n",
      "    18     0.312341   0.449094   0.8547                    \n",
      "    19     0.286669   0.491      0.8375                    \n",
      "    20     0.274928   0.541283   0.8339                    \n",
      "    21     0.252907   0.382217   0.8757                    \n",
      "    22     0.227829   0.393691   0.874                     \n",
      "    23     0.201377   0.344754   0.8932                    \n",
      "    24     0.186197   0.342812   0.8914                    \n",
      "    25     0.157773   0.3236     0.8968                    \n",
      "    26     0.122201   0.303088   0.9083                    \n",
      "    27     0.085091   0.267276   0.9216                     \n",
      "    28     0.059694   0.241359   0.9273                     \n",
      "    29     0.047959   0.24611    0.9291                     \n",
      "    30     0.041054   0.252879   0.928                      \n",
      "    31     0.033776   0.244341   0.9289                     \n",
      "    32     0.027548   0.246494   0.9323                     \n",
      "    33     0.023779   0.242985   0.9322                     \n",
      "    34     0.021791   0.244177   0.9328                     \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([0.24418]), 0.9328000016212463]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = PreActResNet(PreActBlock, [2,2,2,2], concatpool=True)\n",
    "learn = ConvLearner.from_model_data(m, data)\n",
    "learn.half()\n",
    "learn.crit = nn.CrossEntropyLoss()\n",
    "learn.metrics = [accuracy]\n",
    "wd=2e-4\n",
    "lr=1.2\n",
    "learn.clip = 3e-1\n",
    "def_phase = {'opt_fn':optim.SGD, 'wds':wd}\n",
    "# TODO: add momentum\n",
    "# %time learn.fit(lr, 1, wds=wd, cycle_len=23, use_clr_beta=(20,22,0.95,0.85), loss_scale=512)\n",
    "phases = [\n",
    "    TrainingPhase(**def_phase, epochs=2, lr=(.04, .08), lr_decay=DecayType.LINEAR, momentum=0.95),\n",
    "    TrainingPhase(**def_phase, epochs=13, lr=(.08,.7), lr_decay=DecayType.LINEAR, momentum=(0.95,0.85), momentum_decay=DecayType.LINEAR),\n",
    "    TrainingPhase(**def_phase, epochs=13, lr=(.7,.04), lr_decay=DecayType.LINEAR, momentum=(0.85,0.95), momentum_decay=DecayType.LINEAR),\n",
    "    TrainingPhase(**def_phase, epochs=7, lr=(.04,.001), lr_decay=DecayType.LINEAR, momentum=(0.95))]\n",
    "\n",
    "learn.fit_opt_sched(phases, data_list=[data], loss_scale=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TTA acc: 0.6618                              \n",
      "0.8267 None\n"
     ]
    }
   ],
   "source": [
    "print(get_TTA_accuracy(learn), get_TTA_accuracy_2(learn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = PreActResNet(PreActBlock, [2,2,2,2], concatpool=True)\n",
    "learn = ConvLearner.from_model_data(m, data)\n",
    "learn.half()\n",
    "learn.crit = nn.CrossEntropyLoss()\n",
    "learn.metrics = [accuracy]\n",
    "wd=2e-4\n",
    "learn.clip = 3e-1\n",
    "\n",
    "def_phase = {'opt_fn':optim.SGD, 'wds':wd}\n",
    "# TODO: add momentum\n",
    "# %time learn.fit(lr, 1, wds=wd, cycle_len=23, use_clr_beta=(20,22,0.95,0.85), loss_scale=512)\n",
    "phases = [\n",
    "    TrainingPhase(**def_phase, epochs=3, lr=(.04, .08), lr_decay=DecayType.LINEAR, momentum=(0.75,0.95), momentum_decay=DecayType.LINEAR),\n",
    "    TrainingPhase(**def_phase, epochs=10, lr=(.08,.7), lr_decay=DecayType.LINEAR, momentum=(0.95,0.85), momentum_decay=DecayType.LINEAR),\n",
    "    TrainingPhase(**def_phase, epochs=10, lr=(.7,.04), lr_decay=DecayType.LINEAR, momentum=(0.85,0.95), momentum_decay=DecayType.LINEAR),\n",
    "    TrainingPhase(**def_phase, epochs=5, lr=(.04,.001), lr_decay=DecayType.LINEAR, momentum=(0.95))]\n",
    "\n",
    "learn.fit_opt_sched(phases, data_list=[data], loss_scale=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('27epoch9288')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bbd7a9430cb4690be8d0d89617e1f2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=5), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                   \n",
      "    0      0.040664   0.243845   0.9292    \n",
      "                                                            \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-28:\n",
      "Process Process-24:\n",
      "Process Process-23:\n",
      "Process Process-26:\n",
      "Process Process-22:\n",
      "Process Process-25:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Process Process-27:\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 55, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 55, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 55, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/PIL/PngImagePlugin.py\", line 535, in _open\n",
      "    s = self.png.call(cid, pos, length)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 55, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/PIL/PngImagePlugin.py\", line 132, in call\n",
      "    return getattr(self, \"chunk_\" + cid.decode('ascii'))(pos, length)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 55, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torchvision/datasets/folder.py\", line 122, in __getitem__\n",
      "    img = self.loader(path)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 55, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/PIL/PngImagePlugin.py\", line 347, in chunk_IDAT\n",
      "    raise EOFError\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torchvision/datasets/folder.py\", line 122, in __getitem__\n",
      "    img = self.loader(path)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torchvision/datasets/folder.py\", line 69, in default_loader\n",
      "    return pil_loader(path)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 55, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 55, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "EOFError\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torchvision/datasets/folder.py\", line 69, in default_loader\n",
      "    return pil_loader(path)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torchvision/datasets/folder.py\", line 51, in pil_loader\n",
      "    with Image.open(f) as img:\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torchvision/datasets/folder.py\", line 124, in __getitem__\n",
      "    img = self.transform(img)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 55, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torchvision/datasets/folder.py\", line 50, in pil_loader\n",
      "    with open(path, 'rb') as f:\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/PIL/Image.py\", line 2559, in open\n",
      "    im = _open_core(fp, filename, prefix)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 55, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "KeyboardInterrupt\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torchvision/transforms/transforms.py\", line 42, in __call__\n",
      "    img = t(img)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torchvision/datasets/folder.py\", line 124, in __getitem__\n",
      "    img = self.transform(img)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 55, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torchvision/transforms/transforms.py\", line 61, in __call__\n",
      "    return F.to_tensor(pic)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torchvision/transforms/functional.py\", line 63, in to_tensor\n",
      "    img = torch.ByteTensor(torch.ByteStorage.from_buffer(pic.tobytes()))\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 55, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torchvision/transforms/functional.py\", line 76, in to_tensor\n",
      "    return img.float().div(255)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torchvision/datasets/folder.py\", line 124, in __getitem__\n",
      "    img = self.transform(img)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torchvision/transforms/transforms.py\", line 42, in __call__\n",
      "    img = t(img)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torchvision/transforms/transforms.py\", line 61, in __call__\n",
      "    return F.to_tensor(pic)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torchvision/transforms/transforms.py\", line 42, in __call__\n",
      "    img = t(img)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torchvision/transforms/transforms.py\", line 61, in __call__\n",
      "    return F.to_tensor(pic)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torchvision/transforms/functional.py\", line 58, in to_tensor\n",
      "    if pic.mode == 'I':\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 55, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torchvision/datasets/folder.py\", line 124, in __getitem__\n",
      "    img = self.transform(img)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 55, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torchvision/transforms/transforms.py\", line 42, in __call__\n",
      "    img = t(img)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torchvision/datasets/folder.py\", line 122, in __getitem__\n",
      "    img = self.loader(path)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torchvision/transforms/transforms.py\", line 61, in __call__\n",
      "    return F.to_tensor(pic)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torchvision/datasets/folder.py\", line 69, in default_loader\n",
      "    return pil_loader(path)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torchvision/transforms/functional.py\", line 76, in to_tensor\n",
      "    return img.float().div(255)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torchvision/datasets/folder.py\", line 51, in pil_loader\n",
      "    with Image.open(f) as img:\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/PIL/Image.py\", line 2559, in open\n",
      "    im = _open_core(fp, filename, prefix)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/PIL/Image.py\", line 2549, in _open_core\n",
      "    im = factory(fp, filename)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/PIL/ImageFile.py\", line 102, in __init__\n",
      "    self._open()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/PIL/PngImagePlugin.py\", line 535, in _open\n",
      "    s = self.png.call(cid, pos, length)\n",
      "KeyboardInterrupt\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-11-6f55e2b490a8>\", line 3, in <module>\n",
      "    learn.fit_opt_sched(phases, data_list=[data], loss_scale=512)\n",
      "  File \"/home/paperspace/fastai/courses/dl2/fastai/learner.py\", line 426, in fit_opt_sched\n",
      "    metrics=metrics, callbacks=callbacks, reg_fn=self.reg_fn, clip=self.clip, fp16=self.fp16, **kwargs)\n",
      "  File \"/home/paperspace/fastai/courses/dl2/fastai/model.py\", line 150, in fit\n",
      "    vals = validate(model_stepper, cur_data.val_dl, metrics)\n",
      "  File \"/home/paperspace/fastai/courses/dl2/fastai/model.py\", line 206, in validate\n",
      "    for (*x,y) in iter(dl):\n",
      "  File \"<ipython-input-4-9b4bf4427d44>\", line 106, in __iter__\n",
      "    self.preload()\n",
      "  File \"<ipython-input-4-9b4bf4427d44>\", line 94, in preload\n",
      "    self.next_input, self.next_target = next(self.loaditer)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 275, in __next__\n",
      "    idx, batch = self._get_batch()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 254, in _get_batch\n",
      "    return self.data_queue.get()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/queue.py\", line 164, in get\n",
      "    self.not_empty.wait()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/threading.py\", line 295, in wait\n",
      "    waiter.acquire()\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 1863, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 1095, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 311, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 345, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/inspect.py\", line 1483, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/inspect.py\", line 1441, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/inspect.py\", line 742, in getmodule\n",
      "    os.path.realpath(f)] = module.__name__\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/posixpath.py\", line 388, in realpath\n",
      "    path, ok = _joinrealpath(filename[:0], filename, {})\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/posixpath.py\", line 422, in _joinrealpath\n",
      "    if not islink(newpath):\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/posixpath.py\", line 171, in islink\n",
      "    st = os.lstat(path)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 175, in handler\n",
      "    _error_if_any_worker_fails()\n",
      "RuntimeError: DataLoader worker (pid 23189) exited unexpectedly with exit code 1.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "phases = [TrainingPhase(**def_phase, epochs=5, lr=(.01,.001), lr_decay=DecayType.LINEAR, momentum=(0.95))]\n",
    "\n",
    "learn.fit_opt_sched(phases, data_list=[data], loss_scale=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TTA acc: 0.6647                              \n",
      "0.6592 None\n"
     ]
    }
   ],
   "source": [
    "print(get_TTA_accuracy(learn), ga\n",
    "      et_TTA_accuracy_2(learn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = PreActResNet(PreActBlock, [2,2,2,2], concatpool=True)\n",
    "learn = ConvLearner.from_model_data(m, data)\n",
    "learn.half()\n",
    "learn.crit = nn.CrossEntropyLoss()\n",
    "learn.metrics = [accuracy]\n",
    "wd=2e-4\n",
    "lr=1.2\n",
    "learn.clip = 3e-1\n",
    "def_phase = {'opt_fn':optim.SGD, 'wds':wd}\n",
    "# TODO: add momentum\n",
    "# %time learn.fit(lr, 1, wds=wd, cycle_len=23, use_clr_beta=(20,22,0.95,0.85), loss_scale=512)\n",
    "phases = [\n",
    "    TrainingPhase(**def_phase, epochs=3, lr=(.04, .08), lr_decay=DecayType.LINEAR, momentum=(0.75,0.95), momentum_decay=DecayType.LINEAR),\n",
    "    TrainingPhase(**def_phase, epochs=12, lr=(.08,.7), lr_decay=DecayType.LINEAR, momentum=(0.95,0.85), momentum_decay=DecayType.LINEAR),\n",
    "    TrainingPhase(**def_phase, epochs=13, lr=(.7,.04), lr_decay=DecayType.LINEAR, momentum=(0.85,0.95), momentum_decay=DecayType.LINEAR)]\n",
    "\n",
    "learn.fit_opt_sched(phases, data_list=[data], loss_scale=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('e279269')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efd148ee1fe64cd487b185f1e954840a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                   \n",
      "    0      0.021264   0.247426   0.9341    \n",
      "    1      0.021122   0.248507   0.9342                     \n",
      "    2      0.019623   0.250664   0.9344                     \n",
      "    3      0.018247   0.244344   0.9352                     \n",
      "    4      0.014671   0.246918   0.9361                     \n",
      "    5      0.013124   0.243003   0.9383                     \n",
      "    6      0.010386   0.242575   0.9388                     \n",
      "    7      0.010377   0.245571   0.9377                     \n",
      "    8      0.010275   0.245191   0.9374                      \n",
      "    9      0.009524   0.244672   0.9379                      \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([0.24467]), 0.9379000016212463]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wd=5e-4\n",
    "lr=1.2\n",
    "learn.clip = 3e-1\n",
    "def_phase = {'opt_fn':optim.SGD, 'wds':wd}\n",
    "phases = [TrainingPhase(**def_phase, epochs=10, lr=(.03,.0005), lr_decay=DecayType.LINEAR, momentum=(0.95))]\n",
    "learn.fit_opt_sched(phases, data_list=[data], loss_scale=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "879a5c40685644a78b82636e9ff34e7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=28), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                 \n",
      "    0      1.391143   1.334314   0.5177    \n",
      "    1      1.042856   1.109197   0.6287                   \n",
      "    2      0.904438   1.469603   0.5758                    \n",
      "    3      0.874192   0.962976   0.705                     \n",
      "    4      0.715085   0.694865   0.7622                    \n",
      "    5      0.586988   0.598435   0.796                     \n",
      "    6      0.5375     0.745907   0.7434                    \n",
      "    7      0.516125   0.606515   0.7944                    \n",
      "    8      0.494006   0.886046   0.7204                    \n",
      "    9      0.484716   0.610714   0.7865                    \n",
      "    10     0.475833   1.010698   0.6963                    \n",
      "    11     0.462307   0.678418   0.7723                    \n",
      "    12     0.475521   0.613303   0.8007                    \n",
      "    13     0.47077    1.558636   0.6062                    \n",
      "    14     0.456944   0.552482   0.814                     \n",
      "    15     0.442594   0.936427   0.7178                    \n",
      "    16     0.422528   0.724889   0.7688                    \n",
      "    17     0.416021   1.328887   0.6611                    \n",
      "    18     0.396867   1.023253   0.7245                    \n",
      "    19     0.391526   0.768675   0.7733                    \n",
      "    20     0.384508   0.710807   0.7637                    \n",
      "    21     0.361591   0.520566   0.8191                    \n",
      "    22     0.331521   0.404774   0.8602                    \n",
      "    23     0.308612   0.472198   0.8413                    \n",
      "    24     0.293305   0.417861   0.8573                    \n",
      "    25     0.254195   0.337765   0.8823                    \n",
      "    26     0.220923   0.346635   0.8878                    \n",
      "    27     0.165984   0.269917   0.915                     \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([0.26992]), 0.9150000018119812]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = PreActResNet(PreActBlock, [2,2,2,2], concatpool=True)\n",
    "learn = ConvLearner.from_model_data(m, data)\n",
    "learn.half()\n",
    "learn.crit = nn.CrossEntropyLoss()\n",
    "learn.metrics = [accuracy]\n",
    "wd=5e-4\n",
    "lr=1.2\n",
    "learn.clip = 3e-1\n",
    "def_phase = {'opt_fn':optim.SGD, 'wds':wd}\n",
    "# TODO: add momentum\n",
    "# %time learn.fit(lr, 1, wds=wd, cycle_len=23, use_clr_beta=(20,22,0.95,0.85), loss_scale=512)\n",
    "phases = [\n",
    "    TrainingPhase(**def_phase, epochs=3, lr=(.04, .08), lr_decay=DecayType.LINEAR, momentum=(0.75,0.95), momentum_decay=DecayType.LINEAR),\n",
    "    TrainingPhase(**def_phase, epochs=12, lr=(.08,.7), lr_decay=DecayType.LINEAR, momentum=(0.95,0.85), momentum_decay=DecayType.LINEAR),\n",
    "    TrainingPhase(**def_phase, epochs=13, lr=(.7,.04), lr_decay=DecayType.LINEAR, momentum=(0.85,0.95), momentum_decay=DecayType.LINEAR)]\n",
    "\n",
    "learn.fit_opt_sched(phases, data_list=[data], loss_scale=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('27e915wd5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ead50cc373b42688c2b93f20d838881",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=12), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                  \n",
      "    0      0.110968   0.238117   0.9238    \n",
      "    1      0.098732   0.241428   0.9235                     \n",
      "    2      0.090655   0.290853   0.9096                     \n",
      "    3      0.080642   0.239033   0.9274                     \n",
      "    4      0.073385   0.240833   0.9264                     \n",
      "    5      0.059446   0.227871   0.9319                     \n",
      "    6      0.048171   0.239564   0.9307                     \n",
      "    7      0.041601   0.231649   0.9352                     \n",
      "    8      0.034683   0.223164   0.9371                     \n",
      "    9      0.027196   0.223093   0.939                      \n",
      "    10     0.022635   0.226913   0.9393                     \n",
      "    11     0.018472   0.223484   0.9399                     \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([0.22348]), 0.9399000015258789]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phases = [TrainingPhase(**def_phase, epochs=12, lr=(.04,.0001), lr_decay=DecayType.LINEAR, momentum=(0.95))]\n",
    "learn.fit_opt_sched(phases, data_list=[data], loss_scale=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('27e915wd5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b32899b9ea094689b99d3f40161b5d38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=13), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                   \n",
      "    0      0.083213   0.32967    0.9061    \n",
      "    1      0.094038   0.282612   0.9148                     \n",
      "    2      0.081213   0.317804   0.9092                     \n",
      "    3      0.076014   0.288641   0.9167                     \n",
      "    4      0.066762   0.256036   0.9232                     \n",
      "    5      0.057202   0.263993   0.9229                     \n",
      "    6      0.04991    0.268894   0.9249                     \n",
      "    7      0.037379   0.242746   0.933                      \n",
      "    8      0.02749    0.241933   0.9349                     \n",
      "    9      0.02153    0.232156   0.9385                     \n",
      "    10     0.016212   0.234194   0.9365                     \n",
      "    11     0.01265    0.231261   0.9384                     \n",
      "    12     0.010391   0.23264    0.9399                     \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([0.23264]), 0.9398999988555908]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phases = [TrainingPhase(**def_phase, epochs=13, lr=(.04,.00001), lr_decay=DecayType.LINEAR, momentum=(0.95))]\n",
    "learn.fit_opt_sched(phases, data_list=[data], loss_scale=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('27e915wd5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=30), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                 \n",
      "    0      1.395335   1.396503   0.5316    \n",
      "    1      1.041985   1.463319   0.5623                   \n",
      "    2      0.904097   1.009868   0.6577                    \n",
      "    3      1.001244   1.388565   0.5683                    \n",
      "    4      0.704542   0.734299   0.7588                    \n",
      "    5      0.553996   0.776914   0.7565                    \n",
      "    6      0.493651   0.708688   0.7639                    \n",
      "    7      0.466777   0.492839   0.8291                    \n",
      "    8      0.42863    0.524811   0.8235                    \n",
      "    9      0.40446    0.593429   0.8122                    \n",
      "    10     0.38921    0.504208   0.8254                    \n",
      "    11     0.373812   0.53962    0.8265                    \n",
      "    12     0.356916   0.441853   0.8549                    \n",
      "    13     0.361846   0.614352   0.7995                    \n",
      "    14     0.340386   0.771667   0.7689                    \n",
      "    15     0.32771    0.906955   0.7456                    \n",
      "    16     0.337661   0.596194   0.8004                    \n",
      "    17     0.36132    0.919009   0.7439                    \n",
      "    18     0.373178   0.584688   0.8005                    \n",
      "    19     0.37812    0.658305   0.7892                    \n",
      "    20     0.368193   0.807862   0.7491                    \n",
      "    21     0.375435   0.583349   0.804                     \n",
      "    22     0.357695   0.527085   0.8193                    \n",
      "    23     0.346023   0.607885   0.8064                    \n",
      "    24     0.325592   0.551229   0.8176                    \n",
      "    25     0.305115   0.46072    0.8512                    \n",
      "    26     0.275067   0.4493     0.8504                    \n",
      "    27     0.252105   0.35131    0.8773                    \n",
      "    28     0.217259   0.312264   0.8936                    \n",
      "    29     0.164673   0.265166   0.9101                    \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([0.26517]), 0.9100999982833863]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = PreActResNet(PreActBlock, [2,2,2,2], concatpool=True)\n",
    "learn = ConvLearner.from_model_data(m, data)\n",
    "learn.half()\n",
    "learn.crit = nn.CrossEntropyLoss()\n",
    "learn.metrics = [accuracy]\n",
    "wd=2e-4\n",
    "lr=1.2\n",
    "learn.clip = 3e-1\n",
    "def_phase = {'opt_fn':optim.SGD, 'wds':wd}\n",
    "# TODO: add momentum\n",
    "# %time learn.fit(lr, 1, wds=wd, cycle_len=23, use_clr_beta=(20,22,0.95,0.85), loss_scale=512)\n",
    "phases = [\n",
    "    TrainingPhase(**def_phase, epochs=3, lr=(.04, .08), lr_decay=DecayType.LINEAR, momentum=(0.75,0.95), momentum_decay=DecayType.LINEAR),\n",
    "    TrainingPhase(**def_phase, epochs=13, lr=(.08,.6), lr_decay=DecayType.LINEAR, momentum=(0.95,0.85), momentum_decay=DecayType.LINEAR),\n",
    "    TrainingPhase(opt_fn=optim.SGD, wds=6e-4, epochs=14, lr=(.6,.04), lr_decay=DecayType.LINEAR, momentum=(0.85,0.95), momentum_decay=DecayType.LINEAR)]\n",
    "\n",
    "learn.fit_opt_sched(phases, data_list=[data], loss_scale=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('Crap')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=12), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 93%|| 91/98 [00:07<00:00, 12.93it/s, loss=0.115] \n",
      " 97%|| 95/98 [00:07<00:00, 13.12it/s, loss=0.116]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-95:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/tqdm/_monitor.py\", line 62, in run\n",
      "    for instance in self.tqdm_cls._instances:\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/_weakrefset.py\", line 60, in __iter__\n",
      "    for itemref in self.data:\n",
      "RuntimeError: Set changed size during iteration\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                  \n",
      "    0      0.115448   0.250468   0.9168    \n",
      "    1      0.110093   0.241932   0.9189                    \n",
      "    2      0.095553   0.242897   0.9249                     \n",
      "    3      0.0861     0.262625   0.9206                     \n",
      "    4      0.07784    0.248432   0.9247                     \n",
      "    5      0.064775   0.244981   0.9226                     \n",
      "    6      0.051766   0.227596   0.9307                     \n",
      "    7      0.042212   0.229271   0.931                      \n",
      "    8      0.033536   0.231184   0.9325                     \n",
      "    9      0.026059   0.214287   0.9357                     \n",
      "    10     0.021885   0.208243   0.9383                     \n",
      "    11     0.017362   0.205271   0.9375                     \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([0.20527]), 0.9375000012397766]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phases = [TrainingPhase(opt_fn=optim.SGD, wds=6e-4, epochs=12, lr=(.04,.0001), lr_decay=DecayType.LINEAR, momentum=(0.95))]\n",
    "learn.fit_opt_sched(phases, data_list=[data], loss_scale=512)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### END TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = pre_resnet18()\n",
    "learn = ConvLearner.from_model_data(m, data)\n",
    "learn.half()\n",
    "learn.crit = nn.CrossEntropyLoss()\n",
    "learn.metrics = [accuracy]\n",
    "wd=1e-4\n",
    "lr=.6\n",
    "learn.clip = 3e-1\n",
    "def_phase = {'opt_fn':optim.SGD, 'wds':wd}\n",
    "# TODO: add momentum\n",
    "lr=0.6\n",
    "phases = [\n",
    "    TrainingPhase(**def_phase, epochs=1, lr=(.005,.05), lr_decay=DecayType.EXPONENTIAL, momentum=0.95),\n",
    "    TrainingPhase(**def_phase, epochs=6, lr=(.05,.9), lr_decay=DecayType.COSINE, momentum=(0.95,0.85), momentum_decay=DecayType.COSINE),\n",
    "    TrainingPhase(**def_phase, epochs=4, lr=1, momentum=0.85),\n",
    "    TrainingPhase(**def_phase, epochs=7, lr=(.9,.01), lr_decay=DecayType.COSINE, momentum=(0.85,0.95), momentum_decay=DecayType.COSINE),\n",
    "    TrainingPhase(**def_phase, epochs=3, lr=(.01,.0005), lr_decay=DecayType.LINEAR, momentum=(0.95))]\n",
    "\n",
    "learn.fit_opt_sched(phases, data_list=[data], loss_scale=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.sched.plot_lr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = WideResNetConcat(num_groups=3, N=3, num_classes=10, k=1, drop_p=0.)\n",
    "learn = ConvLearner.from_model_data(m, data)\n",
    "learn.half()\n",
    "learn.crit = nn.CrossEntropyLoss()\n",
    "learn.metrics = [accuracy]\n",
    "wd=1e-4\n",
    "lr=1.5\n",
    "learn.clip = 3e-1\n",
    "%time learn.fit(lr, 1, wds=wd, cycle_len=23, use_clr_beta=(12,22,0.95,0.85), loss_scale=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "266px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
